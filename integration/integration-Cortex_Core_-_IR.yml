category: Endpoint
commonfields:
  id: Cortex Core - IR
  version: -1
configuration:
- display: Server URL (copy URL from Core - click ? to see more info.)
  hidden: true
  name: url
  required: false
  type: 0
- display: API Key ID
  hidden: true
  name: apikey_id
  required: false
  type: 4
- display: API Key
  hidden: true
  name: apikey
  required: false
  type: 4
- additionalinfo: The timeout of the HTTP requests sent to Cortex API (in seconds).
  defaultvalue: "120"
  display: HTTP Timeout
  name: timeout
  required: false
  type: 0
contentitemexportablefields:
  contentitemfields:
    definitionid: ""
    fromServerVersion: 6.2.0
    itemVersion: 3.0.21
    packID: Core
    packName: Core - Investigation and Response
    packPropagationLabels:
    - all
    prevname: ""
    propagationLabels: []
    toServerVersion: ""
description: The Cortex Core IR integration uses the Cortex API for detection and
  response, by natively integrating network, endpoint, and cloud data to stop sophisticated
  attacks.
detaileddescription: '[View Integration Documentation](https://xsoar.pan.dev/docs/reference/integrations/cortex-core---ir)'
display: Investigation & Response
image: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHgAAAAyCAYAAACXpx/YAAAACXBIWXMAAAsSAAALEgHS3X78AAAD6klEQVR4nO2cS24bMQyGyaL75AbJCeo5QIH6BnVPkOkN3BPER8gN4tzA3XQbB+gBHHTbRbzq1kH3ZaGA4ygUNaPxxBOA4AcIqPWgHv9QosZOkYjAscs719Y2LrBxXGDjuMDGcYGN4wIbxwU2jgtsHBfYOC6wcVxg47jAxnGBjeMCG+f9W04PEacAENIDES2TCs7wNR77+2BEPAeABQBcRNl3RDRNKjuDGdWDEbEGgCsAOEkKnaPQW2BErHhbPY2ydwCwJqJN0uCluNdJQf/+Q79VUiAgonWS+WyjEuMvIRwjDwPs7OL14eMpJrGfm2+YGyLOAeAPAPwloh9Jb1HlogQAQaAwAGpJD5otfiC0dksuW/LnYH+u2SiwpaVg91SxsVbqdqXFQDtr0bYW5cFJKlEniLsR9eZc9hsA/gHAL22d9ja0TKWT4olkbMgHYxNPhs9kWZ4Ic4DAT7YUG28ucMm8owd/7xBR2UdOH7R1alLJFh06+STybnhyQbhz3kJmAHCmbDG1yH8MdbXtKGICACsWs4tvvDDNw1ixdzR9TsJ2KLbsJY8/5jL6951Snt3ymS3bzZHMl4gWHHQ2Aed+3ogoA9EbIqqjtj8z/SSdZBMvVvwEPQnaUn+m5MmnUPME+SQ3aarUlR5cUifpU2nTq77iwYmH9jj+5BrJneFg210ePBOf6zbPI6JVkpl64VVSI8+swHM0kgBGqfPanLPXSTrv+MEzOWCbcFa8Y94rOhTTK4pui0xbeLFtE9EuXzWhM1oODwwixjYrcQ175G3v2JyJbb7hrmPrbpjyUSOPs2nPNXtBL4FDyD6ksyMxaTE7eIFGRIthTnjHqw8dRte7aLkw86RGN9u4BgcVpWTv1RH37CVbkf+d44USG69BeBuHSuoMFDveEVxw+UF0CbxkL2i4DOcMX77jAZ6GQSCidtbJbb3PYEu21jkvYsViN3wecnaNBSLOhLhhvb+Idb8+WGQt8hIRnryQxxH1Wl7EC9vLC70WRa8y48lG0XxN2rX1lUuvEEUfcg+uxHj3LzuUMuIgNxlHW2otFCLJztSUaS9fdOyEMFLgdY8XHdPSRWtLYwusjDN5GBXnKJpLn2tS4+VLRFxxhzMlUt3yZHNRdmh3G30ObW8RsYkwm3M5bLFXHdeKHZ+58ed4rBt+zxtfxxYF23VsUztqNPqc77LuQuQtZbzA6w7iWAtHZF0aOI72dWFHIOFfFx6J0X7RwV75VQQPjhWB4Vnkit9lOyPwpn/h7z/ZOT7+XzgYx39VaRwX2DgusHFcYOO4wMZxgY3jAhvHBTaOC2wcF9g4LrBxXGDjuMDGcYEtAwD/AbjPSozwVJX9AAAAAElFTkSuQmCC
name: Cortex Core - IR
script:
  commands:
  - arguments:
    - description: A date in the format 2019-12-31T23:59:00. Only incidents that were
        created on or before the specified date/time will be retrieved.
      name: lte_creation_time
    - description: A date in the format 2019-12-31T23:59:00. Only incidents that were
        created on or after the specified date/time will be retrieved.
      name: gte_creation_time
    - description: Filters returned incidents that were created on or before the specified
        date/time, in the format 2019-12-31T23:59:00.
      name: lte_modification_time
    - description: Filters returned incidents that were modified on or after the specified
        date/time, in the format 2019-12-31T23:59:00.
      name: gte_modification_time
    - description: An array or CSV string of incident IDs.
      isArray: true
      name: incident_id_list
    - description: Filters returned incidents that were created on or after the specified
        date/time range, for example, 1 month, 2 days, 1 hour, and so on.
      name: since_creation_time
    - description: Filters returned incidents that were modified on or after the specified
        date/time range, for example, 1 month, 2 days, 1 hour, and so on.
      name: since_modification_time
    - auto: PREDEFINED
      description: Sorts returned incidents by the date/time that the incident was
        last modified ("asc" - ascending, "desc" - descending).
      name: sort_by_modification_time
      predefined:
      - asc
      - desc
    - auto: PREDEFINED
      description: Sorts returned incidents by the date/time that the incident was
        created ("asc" - ascending, "desc" - descending).
      name: sort_by_creation_time
      predefined:
      - asc
      - desc
    - defaultValue: "0"
      description: Page number (for pagination). The default is 0 (the first page).
      name: page
    - defaultValue: "100"
      description: Maximum number of incidents to return per page. The default and
        maximum is 100.
      name: limit
    - description: 'Filters only incidents in the specified status. The options are:
        new, under_investigation, resolved_known_issue, resolved_false_positive, resolved_true_positive
        resolved_security_testing, resolved_other, resolved_auto.'
      name: status
    - auto: PREDEFINED
      description: 'Whether the incident is starred (Boolean value: true or false).'
      name: starred
      predefined:
      - "true"
      - "false"
    - defaultValue: 3 days
      description: Starred fetch window timestamp (<number> <time unit>, e.g., 12
        hours, 7 days).
      name: starred_incidents_fetch_window
    description: |-
      Returns a list of incidents, which you can filter by a list of incident IDs (max. 100), the time the incident was last modified, and the time the incident was created.
      If you pass multiple filtering arguments, they will be concatenated using the AND condition. The OR condition is not supported.
    name: core-get-incidents
    outputs:
    - contextPath: Core.Incident.incident_id
      description: Unique ID assigned to each returned incident.
      type: String
    - contextPath: Core.Incident.manual_severity
      description: Incident severity assigned by the user. This does not affect the
        calculated severity. Can be "low", "medium", "high".
      type: String
    - contextPath: Core.Incident.manual_description
      description: Incident description provided by the user.
      type: String
    - contextPath: Core.Incident.assigned_user_mail
      description: Email address of the assigned user.
      type: String
    - contextPath: Core.Incident.high_severity_alert_count
      description: Number of alerts with the severity HIGH.
      type: String
    - contextPath: Core.Incident.host_count
      description: Number of hosts involved in the incident.
      type: number
    - contextPath: Core.Incident.xdr_url
      description: A link to the incident view on Cortex XDR.
      type: String
    - contextPath: Core.Incident.assigned_user_pretty_name
      description: Full name of the user assigned to the incident.
      type: String
    - contextPath: Core.Incident.alert_count
      description: Total number of alerts in the incident.
      type: number
    - contextPath: Core.Incident.med_severity_alert_count
      description: Number of alerts with the severity MEDIUM.
      type: number
    - contextPath: Core.Incident.user_count
      description: Number of users involved in the incident.
      type: number
    - contextPath: Core.Incident.severity
      description: |-
        Calculated severity of the incident. Valid values are:
        "low","medium","high".
      type: String
    - contextPath: Core.Incident.low_severity_alert_count
      description: Number of alerts with the severity LOW.
      type: String
    - contextPath: Core.Incident.status
      description: |
        Current status of the incident. Valid values are: "new","under_investigation","resolved_known_issue","resolved_duplicate","resolved_false_positive","resolved_true_positive","resolved_security_testing" or "resolved_other".
      type: String
    - contextPath: Core.Incident.description
      description: Dynamic calculated description of the incident.
      type: String
    - contextPath: Core.Incident.resolve_comment
      description: Comments entered by the user when the incident was resolved.
      type: String
    - contextPath: Core.Incident.notes
      description: Comments entered by the user regarding the incident.
      type: String
    - contextPath: Core.Incident.creation_time
      description: Date and time the incident was created on Cortex XDR.
      type: date
    - contextPath: Core.Incident.detection_time
      description: Date and time that the first alert occurred in the incident.
      type: date
    - contextPath: Core.Incident.modification_time
      description: Date and time that the incident was last modified.
      type: date
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: The endpoint ID (string) to isolate. Retrieve the string from the
        core-get-endpoints command.
      name: endpoint_id
      required: true
    - auto: PREDEFINED
      defaultValue: "false"
      description: Suppress an error when trying to isolate a disconnected endpoint.
        When set to false, an error is returned.
      name: suppress_disconnected_endpoint_error
      predefined:
      - "true"
      - "false"
    description: Isolates the specified endpoint.
    execution: true
    name: core-isolate-endpoint
    outputs:
    - contextPath: Core.Isolation.endpoint_id
      description: The endpoint ID.
      type: String
    polling: true
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: The endpoint ID (string) to reverse the isolation. Retrieve it
        from the core-get-endpoints command.
      name: endpoint_id
      required: true
    - auto: PREDEFINED
      defaultValue: "false"
      description: Suppress an error when trying to unisolate a disconnected endpoint.
        When set to false, an error is be returned.
      name: suppress_disconnected_endpoint_error
      predefined:
      - "true"
      - "false"
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Reverses the isolation of an endpoint.
    execution: true
    name: core-unisolate-endpoint
    outputs:
    - contextPath: Core.UnIsolation.endpoint_id
      description: Isolates the specified endpoint.
      type: String
    polling: true
  - arguments:
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_id_list
    - description: "A comma-separated list of distribution package names or installation
        package names. \nExample: dist_name1,dist_name2."
      isArray: true
      name: dist_name
    - description: |-
        A comma-separated list of private IP addresses.
        Example: 10.1.1.1,192.168.1.1.
      isArray: true
      name: ip_list
    - description: |-
        A comma-separated list of public IP addresses that correlate to the last IPv4 address from which the Cortex XDR agent connected (know as `Last Origin IP`).
        Example: 8.8.8.8,1.1.1.1.
      isArray: true
      name: public_ip_list
    - description: |-
        The group name to which the agent belongs.
        Example: group_name1,group_name2.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: 'The endpoint platform. Valid values are\: "windows", "linux",
        "macos", or "android". '
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: |-
        A comma-separated list of alias names.
        Examples: alias_name1,alias_name2.
      isArray: true
      name: alias_name
    - auto: PREDEFINED
      description: Specifies whether the endpoint was isolated or unisolated.
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: |-
        Hostname
        Example: hostname1,hostname2.
      isArray: true
      name: hostname
    - description: |-
        All the agents that were first seen after {first_seen_gte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_gte
    - description: |-
        All the agents that were first seen before {first_seen_lte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_lte
    - description: |-
        All the agents that were last seen before {last_seen_gte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_gte
    - description: |-
        All the agents that were last seen before {last_seen_lte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_lte
    - defaultValue: "0"
      description: Page number (for pagination). The default is 0 (the first page).
      name: page
    - defaultValue: "30"
      description: Maximum number of endpoints to return per page. The default and
        maximum is 30.
      name: limit
    - auto: PREDEFINED
      description: Specifies whether to sort endpoints by the first time or last time
        they were seen. Can be "first_seen" or "last_seen".
      name: sort_by
      predefined:
      - first_seen
      - last_seen
    - auto: PREDEFINED
      defaultValue: asc
      description: The order by which to sort results. Can be "asc" (ascending) or
        "desc" ( descending). Default set to asc.
      name: sort_order
      predefined:
      - asc
      - desc
    - auto: PREDEFINED
      description: A comma-separated list of endpoints statuses to filter.
      isArray: true
      name: status
      predefined:
      - connected
      - disconnected
      - lost
      - uninstalled
    - description: The usernames to query for, accepts a single user, or comma-separated
        list of usernames.
      isArray: true
      name: username
    description: Gets a list of endpoints, according to the passed filters. If there
      are no filters, all endpoints are returned. Filtering by multiple fields will
      be concatenated using AND condition (OR is not supported). Maximum result set
      size is 100. Offset is the zero-based number of endpoint from the start of the
      result set (start by counting from 0).
    name: core-get-endpoints
    outputs:
    - contextPath: Core.Endpoint.endpoint_id
      description: The endpoint ID.
      type: String
    - contextPath: Core.Endpoint.endpoint_name
      description: The endpoint name.
      type: String
    - contextPath: Core.Endpoint.endpoint_type
      description: The endpoint type.
      type: String
    - contextPath: Core.Endpoint.endpoint_status
      description: The status of the endpoint.
      type: String
    - contextPath: Core.Endpoint.os_type
      description: The endpoint OS type.
      type: String
    - contextPath: Core.Endpoint.ip
      description: A list of IP addresses.
      type: Unknown
    - contextPath: Core.Endpoint.users
      description: A list of users.
      type: Unknown
    - contextPath: Core.Endpoint.domain
      description: The endpoint domain.
      type: String
    - contextPath: Core.Endpoint.alias
      description: The endpoint's aliases.
      type: String
    - contextPath: Core.Endpoint.first_seen
      description: First seen date/time in Epoch (milliseconds).
      type: Unknown
    - contextPath: Core.Endpoint.last_seen
      description: Last seen date/time in Epoch (milliseconds).
      type: Date
    - contextPath: Core.Endpoint.content_version
      description: Content version.
      type: String
    - contextPath: Core.Endpoint.installation_package
      description: Installation package.
      type: String
    - contextPath: Core.Endpoint.active_directory
      description: Active directory.
      type: String
    - contextPath: Core.Endpoint.install_date
      description: Install date in Epoch (milliseconds).
      type: Date
    - contextPath: Core.Endpoint.endpoint_version
      description: Endpoint version.
      type: String
    - contextPath: Core.Endpoint.is_isolated
      description: Whether the endpoint is isolated.
      type: String
    - contextPath: Core.Endpoint.group_name
      description: The name of the group to which the endpoint belongs.
      type: String
    - contextPath: Endpoint.Hostname
      description: The hostname that is mapped to this endpoint.
      type: String
    - contextPath: Endpoint.ID
      description: The unique ID within the tool retrieving the endpoint.
      type: String
    - contextPath: Endpoint.IPAddress
      description: The IP address of the endpoint.
      type: String
    - contextPath: Endpoint.Domain
      description: The domain of the endpoint.
      type: String
    - contextPath: Endpoint.OS
      description: The endpoint's operation system.
      type: String
    - contextPath: Account.Username
      description: The username in the relevant system.
      type: String
    - contextPath: Account.Domain
      description: The domain of the account.
      type: String
    - contextPath: Endpoint.Status
      description: The endpoint's status.
      type: String
    - contextPath: Endpoint.IsIsolated
      description: The endpoint's isolation status.
      type: String
    - contextPath: Endpoint.MACAddress
      description: The endpoint's MAC address.
      type: String
    - contextPath: Endpoint.Vendor
      description: The integration name of the endpoint vendor.
      type: String
  - arguments:
    - auto: PREDEFINED
      description: The status of the endpoint to use as a filter.
      name: status
      predefined:
      - connected
      - disconnected
    - description: A comma-separated list of endpoint IDs to use as a filter.
      isArray: true
      name: endpoint_id_list
    - description: |-
        A comma-separated list of distribution package names or installation package names to use as a filter.
        Example: dist_name1,dist_name2.
      isArray: true
      name: dist_name
    - description: |-
        A comma-separated list of IP addresses to use as a filter.
        Example: 8.8.8.8,1.1.1.1.
      isArray: true
      name: ip_list
    - description: A comma-separated list of group names to which the agent belongs
        to use as a filter.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: The endpoint platform to use as a filter.
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: |-
        A comma-separated list of alias names to use as a filter.
        Examples: alias_name1,alias_name2.
      isArray: true
      name: alias_name
    - auto: PREDEFINED
      description: Specifies whether the endpoint was isolated or unisolated to use
        as a filter.
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: A comma-separated list of hostnames to use as a filter.
      isArray: true
      name: hostname
    - description: |-
        All the agents that were first seen after {first_seen_gte} to use as a filter.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_gte
    - description: |-
        All the agents that were first seen before {first_seen_lte} to use as a filter.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_lte
    - description: |-
        All the agents that were last seen after {last_seen_gte} to use as a filter.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_gte
    - description: |-
        All the agents that were last seen before {last_seen_lte} to use as a filter.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_lte
    - description: The usernames to use as a filter. Accepts a single user, or comma-separated
        list of usernames.
      isArray: true
      name: username
    - description: |-
        The alias name to change to.
        Note: If you send an empty field, (e.g., new_alias_name=\"\") the current alias name is deleted.
      name: new_alias_name
      required: true
    - auto: PREDEFINED
      description: The scan status of the endpoint to use as a filter.
      name: scan_status
      predefined:
      - none
      - pending
      - in_progress
      - canceled
      - aborted
      - pending_cancellation
      - success
      - error
    description: Gets a list of endpoints according to the passed filters, and changes
      their alias name. Filtering by multiple fields will be concatenated using the
      AND condition (OR is not supported).
    name: core-endpoint-alias-change
  - arguments: []
    description: Gets a list of all the agent versions to use for creating a distribution
      list.
    name: core-get-distribution-versions
    outputs:
    - contextPath: Core.DistributionVersions.windows
      description: A list of Windows agent versions.
      type: Unknown
    - contextPath: Core.DistributionVersions.linux
      description: A list of Linux agent versions.
      type: Unknown
    - contextPath: Core.DistributionVersions.macos
      description: A list of Mac agent versions.
      type: Unknown
  - arguments:
    - description: A string representing the name of the installation package.
      name: name
      required: true
    - auto: PREDEFINED
      description: "String, valid values are:\n• windows \n• linux\n• macos \n• android."
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
      required: true
    - auto: PREDEFINED
      description: |-
        A string representing the type of package to create.
        standalone - An installation for a new agent
        upgrade - An upgrade of an agent from ESM.
      name: package_type
      predefined:
      - standalone
      - upgrade
      required: true
    - description: agent_version returned from core-get-distribution-versions. Not
        required for Android platfoms.
      name: agent_version
      required: true
    - description: Information about the package.
      name: description
    description: Creates an installation package. This is an asynchronous call that
      returns the distribution ID. This does not mean that the creation succeeded.
      To confirm that the package has been created, check the status of the distribution
      by running the Get Distribution Status API.
    name: core-create-distribution
    outputs:
    - contextPath: Core.Distribution.id
      description: The installation package ID.
      type: String
    - contextPath: Core.Distribution.name
      description: The name of the installation package.
      type: String
    - contextPath: Core.Distribution.platform
      description: The installation OS.
      type: String
    - contextPath: Core.Distribution.agent_version
      description: Agent version.
      type: String
    - contextPath: Core.Distribution.description
      description: Information about the package.
      type: String
  - arguments:
    - description: |-
        The ID of the installation package.
        Copy the distribution_id from the "id" field on Endpoints > Agent Installation page.
      name: distribution_id
      required: true
    - auto: PREDEFINED
      description: |-
        The installation package type. Valid
        values are:
        • upgrade
        • sh - For Linux
        • rpm - For Linux
        • deb - For Linux
        • pkg - For Mac
        • x86 - For Windows
        • x64 - For Windows.
      name: package_type
      predefined:
      - upgrade
      - sh
      - rpm
      - deb
      - pkg
      - x86
      - x64
      required: true
    description: Gets the distribution URL for downloading the installation package.
    name: core-get-distribution-url
    outputs:
    - contextPath: Core.Distribution.id
      description: Distribution ID.
      type: String
    - contextPath: Core.Distribution.url
      description: URL for downloading the installation package.
      type: String
  - arguments:
    - description: Status of distribution IDs, in a comma-separated list.
      isArray: true
      name: distribution_ids
      required: true
    description: Gets the status of the installation package.
    name: core-get-create-distribution-status
    outputs:
    - contextPath: Core.Distribution.id
      description: Distribution ID.
      type: String
    - contextPath: Core.Distribution.status
      description: Installation package status.
      type: String
  - arguments:
    - description: User’s email address.
      name: email
    - auto: PREDEFINED
      description: The audit log type.
      name: type
      predefined:
      - REMOTE_TERMINAL
      - RULES
      - AUTH
      - RESPONSE
      - INCIDENT_MANAGEMENT
      - ENDPOINT_MANAGEMENT
      - ALERT_WHITELIST
      - PUBLIC_API
      - DISTRIBUTIONS
      - STARRED_INCIDENTS
      - POLICY_PROFILES
      - DEVICE_CONTROL_PROFILE
      - HOST_FIREWALL_PROFILE
      - POLICY_RULES
      - PROTECTION_POLICY
      - DEVICE_CONTROL_TEMP_EXCEPTIONS
      - DEVICE_CONTROL_GLOBAL_EXCEPTIONS
      - GLOBAL_EXCEPTIONS
      - MSSP
      - REPORTING
      - DASHBOARD
      - BROKER_VM
    - description: The audit log subtype.
      name: sub_type
    - auto: PREDEFINED
      description: Result type.
      name: result
      predefined:
      - SUCCESS
      - FAIL
      - PARTIAL
    - description: |-
        Return logs when the timestamp is after 'log_time_after'.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: timestamp_gte
    - description: |-
        Return logs when the timestamp is before the 'log_time_after'.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: timestamp_lte
    - defaultValue: "0"
      description: Page number (for pagination). The default is 0 (the first page).
      name: page
    - defaultValue: "30"
      description: Maximum number of audit logs to return per page. The default and
        maximum is 30.
      name: limit
    - auto: PREDEFINED
      description: Specifies the field by which to sort the results. By default the
        sort is defined as creation-time and descending. Can be "type", "sub_type",
        "result", or "timestamp".
      name: sort_by
      predefined:
      - type
      - sub_type
      - result
      - timestamp
    - auto: PREDEFINED
      defaultValue: desc
      description: The sort order. Can be "asc" (ascending) or "desc" (descending).
        Default set to "desc".
      name: sort_order
      predefined:
      - asc
      - desc
    description: Gets management logs. You can filter by multiple fields, which will
      be concatenated using the AND condition (OR is not supported). Maximum result
      set size is 100. Offset is the zero-based number of management logs from the
      start of the result set (start by counting from 0).
    name: core-get-audit-management-logs
    outputs:
    - contextPath: Core.AuditManagementLogs.AUDIT_ID
      description: Audit log ID.
      type: Number
    - contextPath: Core.AuditManagementLogs.AUDIT_OWNER_NAME
      description: Audit owner name.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_OWNER_EMAIL
      description: Audit owner email address.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_ASSET_JSON
      description: Asset JSON.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_ASSET_NAMES
      description: Audit asset names.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_HOSTNAME
      description: Host name.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_RESULT
      description: Audit result.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_REASON
      description: Audit reason.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_DESCRIPTION
      description: Description of the audit.
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_ENTITY
      description: Audit entity (e.g., AUTH, DISTRIBUTIONS).
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_ENTITY_SUBTYPE
      description: Entity subtype (e.g., Login, Create).
      type: String
    - contextPath: Core.AuditManagementLogs.AUDIT_CASE_ID
      description: Audit case ID.
      type: Number
    - contextPath: Core.AuditManagementLogs.AUDIT_INSERT_TIME
      description: Log's insert time.
      type: Date
  - arguments:
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_ids
    - description: A comma-separated list of endpoint names.
      isArray: true
      name: endpoint_names
    - auto: PREDEFINED
      description: The report type. Can be "Installation", "Policy", "Action", "Agent
        Service", "Agent Modules", or "Agent Status".
      isArray: true
      name: type
      predefined:
      - Installation
      - Policy
      - Action
      - Agent Service
      - Agent Modules
      - Agent Status
    - auto: PREDEFINED
      description: The report subtype.
      isArray: true
      name: sub_type
      predefined:
      - Install
      - Uninstall
      - Upgrade
      - Local Configuration
      - Content Update
      - Policy Update
      - Process Exception
      - Hash Exception
      - Scan
      - File Retrieval
      - File Scan
      - Terminate Process
      - Isolate
      - Cancel Isolation
      - Payload Execution
      - Quarantine
      - Restore
      - Stop
      - Start
      - Module Initialization
      - Local Analysis Model
      - Local Analysis Feature Extraction
      - Fully Protected
      - OS Incompatible
      - Software Incompatible
      - Kernel Driver Initialization
      - Kernel Extension Initialization
      - Proxy Communication
      - Quota Exceeded
      - Minimal Content
      - Reboot Eequired
      - Missing Disc Access
    - auto: PREDEFINED
      description: The result type. Can be "Success" or "Fail". If not passed, returns
        all event reports.
      isArray: true
      name: result
      predefined:
      - Success
      - Fail
    - description: |-
        Return logs that their timestamp is greater than 'log_time_after'.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: timestamp_gte
    - description: |-
        Return logs for which the timestamp is before the 'timestamp_lte'.

        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: timestamp_lte
    - defaultValue: "0"
      description: Page number (for pagination). The default is 0 (the first page).
      name: page
    - defaultValue: "30"
      description: The maximum number of reports to return. Default and maximum is
        30.
      name: limit
    - auto: PREDEFINED
      description: The field by which to sort results. Can be "type", "category",
        "trapsversion", "timestamp", or "domain").
      name: sort_by
      predefined:
      - type
      - category
      - trapsversion
      - timestamp
      - domain
    - auto: PREDEFINED
      defaultValue: asc
      description: The sort order. Can be "asc" (ascending) or "desc" (descending).
        Default is "asc".
      name: sort_order
      predefined:
      - asc
      - desc
    description: Gets agent event reports. You can filter by multiple fields, which
      will be concatenated using the AND condition (OR is not supported). Maximum
      result set size is 100. Offset is the zero-based number of reports from the
      start of the result set (start by counting from 0).
    name: core-get-audit-agent-reports
    outputs:
    - contextPath: Core.AuditAgentReports.ENDPOINTID
      description: Endpoint ID.
      type: String
    - contextPath: Core.AuditAgentReports.ENDPOINTNAME
      description: Endpoint name.
      type: String
    - contextPath: Core.AuditAgentReports.DOMAIN
      description: Agent domain.
      type: String
    - contextPath: Core.AuditAgentReports.TRAPSVERSION
      description: Traps version.
      type: String
    - contextPath: Core.AuditAgentReports.RECEIVEDTIME
      description: Received time in Epoch time.
      type: Date
    - contextPath: Core.AuditAgentReports.TIMESTAMP
      description: Timestamp in Epoch time.
      type: Date
    - contextPath: Core.AuditAgentReports.CATEGORY
      description: Report category (e.g., Audit).
      type: String
    - contextPath: Core.AuditAgentReports.TYPE
      description: Report type (e.g., Action, Policy).
      type: String
    - contextPath: Core.AuditAgentReports.SUBTYPE
      description: Report subtype (e.g., Fully Protected,Policy Update,Cancel Isolation).
      type: String
    - contextPath: Core.AuditAgentReports.RESULT
      description: Report result.
      type: String
    - contextPath: Core.AuditAgentReports.REASON
      description: Report reason.
      type: String
    - contextPath: Core.AuditAgentReports.DESCRIPTION
      description: Agent report description.
      type: String
    - contextPath: Endpoint.ID
      description: The unique ID within the tool retrieving the endpoint.
      type: String
    - contextPath: Endpoint.Hostname
      description: The hostname that is mapped to this endpoint.
      type: String
    - contextPath: Endpoint.Domain
      description: The domain of the endpoint.
      type: String
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: String that represents a list of hashed files you want to block
        list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    - auto: PREDEFINED
      defaultValue: "false"
      description: Choose either regular response or detailed response. Default value
        = false, regular response.
      name: detailed_response
      predefined:
      - "true"
      - "false"
    description: Block lists requested files which have not already been block listed
      or added to allow lists.
    name: core-blocklist-files
    outputs:
    - contextPath: Core.blocklist.added_hashes
      description: Added fileHash to blocklist.
      type: Number
    - contextPath: Core.blocklist.excluded_hashes
      description: Added fileHash to blocklist.
      type: Number
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: String that represents a list of hashed files you want to add to
        allow lists. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    - auto: PREDEFINED
      defaultValue: "false"
      description: Choose either regular response or detailed response. Default value
        = false, regular response.
      name: detailed_response
      predefined:
      - "true"
      - "false"
    description: Adds requested files to allow list if they are not already on block
      list or allow list.
    name: core-allowlist-files
    outputs:
    - contextPath: Core.allowlist.added_hashes
      description: Added fileHash to allowlist.
      type: Number
    - contextPath: Core.allowlist.excluded_hashes
      description: Added fileHash to allowlist.
      type: Number
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
      required: true
    - description: String that represents the path of the file you want to quarantine.
      name: file_path
      required: true
    - description: String that represents the file’s hash. Must be a valid SHA256
        hash.
      name: file_hash
      required: true
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Quarantines a file on selected endpoints. You can select up to 1000
      endpoints.
    name: core-quarantine-files
    polling: true
  - arguments:
    - description: String that represents the endpoint ID.
      name: endpoint_id
      required: true
    - description: String that represents the file hash. Must be a valid SHA256 hash.
      name: file_hash
      required: true
    - description: String that represents the file path.
      name: file_path
      required: true
    description: Retrieves the quarantine status for a selected file.
    name: core-get-quarantine-status
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: String that represents the file in hash. Must be a valid SHA256
        hash.
      name: file_hash
      required: true
    - description: String that represents the endpoint ID. If you do not enter a specific
        endpoint ID, the request will run restore on all endpoints which relate to
        the quarantined file you defined.
      name: endpoint_id
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Restores a quarantined file on requested endpoints.
    name: core-restore-file
    polling: true
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
    - description: Name of the distribution list.
      isArray: true
      name: dist_name
    - description: Epoch timestamp in milliseconds.
      name: gte_first_seen
    - description: Epoch timestamp in milliseconds.
      name: gte_last_seen
    - description: Epoch timestamp in milliseconds.
      name: lte_first_seen
    - description: Epoch timestamp in milliseconds.
      name: lte_last_seen
    - description: List of IP addresses.
      isArray: true
      name: ip_list
    - description: Name of the endpoint group.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: Type of operating system.
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: Endpoint alias name.
      isArray: true
      name: alias
    - auto: PREDEFINED
      description: Choose if an endpoint has been isolated. Select "isolated" or "unisolated".
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: Name of the host.
      isArray: true
      name: hostname
    - auto: PREDEFINED
      defaultValue: "false"
      description: Choose whether to scan all of the endpoints or not. Default is
        false. Scanning all of the endpoints may cause performance issues and latency.
      name: all
      predefined:
      - "true"
      - "false"
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Runs a scan on a selected endpoint. To scan all endpoints, run this
      command with argument all=true. Note that scanning all the endpoints may cause
      performance issues and latency.
    execution: true
    name: core-endpoint-scan
    outputs:
    - contextPath: Core.endpointScan.actionId
      description: The action ID of the scan request.
      type: Number
    - contextPath: Core.endpointScan.aborted
      description: Was the scan aborted.
      type: Boolean
    polling: true
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
    - description: Name of the distribution list.
      isArray: true
      name: dist_name
    - description: Epoch timestamp in milliseconds.
      name: gte_first_seen
    - description: Epoch timestamp in milliseconds.
      name: gte_last_seen
    - description: Epoch timestamp in milliseconds.
      name: lte_first_seen
    - description: Epoch timestamp in milliseconds.
      name: lte_last_seen
    - description: List of IP addresses.
      isArray: true
      name: ip_list
    - description: Name of the endpoint group.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: Type of operating system.
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: Endpoint alias name.
      isArray: true
      name: alias
    - auto: PREDEFINED
      description: Choose whether an endpoint has been isolated. Select "isolated"
        or "unisolated".
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: Name of the host.
      isArray: true
      name: hostname
    - auto: PREDEFINED
      defaultValue: "false"
      description: Whether to scan all of the endpoints or not. Default is false.
        Note that scanning all of the endpoints may cause performance issues and latency.
      name: all
      predefined:
      - "true"
      - "false"
    description: Cancel the selected endpoints scan. A scan can only be cancelled
      if the selected endpoints are Pending or In Progress. To scan all endpoints,
      run the command with the argument all=true. Note that scanning all of the endpoints
      may cause performance issues and latency.
    execution: true
    name: core-endpoint-scan-abort
    outputs:
    - contextPath: Core.endpointScan.actionId
      description: The action id of the abort scan request.
      type: Unknown
    - contextPath: Core.endpointScan.aborted
      description: Was the scan cancelled.
      type: Boolean
  - arguments:
    - description: The endpoint ID. Retrieve by running the core-get-endpoints command.
      name: endpoint_id
      required: true
    description: Gets the policy name for a specific endpoint.
    name: core-get-policy
    outputs:
    - contextPath: Core.Policy
      description: The policy allocated with the endpoint.
      type: string
    - contextPath: Core.Policy.policy_name
      description: Name of the policy allocated with the endpoint.
      type: string
    - contextPath: Core.Policy.endpoint_id
      description: Endpoint ID.
      type: string
  - arguments:
    - description: A comma-separated list of the script names.
      isArray: true
      name: script_name
    - description: A comma-separated list of the script descriptions.
      isArray: true
      name: description
    - description: A comma-separated list of the users who created the script.
      isArray: true
      name: created_by
    - description: The maximum number of scripts returned to the War Room. Default
        is 50.
      name: limit
    - description: (Int) Offset in the data set. Default is 0.
      name: offset
    - auto: PREDEFINED
      description: Choose to run the script on a Windows operating system.
      name: windows_supported
      predefined:
      - "true"
      - "false"
    - auto: PREDEFINED
      description: Choose to run the script on a Linux operating system.
      name: linux_supported
      predefined:
      - "true"
      - "false"
    - auto: PREDEFINED
      description: Choose to run the script on a Mac operating system.
      name: macos_supported
      predefined:
      - "true"
      - "false"
    - auto: PREDEFINED
      description: Choose if the script has a high-risk outcome.
      name: is_high_risk
      predefined:
      - "true"
      - "false"
    description: Gets a list of scripts available in the scripts library.
    name: core-get-scripts
    outputs:
    - contextPath: Core.Scripts
      description: The scripts command results.
      type: Unknown
    - contextPath: Core.Scripts.script_id
      description: Script ID.
      type: Unknown
    - contextPath: Core.Scripts.name
      description: Name of the script.
      type: string
    - contextPath: Core.Scripts.description
      description: Description of the script.
      type: string
    - contextPath: Core.Scripts.modification_date
      description: Timestamp of when the script was last modified.
      type: Unknown
    - contextPath: Core.Scripts.created_by
      description: Name of the user who created the script.
      type: string
    - contextPath: Core.Scripts.windows_supported
      description: Choose to run the script on a Windows operating system.
      type: boolean
    - contextPath: Core.Scripts.linux_supported
      description: Choose to run the script on a Linux operating system.
      type: boolean
    - contextPath: Core.Scripts.macos_supported
      description: Choose to run the script on a Mac operating system.
      type: boolean
    - contextPath: Core.Scripts.is_high_risk
      description: Choose if the script has a high-risk outcome.
      type: boolean
    - contextPath: Core.Scripts.script_uid
      description: Globally Unique Identifier of the script, used to identify the
        script when executing.
      type: string
  - arguments:
    - description: Comma-separated list of endpoint IDs. You can retrieve the endpoint
        IDs from the core-get-endpoints command.
      name: endpoint_ids
      required: true
    description: Deletes selected endpoints in the Cortex app. You can delete up to
      1000 endpoints.
    name: core-delete-endpoints
  - arguments:
    - description: Comma-separated list of endpoint IDs. You can retrieve the endpoint
        IDs from the core-get-endpoints command.
      isArray: true
      name: endpoint_ids
    - auto: PREDEFINED
      description: 'Type of violation. Possible values are: "cd-rom", "disk drive",
        "floppy disk", and "portable device".'
      name: type
      predefined:
      - cd-rom
      - disk drive
      - floppy disk
      - portable device
    - description: 'Timestamp of the violation. Violations that are greater than or
        equal to this timestamp will be returned. Values can be in either ISO date
        format, relative time, or epoch timestamp. For example:  "2019-10-21T23:45:00"
        (ISO date format), "3 days ago" (relative time) 1579039377301 (epoch time).'
      name: timestamp_gte
    - description: 'Timestamp of the violation. Violations that are less than or equal
        to this timestamp will be returned. Values can be in either ISO date format,
        relative time, or epoch timestamp. For example:  "2019-10-21T23:45:00" (ISO
        date format), "3 days ago" (relative time) 1579039377301 (epoch time).'
      name: timestamp_lte
    - description: Comma-separated list of IP addresses.
      isArray: true
      name: ip_list
    - description: Name of the vendor.
      isArray: true
      name: vendor
    - description: Vendor ID.
      isArray: true
      name: vendor_id
    - description: Name of the product.
      isArray: true
      name: product
    - description: Product ID.
      isArray: true
      name: product_id
    - description: Serial number.
      isArray: true
      name: serial
    - description: Hostname.
      isArray: true
      name: hostname
    - description: Comma-separated list of violation IDs.
      isArray: true
      name: violation_id_list
    - description: Username.
      isArray: true
      name: username
    description: Gets a list of device control violations filtered by selected fields.
      You can retrieve up to 100 violations.
    name: core-get-endpoint-device-control-violations
    outputs:
    - contextPath: Core.EndpointViolations
      description: Endpoint violations command results.
      type: Unknown
    - contextPath: Core.EndpointViolations.violations
      description: A list of violations.
      type: Unknown
    - contextPath: Core.EndpointViolations.violations.os_type
      description: Type of the operating system.
      type: string
    - contextPath: Core.EndpointViolations.violations.hostname
      description: Hostname of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.username
      description: Username of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.ip
      description: IP address of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.timestamp
      description: Timestamp of the violation.
      type: number
    - contextPath: Core.EndpointViolations.violations.violation_id
      description: Violation ID.
      type: number
    - contextPath: Core.EndpointViolations.violations.type
      description: Type of violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.vendor_id
      description: Vendor ID of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.vendor
      description: Name of the vendor of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.product_id
      description: Product ID of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.product
      description: Name of the product of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.serial
      description: Serial number of the violation.
      type: string
    - contextPath: Core.EndpointViolations.violations.endpoint_id
      description: Endpoint ID of the violation.
      type: string
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: Comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_ids
      required: true
    - description: A comma-separated list of file paths on the Windows platform.
      isArray: true
      name: windows_file_paths
    - description: A comma-separated list of file paths on the Linux platform.
      isArray: true
      name: linux_file_paths
    - description: A comma-separated list of file paths on the Mac platform.
      isArray: true
      name: mac_file_paths
    - description: A comma-separated list of file paths in any platform. Can be used
        instead of the mac/windows/linux file paths. The order of the files path list
        must be parellel to the endpoints list order, therefore, the first file path
        in the list is related to the first endpoint and so on.
      isArray: true
      name: generic_file_path
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Retrieves files from selected endpoints. You can retrieve up to 20
      files, from no more than 10 endpoints. At least one endpoint ID and one file
      path are necessary in order to run the command. After running this command,
      you can use the core-action-status-get command with returned action_id, to check
      the action status.
    name: core-retrieve-files
    outputs:
    - contextPath: Core.RetrievedFiles.action_id
      description: ID of the action to retrieve files from selected endpoints.
      type: string
    polling: true
  - arguments:
    - description: Action ID retrieved from the core-retrieve-files command.
      isArray: true
      name: action_id
      required: true
    description: View the file retrieved by the core-retrieve-files command according
      to the action ID. Before running this command, you can use the core-action-status-get
      command to check if this action completed successfully.
    name: core-retrieve-file-details
    outputs:
    - contextPath: File
      description: The file details command results.
      type: Unknown
    - contextPath: File.Name
      description: The full file name (including the file extension).
      type: String
    - contextPath: File.EntryID
      description: The ID for locating the file in the War Room.
      type: String
    - contextPath: File.Size
      description: The size of the file in bytes.
      type: Number
    - contextPath: File.MD5
      description: The MD5 hash of the file.
      type: String
    - contextPath: File.SHA1
      description: The SHA1 hash of the file.
      type: String
    - contextPath: File.SHA256
      description: The SHA256 hash of the file.
      type: String
    - contextPath: File.SHA512
      description: The SHA512 hash of the file.
      type: String
    - contextPath: File.Extension
      description: 'The file extension. For example: "xls".'
      type: String
    - contextPath: File.Type
      description: The file type, as determined by libmagic (same as displayed in
        file entries).
      type: String
  - arguments:
    - description: Unique identifier of the script, returned by the core-get-scripts
        command.
      name: script_uid
      required: true
    description: Gets the full definition of a specific script in the scripts library.
    name: core-get-script-metadata
    outputs:
    - contextPath: Core.ScriptMetadata
      description: The script metadata command results.
      type: Unknown
    - contextPath: Core.ScriptMetadata.script_id
      description: Script ID.
      type: number
    - contextPath: Core.ScriptMetadata.name
      description: Script name.
      type: string
    - contextPath: Core.ScriptMetadata.description
      description: Script description.
      type: string
    - contextPath: Core.ScriptMetadata.modification_date
      description: Timestamp of when the script was last modified.
      type: unknown
    - contextPath: Core.ScriptMetadata.created_by
      description: Name of the user who created the script.
      type: string
    - contextPath: Core.ScriptMetadata.is_high_risk
      description: Whether the script has a high-risk outcome.
      type: boolean
    - contextPath: Core.ScriptMetadata.windows_supported
      description: Choose to run the script on a Windows operating system.
      type: boolean
    - contextPath: Core.ScriptMetadata.linux_supported
      description: Choose to run the script on a Linux operating system.
      type: boolean
    - contextPath: Core.ScriptMetadata.macos_supported
      description: Choose to run the script on a Mac operating system.
      type: boolean
    - contextPath: Core.ScriptMetadata.entry_point
      description: Name of the entry point selected for the script. An empty string
        indicates  the script defined as just run.
      type: string
    - contextPath: Core.ScriptMetadata.script_input
      description: Name and type for the specified entry point.
      type: string
    - contextPath: Core.ScriptMetadata.script_output_type
      description: Type of the output.
      type: string
    - contextPath: Core.ScriptMetadata.script_output_dictionary_definitions
      description: If the script_output_type is a dictionary, an array with friendly
        name, name, and type for each output.
      type: Unknown
  - arguments:
    - description: Unique identifier of the script, returned by the core-get-scripts
        command.
      name: script_uid
      required: true
    description: Gets the code of a specific script in the script library.
    name: core-get-script-code
    outputs:
    - contextPath: Core.ScriptCode
      description: The script code command results.
      type: Unknown
    - contextPath: Core.ScriptCode.code
      description: The code of a specific script in the script library.
      type: string
    - contextPath: Core.ScriptCode.script_uid
      description: Unique identifier of the script.
      type: string
  - arguments:
    - description: The action ID of the selected request. After performing an action,
        you will receive an action ID.
      isArray: true
      name: action_id
      required: true
    description: Retrieves the status of the requested actions according to the action
      ID.
    name: core-action-status-get
    outputs:
    - contextPath: Core.GetActionStatus
      description: The action status command results.
      type: Unknown
    - contextPath: Core.GetActionStatus.endpoint_id
      description: Endpoint ID.
      type: string
    - contextPath: Core.GetActionStatus.status
      description: The status of the specific endpoint ID.
      type: string
    - contextPath: Core.GetActionStatus.action_id
      description: The specified action ID.
      type: number
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: Comma-separated list of endpoint IDs. Can be retrieved by running
        the core-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: Unique identifier of the script. Can be retrieved by running the
        core-get-scripts command.
      name: script_uid
      required: true
    - description: Dictionary contains the parameter name as key and its value for
        this execution as the value. For example, {"param1":"param1_value","param2":"param2_value"}.
      name: parameters
    - defaultValue: "600"
      description: The timeout in seconds for this execution.
      name: timeout
    description: Initiates a new endpoint script execution action using a script from
      the script library.
    name: core-run-script
    outputs:
    - contextPath: Core.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Links the response action to the incident that triggered it. it.
      name: incident_id
    - description: Comma-separated list of endpoint IDs. Can be retrieved by running
        the core-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: Section of a script you want to initiate on an endpoint, for example,
        print("7").
      name: snippet_code
      required: true
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Initiates a new endpoint script execution action using the provided
      snippet code.
    name: core-run-snippet-code-script
    outputs:
    - contextPath: Core.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
    polling: true
  - arguments:
    - description: Action IDs retrieved from the core-run-script command.
      isArray: true
      name: action_id
      required: true
    description: Retrieves the status of a script execution action.
    name: core-get-script-execution-status
    outputs:
    - contextPath: Core.ScriptStatus.general_status
      description: General status of the action, considering the status of all the
        endpoints.
      type: String
    - contextPath: Core.ScriptStatus.error_message
      description: Error message regarding permissions for running APIs or the action
        doesn’t exist.
      type: String
    - contextPath: Core.ScriptStatus.endpoints_timeout
      description: Number of endpoints in "timeout" status.
      type: Number
    - contextPath: Core.ScriptStatus.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_pending_abort
      description: Number of endpoints in "pending abort" status.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_pending
      description: Number of endpoints in "pending" status.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_in_progress
      description: Number of endpoints in "in progress" status.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_failed
      description: Number of endpoints in "failed" status.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_expired
      description: Number of endpoints in "expired" status.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_completed_successfully
      description: Number of endpoints in "completed successfully" status.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_canceled
      description: Number of endpoints in "canceled" status.
      type: Number
    - contextPath: Core.ScriptStatus.endpoints_aborted
      description: Number of endpoints in "aborted" status.
      type: Number
  - arguments:
    - description: Action IDs retrieved from the core-run-script command.
      isArray: true
      name: action_id
      required: true
    description: Retrieve the results of a script execution action.
    name: core-get-script-execution-results
    outputs:
    - contextPath: Core.ScriptResult.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptResult.results.retrieved_files
      description: Number of successfully retrieved files.
      type: Number
    - contextPath: Core.ScriptResult.results.endpoint_ip_address
      description: Endpoint IP address.
      type: String
    - contextPath: Core.ScriptResult.results.endpoint_name
      description: Number of successfully retrieved files.
      type: String
    - contextPath: Core.ScriptResult.results.failed_files
      description: Number of files failed to retrieve.
      type: Number
    - contextPath: Core.ScriptResult.results.endpoint_status
      description: Endpoint status.
      type: String
    - contextPath: Core.ScriptResult.results.domain
      description: Domain to which the endpoint belongs.
      type: String
    - contextPath: Core.ScriptResult.results.endpoint_id
      description: Endpoint ID.
      type: String
    - contextPath: Core.ScriptResult.results.execution_status
      description: Execution status of this endpoint.
      type: String
    - contextPath: Core.ScriptResult.results.return_value
      description: Value returned by the script in case the type is not a dictionary.
      type: String
    - contextPath: Core.ScriptResult.results.standard_output
      description: The STDOUT and the STDERR logged by the script during the execution.
      type: String
    - contextPath: Core.ScriptResult.results.retention_date
      description: Timestamp in which the retrieved files will be deleted from the
        server.
      type: Date
    - contextPath: Core.ScriptResult.results.command
      description: The command that was executed by the script.
      type: String
    - contextPath: Core.ScriptResult.results.command_output
      description: The output of the command executed by the script.
      type: array
  - arguments:
    - description: Action ID retrieved from the core-run-script command.
      isArray: true
      name: action_id
      required: true
    - description: Endpoint ID. Can be retrieved by running the core-get-endpoints
        command.
      isArray: true
      name: endpoint_id
      required: true
    description: Gets the files retrieved from a specific endpoint during a script
      execution.
    name: core-get-script-execution-result-files
    outputs:
    - contextPath: File.Size
      description: The size of the file.
      type: String
    - contextPath: File.SHA1
      description: The SHA1 hash of the file.
      type: String
    - contextPath: File.SHA256
      description: The SHA256 hash of the file.
      type: String
    - contextPath: File.SHA512
      description: The SHA512 hash of the file.
      type: String
    - contextPath: File.Name
      description: The name of the file.
      type: String
    - contextPath: File.SSDeep
      description: The SSDeep hash of the file.
      type: String
    - contextPath: File.EntryID
      description: EntryID of the file.
      type: String
    - contextPath: File.Info
      description: Information about the file.
      type: String
    - contextPath: File.Type
      description: The file type.
      type: String
    - contextPath: File.MD5
      description: The MD5 hash of the file.
      type: String
    - contextPath: File.Extension
      description: The extension of the file.
      type: String
  - arguments:
    - description: Link the response action to triggered incident.
      name: incident_id
    - description: Comma-separated list of endpoint IDs. Can be retrieved by running
        the core-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: Comma-separated list of shell commands to execute.
      name: commands
      required: true
    - defaultValue: "600"
      description: The timeout in seconds for this execution.
      name: timeout
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Initiate a new endpoint script execution of shell commands.
    name: core-run-script-execute-commands
    outputs:
    - contextPath: Core.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
    polling: true
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: Comma-separated list of endpoint IDs. Can be retrieved by running
        the core-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: Paths of the files to delete, in a comma-separated list. Paths
        of the files to check for existence. All of the given file paths will run
        on all of the endpoints.
      isArray: true
      name: file_path
      required: true
    - defaultValue: "600"
      description: The timeout in seconds for this execution.
      name: timeout
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Initiates a new endpoint script execution to delete the specified
      file.
    name: core-run-script-delete-file
    outputs:
    - contextPath: Core.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
    polling: true
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: Comma-separated list of endpoint IDs. Can be retrieved by running
        the core-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: Paths of the files to check for existence, in a comma-separated
        list. All of the given file paths will run on all of the endpoints.
      isArray: true
      name: file_path
      required: true
    - defaultValue: "600"
      description: The timeout in seconds for this execution.
      name: timeout
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Initiates a new endpoint script execution to check if file exists.
    name: core-run-script-file-exists
    outputs:
    - contextPath: Core.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
    polling: true
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: Comma-separated list of endpoint IDs. Can be retrieved by running
        the core-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: Names of processes to kill. Will kill all of the given processes
        on all of the endpoints.
      isArray: true
      name: process_name
      required: true
    - defaultValue: "600"
      description: The timeout in seconds for this execution.
      name: timeout
    - deprecated: true
      description: For polling use.
      isArray: true
      name: action_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: Initiates a new endpoint script execution kill process.
    name: core-run-script-kill-process
    outputs:
    - contextPath: Core.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: Core.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
    polling: true
  - arguments:
    - description: The endpoint ID.
      isArray: true
      name: id
    - default: true
      description: The endpoint IP address.
      isArray: true
      name: ip
    - description: The endpoint hostname.
      isArray: true
      name: hostname
    description: Returns information about an endpoint.
    name: endpoint
    outputs:
    - contextPath: Endpoint.Hostname
      description: The endpoint's hostname.
      type: String
    - contextPath: Endpoint.OS
      description: The endpoint's operation system.
      type: String
    - contextPath: Endpoint.IPAddress
      description: The endpoint's IP address.
      type: String
    - contextPath: Endpoint.ID
      description: The endpoint's ID.
      type: String
    - contextPath: Endpoint.Status
      description: The endpoint's status.
      type: String
    - contextPath: Endpoint.IsIsolated
      description: The endpoint's isolation status.
      type: String
    - contextPath: Endpoint.MACAddress
      description: The endpoint's MAC address.
      type: String
    - contextPath: Endpoint.Vendor
      description: The integration name of the endpoint vendor.
      type: String
  - arguments:
    - description: String that represents the file’s hash. Must be a valid SHA256
        hash.
      name: file_hash
      required: true
    - description: The new verdict of the file. 0 - benign, 1 - malware.
      name: new_verdict
      predefined:
      - "0"
      - "1"
      required: true
    - description: String that represents the reason of the report.
      name: reason
      required: true
    - description: User’s email address.
      name: email
      required: true
    description: Reports to WildFire about incorrect hash verdict through Cortex.
    execution: true
    name: core-report-incorrect-wildfire
    outputs:
    - contextPath: Core.WildFire.file_hash
      description: String that represents the file’s hash.
      type: Number
    - contextPath: Core.WildFire.new_verdict
      description: The new verdict of the file.
      type: Number
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: String that represents a list of hashed files you want to add to
        allow list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    description: Removes requested files from allow list.
    name: core-remove-allowlist-files
    outputs:
    - contextPath: Core.allowlist.removed_hashes
      description: Removed file hash.
      type: Number
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: String that represents a list of hashed files you want to add to
        allow list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    description: Removes requested files from block list.
    name: core-remove-blocklist-files
    outputs:
    - contextPath: Core.blocklist.removed_hashes
      description: Removed fileHash from blocklist.
      type: Number
  - arguments:
    - description: Name of the exclusion.
      name: name
      required: true
    - description: 'Filter object for the exclusion. example: {"filter":{"AND":[{"SEARCH_FIELD":"alert_category","SEARCH_TYPE":"NEQ","SEARCH_VALUE":"Phishing"}]}}.'
      name: filterObject
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    - auto: PREDEFINED
      defaultValue: ENABLED
      description: Status of exclusion. default value = ENABLED.
      name: status
      predefined:
      - ENABLED
      - DISABLED
    description: Adds alert exclusion rule based on filterObject.
    name: core-add-exclusion
    outputs:
    - contextPath: Core.exclusion.rule_id
      description: Added exclusion rule id.
      type: Number
  - arguments:
    - description: The desired alert_exclusion_id to be removed.
      name: alert_exclusion_id
      required: true
    description: Delete an alert exclusion rule based on rule ID.
    name: core-delete-exclusion
    outputs:
    - contextPath: Core.deletedExclusion.rule_id
      description: Deleted exclusion rule id.
      type: Number
  - arguments:
    - description: Links the response action to the tenant that triggered it.
      name: tenant_ID
    - description: 'Filter object for the exclusion. Example: {"filter":{"AND":[{"SEARCH_FIELD":"alert_category","SEARCH_TYPE":"NEQ","SEARCH_VALUE":"Phishing"}]}}.'
      name: filterObject
    - defaultValue: "20"
      description: Limit for the response. You will get the first "limit" exclusions.
        Default value is 20.
      name: limit
    description: Get a list of the alerts exclusion.
    name: core-get-exclusion
    outputs:
    - contextPath: Core.exclusion.ALERT_WHITELIST_ID
      description: ""
      type: Number
    - contextPath: Core.exclusion.ALERT_WHITELIST_MODIFY_TIME
      description: ""
      type: Date
    - contextPath: Core.exclusion.ALERT_WHITELIST_NAME
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR_TEXT.pretty_name
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR_TEXT.data_type
      description: ""
      type: Unknown
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR_TEXT.render_type
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR_TEXT.entity_map
      description: ""
      type: Unknown
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR_TEXT.dml_type
      description: ""
      type: Unknown
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR.filter.AND.SEARCH_FIELD
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR.filter.AND.SEARCH_TYPE
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_INDICATOR.filter.AND.SEARCH_VALUE
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_HITS
      description: ""
      type: Number
    - contextPath: Core.exclusion.ALERT_WHITELIST_COMMENT
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_USER
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_PRETTY_USER
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_STATUS
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_BACKWARDS_SCAN_STATUS
      description: ""
      type: String
    - contextPath: Core.exclusion.ALERT_WHITELIST_BACKWARDS_SCAN_TIMESTAMP
      description: ""
      type: Unknown
    - contextPath: Core.exclusion.ALERT_WHITELIST_MIGRATED_FROM_ANALYTICS
      description: ""
      type: Number
  - arguments:
    - description: A comma-separated list of alert IDs.
      isArray: true
      name: alert_ids
      required: true
    - auto: PREDEFINED
      defaultValue: "true"
      description: Whether to return only a subset of the alert fields. Filtering
        the fields can reduce response size for large alerts.
      name: filter_alert_fields
      predefined:
      - "true"
      - "false"
    description: Returns information about each alert ID.
    name: core-get-cloud-original-alerts
    outputs:
    - contextPath: Core.OriginalAlert.event._time
      description: The timestamp of the occurence of the event.
      type: String
    - contextPath: Core.OriginalAlert.event.vendor
      description: Vendor name.
      type: String
    - contextPath: Core.OriginalAlert.event.event_timestamp
      description: Event timestamp.
      type: Number
    - contextPath: Core.OriginalAlert.event.event_type
      description: Event type (static 500).
      type: Number
    - contextPath: Core.OriginalAlert.event.cloud_provider
      description: The cloud provider - GCP, AZURE, or AWS.
      type: String
    - contextPath: Core.OriginalAlert.event.project
      description: The project in which the event occurred.
      type: String
    - contextPath: Core.OriginalAlert.event.cloud_provider_event_id
      description: The ID given to the event by the cloud provider, if the ID exists.
      type: String
    - contextPath: Core.OriginalAlert.event.cloud_correlation_id
      description: The ID the cloud provider is using to aggregate events that are
        part of the same general event.
      type: String
    - contextPath: Core.OriginalAlert.event.operation_name_orig
      description: The name of the operation that occurred, as supplied by the cloud
        provider.
      type: String
    - contextPath: Core.OriginalAlert.event.operation_name
      description: The normalized name of the operation performed by the event.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_orig
      description: Contains the original identity related fields as provided by the
        cloud provider.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_name
      description: The name of the identity that initiated the action.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_uuid
      description: Same as identity_name but also contains the UUID of the identity
        if it exists.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_type
      description: An enum representing the type of the identity.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_sub_type
      description: An enum representing the sub-type of the identity, respective to
        its identity_type.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_invoked_by_name
      description: The name of the identity that invoked the action as it appears
        in the log.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_invoked_by_uuid
      description: The UUID of the identity that invoked the action as it appears
        in the log.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_invoked_by_type
      description: An enum that represents the type of identity event that invoked
        the action.
      type: String
    - contextPath: Core.OriginalAlert.event.identity_invoked_by_sub_type
      description: An enum that represents the respective sub_type of the type of
        identity (identity_type) that has invoked the action.
      type: String
    - contextPath: Core.OriginalAlert.event.operation_status
      description: Status of whether the operation has succeed or failed, if provided.
      type: String
    - contextPath: Core.OriginalAlert.event.operation_status_orig
      description: The operation status code as it appears in the log, including lookup
        from code number to code name.
      type: String
    - contextPath: Core.OriginalAlert.event.operation_status_orig_code
      description: The operation status code as it appears in the log.
      type: String
    - contextPath: Core.OriginalAlert.event.operation_status_reason_provided
      description: Description of the error, if the log record indicates an error
        and the cloud provider supplied the reason.
      type: String
    - contextPath: Core.OriginalAlert.event.resource_type
      description: The normalized type of the service that emitted the log row.
      type: String
    - contextPath: Core.OriginalAlert.event.resource_type_orig
      description: The type of the service that omitted the log as provided by the
        cloud provider.
      type: String
    - contextPath: Core.OriginalAlert.event.resource_sub_type
      description: The sub-type respective to the resource_type field, normalized
        across all cloud providers.
      type: String
    - contextPath: Core.OriginalAlert.event.resource_sub_type_orig
      description: The sub-type of the service that emitted this log row as provided
        by the cloud provider.
      type: String
    - contextPath: Core.OriginalAlert.event.region
      description: The cloud region of the resource that emitted the log.
      type: String
    - contextPath: Core.OriginalAlert.event.zone
      description: The availability zone of the resource that emitted the log.
      type: String
    - contextPath: Core.OriginalAlert.event.referenced_resource
      description: The cloud resource referenced in the audit log.
      type: String
    - contextPath: Core.OriginalAlert.event.referenced_resource_name
      description: Same as referenced_resource but provides only the substring that
        represents the resource name instead of the full asset ID.
      type: String
    - contextPath: Core.OriginalAlert.event.referenced_resources_count
      description: The number of extracted resources referenced in this audit log.
      type: Number
    - contextPath: Core.OriginalAlert.event.user_agent
      description: The user agent provided in the call to the API of the cloud provider.
      type: String
    - contextPath: Core.OriginalAlert.event.caller_ip
      description: The IP of the caller that performed the action in the log.
      type: String
    - contextPath: Core.OriginalAlert.event.caller_ip_geolocation
      description: The geolocation associated with the caller_ip's value.
      type: String
    - contextPath: Core.OriginalAlert.event.caller_ip_asn
      description: The ASN of the caller_ip's value.
      type: Number
    - contextPath: Core.OriginalAlert.event.caller_project
      description: The project of the caller entity.
      type: String
    - contextPath: Core.OriginalAlert.event.raw_log
      description: The raw log that is being normalized.
      type: Unknown
    - contextPath: Core.OriginalAlert.event.log_name
      description: The name of the log that contains the log row.
      type: String
    - contextPath: Core.OriginalAlert.event.caller_ip_asn_org
      description: The organization associated with the ASN of the caller_ip's value.
      type: String
    - contextPath: Core.OriginalAlert.event.event_base_id
      description: Event base ID.
      type: String
    - contextPath: Core.OriginalAlert.event.ingestion_time
      description: Ingestion time.
      type: String
  - arguments:
    - description: A comma-separated list of alert IDs.
      isArray: true
      name: alert_ids
      required: true
    - auto: PREDEFINED
      defaultValue: "true"
      description: Whether to return only a subset of the alert fields. Filtering
        the fields can reduce response size for large alerts.
      name: filter_alert_fields
      predefined:
      - "true"
      - "false"
    description: Returns dynamic analysis of each alert ID.
    name: core-get-dynamic-analysis
    outputs:
    - contextPath: Core.DynamicAnalysis.causalityId
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.name
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.factName
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.timestamp
      description: ""
      type: Date
    - contextPath: Core.DynamicAnalysis.internals.eventId
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.user_presence
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.shellcode_address
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.tid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.parent_pid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_sign
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.sync_action
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_remote_session
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.peb
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.process_image_path
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.command_line
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.scanned_buffer_crc32_stacktrace_allocation_base_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.page_base_shellcode_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.os_sig_status
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_info_legal_copyright
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.user_name
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_heavens_gate
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_impersonated
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.os_parent_instance_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_info_internal_name
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.stack_trace
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_injected
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.pid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.thread_context_eip_image_path
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.image_path_sha256
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.montepi_err
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_info_company_name
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_info_original_name
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.instance_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.yara_file_scan_result
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_obj_flags
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.should_obfuscate
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_size
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_info_is_dot_net
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.call_region_shellcode_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.allocation_base_shellcode_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.signer_name
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.original_command_line
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.yara_rules_results_stacktrace_page_base_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.rpc_interface_uuid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.rpc_interface_minor_version
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.telem
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_trusted_signer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.thread_context_eip
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.requested_parent_instance_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_cgo
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.parent_cid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.enabled_privileges
      description: ""
      type: Date
    - contextPath: Core.DynamicAnalysis.internals.attributes.peb32
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_embedded_sign
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.rpc_function_opnum
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.parent_thread_instance_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.remote_causality_actor_ip
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.canonized_process_image_path
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.scanned_buffer_crc32_stacktrace_call_region_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.yara_rules_results_stacktrace_allocation_base_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.entry_point_rva
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_stack_pivot
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.os_parent_pid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.image_path_md5
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.causality_actor_type
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.timestamp
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.is_in_transaction
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.cid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.integrity_level
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.actor_type
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_info_description
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.chisq_prob
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.parent_tid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.rpc_interface_major_version
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.dse_internal
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.telem_bit_mask
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.process_image_name
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.parent_instance_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.entropy
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.call_region_base_address
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.yara_rules_results_stacktrace_call_region_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.scanned_buffer_crc32_stacktrace_page_base_buffer
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.image_base
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.sync_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.effective_user_sid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.requested_parent_pid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.event_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.rpc_protocol
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.processIdx
      description: ""
      type: Number
    - contextPath: Core.DynamicAnalysis.internals.instanceId
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.scriptblock_text
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.script_path
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.actor_pid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.actor_instance_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.actor_thread_instance_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.etw_event_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.actor_tid
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.suspicious_strings
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.suspicious_strings_context
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.content_version
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.script_hash
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.dotnet_callstack
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.hook_type
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.appdomain_id
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.ps_assembly_version
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.original_length
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.invoke_expression_count
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.file_path
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.content
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.edr_assembly_version
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.expression_tree_scan_result
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.content_length
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.local_analysis_verdict
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.clr_version
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.powershell_version
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.script_source
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.prio
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.internals.attributes.build_timestamp
      description: ""
      type: Date
    - contextPath: Core.DynamicAnalysis.potentialPreventionActionOverride
      description: ""
      type: Boolean
    - contextPath: Core.DynamicAnalysis.isBiocRule
      description: ""
      type: Boolean
    - contextPath: Core.DynamicAnalysis.biocId
      description: ""
      type: Number
    - contextPath: Core.DynamicAnalysis.additionalData
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.biocRuleName
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.reachedMaxActivationsPerRule
      description: ""
      type: Boolean
    - contextPath: Core.DynamicAnalysis.syncActionStatus
      description: ""
      type: Number
    - contextPath: Core.DynamicAnalysis.spawnerImagePath
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.spawnerCmdline
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.spawnerSigner
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.osSpawnerImagePath
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.osSpawnerCmdline
      description: ""
      type: String
    - contextPath: Core.DynamicAnalysis.osSpawnerSigner
      description: ""
      type: String
  - arguments:
    - description: The sha256 of a file.
      isArray: true
      name: sha256
      required: true
    description: Get the prevalence of a file, identified by sha256.
    name: core-get-hash-analytics-prevalence
    outputs:
    - contextPath: Core.AnalyticsPrevalence.Hash.value
      description: Whether the hash is prevalent or not.
      type: Boolean
    - contextPath: Core.AnalyticsPrevalence.Hash.data.global_prevalence.value
      description: The global prevalence of the hash.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Hash.data.local_prevalence.value
      description: The local prevalence of the hash.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Hash.data.prevalence.value
      description: The prevalence of the hash.
      type: Number
  - arguments:
    - description: The IP address.
      isArray: true
      name: ip_address
      required: true
    description: Get the prevalence of an ip, identified by ip_address.
    name: core-get-IP-analytics-prevalence
    outputs:
    - contextPath: Core.AnalyticsPrevalence.Ip.value
      description: Whether the IP address is prevalent or not.
      type: Boolean
    - contextPath: Core.AnalyticsPrevalence.Ip.data.global_prevalence.value
      description: The global prevalence of the IP.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Ip.data.local_prevalence.value
      description: The local prevalence of the IP.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Ip.data.prevalence.value
      description: The prevalence of the IP.
      type: Number
  - arguments:
    - description: The domain name.
      isArray: true
      name: domain_name
      required: true
    description: Get the prevalence of a domain, identified by domain_name.
    name: core-get-domain-analytics-prevalence
    outputs:
    - contextPath: Core.AnalyticsPrevalence.Domain.value
      description: Whether the domain is prevalent or not.
      type: Boolean
    - contextPath: Core.AnalyticsPrevalence.Domain.data.global_prevalence.value
      description: The global prevalence of the domain.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Domain.data.local_prevalence.value
      description: The local prevalence of the domain.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Domain.data.prevalence.value
      description: The prevalence of the domain.
      type: Number
  - arguments:
    - description: The process name.
      isArray: true
      name: process_name
      required: true
    description: Get the prevalence of a process, identified by process_name.
    name: core-get-process-analytics-prevalence
    outputs:
    - contextPath: Core.AnalyticsPrevalence.Process.value
      description: Whether the process is prevalent or not.
      type: Boolean
    - contextPath: Core.AnalyticsPrevalence.Process.data.global_prevalence.value
      description: The global prevalence of the process.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Process.data.local_prevalence.value
      description: The local prevalence of the process.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Process.data.prevalence.value
      description: The prevalence of the process.
      type: Number
  - arguments:
    - description: The key name of a registry path.
      isArray: true
      name: key_name
      required: true
    - description: The value name of a registry path.
      isArray: true
      name: value_name
      required: true
    description: Get the prevalence of a registry_path, identified by key_name, value_name.
    name: core-get-registry-analytics-prevalence
    outputs:
    - contextPath: Core.AnalyticsPrevalence.Registry.value
      description: Whether the registry is prevalent or not.
      type: Boolean
    - contextPath: Core.AnalyticsPrevalence.Registry.data.global_prevalence.value
      description: The global prevalence of the registry.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Registry.data.local_prevalence.value
      description: The local prevalence of the registry.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Registry.data.prevalence.value
      description: The prevalence of the registry.
      type: Number
  - arguments:
    - description: The process command line.
      isArray: true
      name: process_command_line
      required: true
    description: Get the prevalence of a process_command_line, identified by process_command_line.
    name: core-get-cmd-analytics-prevalence
    outputs:
    - contextPath: Core.AnalyticsPrevalence.Cmd.value
      description: Whether the CMD is prevalent or not.
      type: Boolean
    - contextPath: Core.AnalyticsPrevalence.Cmd.data.global_prevalence.value
      description: The global prevalence of the CMD.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Cmd.data.local_prevalence.value
      description: The local prevalence of the CDM.
      type: Number
    - contextPath: Core.AnalyticsPrevalence.Cmd.data.prevalence.value
      description: The prevalence of the Cmd.
      type: Number
  - arguments:
    - description: A comma-separated list of tenant IDs of the endpoint(s) for which
        you want to assign the tag.
      isArray: true
      name: endpoint_ids
      required: true
    - description: The tag name to assign to the endpoint(s).
      name: tag
      required: true
    - description: A comma-separated list of endpoint IDs by which to filter the results.
      isArray: true
      name: endpoint_id_list
    - description: "A comma-separated list of distribution package names or installation
        package names. \nExample: dist_name1,dist_name2."
      isArray: true
      name: dist_name
    - description: |-
        A comma-separated list of IP addresses.
        Example: 8.8.8.8,1.1.1.1.
      isArray: true
      name: ip_list
    - description: |-
        A comma-separated list of group name to which the agent belongs.
        Example: group_name1,group_name2.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: The endpoint platform.
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: |-
        A comma-separated list of alias names.
        Examples: alias_name1,alias_name2.
      isArray: true
      name: alias_name
    - auto: PREDEFINED
      description: Specifies whether the endpoint was isolated or unisolated.
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: |-
        A comma-separated list of hostnames.
        Example: hostname1,hostname2.
      isArray: true
      name: hostname
    - description: |-
        All the agents that were first seen after {first_seen_gte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_gte
    - description: |-
        All the agents that were first seen before {first_seen_lte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_lte
    - description: |-
        All the agents that were last seen before {last_seen_gte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_gte
    - description: |-
        All the agents that were last seen before {last_seen_lte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_lte
    - auto: PREDEFINED
      description: The status of the endpoint to filter.
      name: status
      predefined:
      - connected
      - disconnected
      - lost
      - uninstalled
    description: Add a tag to one or more endpoints.
    name: core-add-endpoint-tag
  - arguments:
    - description: A comma-separated list of tenant IDs of the endpoint(s) for which
        you want to remove the tag.
      isArray: true
      name: endpoint_ids
      required: true
    - description: The tag name to remove from the endpoint(s).
      name: tag
      required: true
    - description: A comma-separated list of endpoint IDs to filter by them.
      isArray: true
      name: endpoint_id_list
    - description: "A comma-separated list of distribution package names or installation
        package names. \nExample: dist_name1,dist_name2."
      isArray: true
      name: dist_name
    - description: |-
        A comma-separated list of IP addresses.
        Example: 8.8.8.8,1.1.1.1.
      isArray: true
      name: ip_list
    - description: |-
        A comma-separated list of group names to which the agent belongs.
        Example: group_name1,group_name2.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: The endpoint platform.
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: |-
        A comma-separated list of alias names.
        Examples: alias_name1,alias_name2.
      isArray: true
      name: alias_name
    - auto: PREDEFINED
      description: Specifies whether the endpoint was isolated or unisolated.
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: |-
        A comma-separated list of hostnames.
        Example: hostname1,hostname2.
      isArray: true
      name: hostname
    - description: |-
        All the agents that were first seen after {first_seen_gte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_gte
    - description: |-
        All the agents that were first seen before {first_seen_lte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: first_seen_lte
    - description: |-
        All the agents that were last seen before {last_seen_gte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_gte
    - description: |-
        All the agents that were last seen before {last_seen_lte}.
        Supported values:
        1579039377301 (time in milliseconds)
        "3 days" (relative date)
        "2019-10-21T23:45:00" (date).
      name: last_seen_lte
    - auto: PREDEFINED
      description: The status of the endpoint to filter.
      name: status
      predefined:
      - connected
      - disconnected
      - lost
      - uninstalled
    description: Remove a tag from one or more endpoints.
    name: core-remove-endpoint-tag
  - arguments: []
    description: Retrieve a list of the current users in your environment.
    name: core-list-users
    outputs:
    - contextPath: Core.User.user_email
      description: Email address of the user.
      type: string
    - contextPath: Core.User.user_first_name
      description: First name of the user.
      type: string
    - contextPath: Core.User.user_last_name
      description: Last name of the user.
      type: string
    - contextPath: Core.User.role_name
      description: Role name associated with the user.
      type: string
    - contextPath: Core.User.last_logged_in
      description: Timestamp of when the user last logged in.
      type: Number
    - contextPath: Core.User.user_type
      description: Type of user.
      type: string
    - contextPath: Core.User.groups
      description: Name of user groups associated with the user, if applicable.
      type: array
    - contextPath: Core.User.scope
      description: Name of scope associated with the user, if applicable.
      type: array
  - arguments:
    - description: |
        Unique ID of a specific user.
        User ID could be either of the `foo/dummy` format, or just `dummy`.
      name: user_id
    - defaultValue: "50"
      description: Limit the number of users that will appear in the list. (limit
        should be used when no specific host is requested).
      name: limit
    description: Retrieve the risk score of a specific user or list of users with
      the highest risk score in the environment along with the reason affecting each
      score.
    name: core-list-risky-users
    outputs:
    - contextPath: Core.RiskyUser.type
      description: Form of identification element.
      type: String
    - contextPath: Core.RiskyUser.id
      description: Identification value of the type field.
      type: String
    - contextPath: Core.RiskyUser.score
      description: The score assigned to the user.
      type: Integer
    - contextPath: Core.RiskyUser.reasons.date created
      description: Date when the incident was created.
      type: String
    - contextPath: Core.RiskyUser.reasons.description
      description: Description of the incident.
      type: String
    - contextPath: Core.RiskyUser.reasons.severity
      description: The severity of the incident.
      type: String
    - contextPath: Core.RiskyUser.reasons.status
      description: The incident status.
      type: String
    - contextPath: Core.RiskyUser.reasons.points
      description: The score.
      type: Number
  - arguments:
    - description: |
        Unique ID of a specific host.
      name: host_id
    - defaultValue: "50"
      description: Limit the number of hosts that will appear in the list. (Use limit
        when no specific host is requested).
      name: limit
    description: Retrieve the risk score of a specific host or list of hosts with
      the highest risk score in the environment along with the reason affecting each
      score.
    name: core-list-risky-hosts
    outputs:
    - contextPath: Core.RiskyHost.type
      description: Form of identification element.
      type: String
    - contextPath: Core.RiskyHost.id
      description: Identification value of the type field.
      type: String
    - contextPath: Core.RiskyHost.score
      description: The score assigned to the host.
      type: Integer
    - contextPath: Core.RiskyHost.reasons.date created
      description: Date when the incident was created.
      type: String
    - contextPath: Core.RiskyHost.reasons.description
      description: Description of the incident.
      type: String
    - contextPath: Core.RiskyHost.reasons.severity
      description: The severity of the incident.
      type: String
    - contextPath: Core.RiskyHost.reasons.status
      description: The incident status.
      type: String
    - contextPath: Core.RiskyHost.reasons.points
      description: The score.
      type: Number
  - arguments:
    - description: A comma-separated list of one or more user group names for which
        you want the associated users.
      isArray: true
      name: group_names
      required: true
    description: Retrieve a list of the current user emails associated with one or
      more user groups in your environment.
    name: core-list-user-groups
    outputs:
    - contextPath: Core.UserGroup.group_name
      description: Name of the user group.
      type: String
    - contextPath: Core.UserGroup.description
      description: Description of the user group, if available.
      type: String
    - contextPath: Core.UserGroup.pretty_name
      description: Name of the user group as it appears in the management console.
      type: String
    - contextPath: Core.UserGroup.insert_time
      description: Timestamp of when the user group was created.
      type: Number
    - contextPath: Core.UserGroup.update_time
      description: Timestamp of when the user group was last updated.
      type: Number
    - contextPath: Core.UserGroup.user_email
      description: List of email addresses belonging to the users associated with
        the user group.
      type: array
    - contextPath: Core.UserGroup.source
      description: Type of user group.
      type: String
  dockerimage: demisto/python3:3.10.13.85667
  nativeimage:
  - "8.6"
  runonce: false
  script: |
    register_module_line('Cortex Core - IR', 'start', __line__())
    ### pack version: 3.0.21



    ### GENERATED CODE ###: from CoreIRApiModule import *
    # This code was inserted in place of an API module.
    register_module_line('CoreIRApiModule', 'start', __line__(), wrapper=-3)


    import urllib3
    import copy
    import re
    from operator import itemgetter

    from typing import Tuple, Callable

    # Disable insecure warnings
    urllib3.disable_warnings()
    TIME_FORMAT = "%Y-%m-%dT%H:%M:%S"

    XSOAR_RESOLVED_STATUS_TO_XDR = {
        'Other': 'resolved_other',
        'Duplicate': 'resolved_duplicate',
        'False Positive': 'resolved_false_positive',
        'Resolved': 'resolved_true_positive',
        'Resolved - Security Testing': 'resolved_security_testing',
    }

    XDR_RESOLVED_STATUS_TO_XSOAR = {
        'resolved_known_issue': 'Other',
        'resolved_duplicate': 'Duplicate',
        'resolved_false_positive': 'False Positive',
        'resolved_true_positive': 'Resolved',
        'resolved_security_testing': 'Resolved - Security Testing',
        'resolved_other': 'Other',
        'resolved_auto': 'Resolved'
    }

    ALERT_GENERAL_FIELDS = {
        'detection_modules',
        'alert_full_description',
        'matching_service_rule_id',
        'variation_rule_id',
        'content_version',
        'detector_id',
        'mitre_technique_id_and_name',
        'silent',
        'mitre_technique_ids',
        'activity_first_seet_at',
        '_type',
        'dst_association_strength',
        'alert_description',
    }

    ALERT_EVENT_GENERAL_FIELDS = {
        "_time",
        "vendor",
        "event_timestamp",
        "event_type",
        "event_id",
        "cloud_provider",
        "project",
        "cloud_provider_event_id",
        "cloud_correlation_id",
        "operation_name_orig",
        "operation_name",
        "identity_orig",
        "identity_name",
        "identity_uuid",
        "identity_type",
        "identity_sub_type",
        "identity_invoked_by_name",
        "identity_invoked_by_uuid",
        "identity_invoked_by_type",
        "identity_invoked_by_sub_type",
        "operation_status",
        "operation_status_orig",
        "operation_status_orig_code",
        "operation_status_reason_provided",
        "resource_type",
        "resource_type_orig",
        "resource_sub_type",
        "resource_sub_type_orig",
        "region",
        "zone",
        "referenced_resource",
        "referenced_resource_name",
        "referenced_resources_count",
        "user_agent",
        "caller_ip",
        'caller_ip_geolocation',
        "caller_ip_asn",
        'caller_project',
        'raw_log',
        "log_name",
        "caller_ip_asn_org",
        "event_base_id",
        "ingestion_time",
    }

    ALERT_EVENT_AWS_FIELDS = {
        "eventVersion",
        "userIdentity",
        "eventTime",
        "eventSource",
        "eventName",
        "awsRegion",
        "sourceIPAddress",
        "userAgent",
        "requestID",
        "eventID",
        "readOnly",
        "eventType",
        "apiVersion",
        "managementEvent",
        "recipientAccountId",
        "eventCategory",
        "errorCode",
        "errorMessage",
        "resources",
    }

    ALERT_EVENT_GCP_FIELDS = {
        "labels",
        "operation",
        "protoPayload",
        "resource",
        "severity",
        "timestamp",
    }

    ALERT_EVENT_AZURE_FIELDS = {
        "time",
        "resourceId",
        "category",
        "operationName",
        "operationVersion",
        "schemaVersion",
        "statusCode",
        "statusText",
        "callerIpAddress",
        "correlationId",
        "identity",
        "level",
        "properties",
        "uri",
        "protocol",
        "resourceType",
        "tenantId",
    }


    class CoreClient(BaseClient):

        def __init__(self, base_url: str, headers: dict, timeout: int = 120, proxy: bool = False, verify: bool = False):
            super().__init__(base_url=base_url, headers=headers, proxy=proxy, verify=verify)
            self.timeout = timeout

        def get_incidents(self, incident_id_list=None, lte_modification_time=None, gte_modification_time=None,
                          lte_creation_time=None, gte_creation_time=None, status=None, starred=None,
                          starred_incidents_fetch_window=None, sort_by_modification_time=None, sort_by_creation_time=None,
                          page_number=0, limit=100, gte_creation_time_milliseconds=0):
            """
            Filters and returns incidents

            :param incident_id_list: List of incident ids - must be list
            :param lte_modification_time: string of time format "2019-12-31T23:59:00"
            :param gte_modification_time: string of time format "2019-12-31T23:59:00"
            :param lte_creation_time: string of time format "2019-12-31T23:59:00"
            :param gte_creation_time: string of time format "2019-12-31T23:59:00"
            :param starred_incidents_fetch_window: string of time format "2019-12-31T23:59:00"
            :param starred: True if the incident is starred, else False
            :param status: string of status
            :param sort_by_modification_time: optional - enum (asc,desc)
            :param sort_by_creation_time: optional - enum (asc,desc)
            :param page_number: page number
            :param limit: maximum number of incidents to return per page
            :param gte_creation_time_milliseconds: greater than time in milliseconds
            :return:
            """
            search_from = page_number * limit
            search_to = search_from + limit

            request_data = {
                'search_from': search_from,
                'search_to': search_to,
            }

            if sort_by_creation_time and sort_by_modification_time:
                raise ValueError('Should be provide either sort_by_creation_time or '
                                 'sort_by_modification_time. Can\'t provide both')
            if sort_by_creation_time:
                request_data['sort'] = {
                    'field': 'creation_time',
                    'keyword': sort_by_creation_time
                }
            elif sort_by_modification_time:
                request_data['sort'] = {
                    'field': 'modification_time',
                    'keyword': sort_by_modification_time
                }

            filters = []
            if incident_id_list is not None and len(incident_id_list) > 0:
                filters.append({
                    'field': 'incident_id_list',
                    'operator': 'in',
                    'value': incident_id_list
                })

            if status:
                filters.append({
                    'field': 'status',
                    'operator': 'eq',
                    'value': status
                })

            if starred and starred_incidents_fetch_window:
                filters.append({
                    'field': 'starred',
                    'operator': 'eq',
                    'value': True
                })
                filters.append({
                    'field': 'creation_time',
                    'operator': 'gte',
                    'value': starred_incidents_fetch_window
                })
                if demisto.command() == 'fetch-incidents':
                    if len(filters) > 0:
                        request_data['filters'] = filters
                    incidents = self.handle_fetch_starred_incidents(limit, page_number, request_data)
                    return incidents

            else:
                if lte_creation_time:
                    filters.append({
                        'field': 'creation_time',
                        'operator': 'lte',
                        'value': date_to_timestamp(lte_creation_time, TIME_FORMAT)
                    })

                if gte_creation_time:
                    filters.append({
                        'field': 'creation_time',
                        'operator': 'gte',
                        'value': date_to_timestamp(gte_creation_time, TIME_FORMAT)
                    })

                if lte_modification_time:
                    filters.append({
                        'field': 'modification_time',
                        'operator': 'lte',
                        'value': date_to_timestamp(lte_modification_time, TIME_FORMAT)
                    })

                if gte_modification_time:
                    filters.append({
                        'field': 'modification_time',
                        'operator': 'gte',
                        'value': date_to_timestamp(gte_modification_time, TIME_FORMAT)
                    })

                if gte_creation_time_milliseconds > 0:
                    filters.append({
                        'field': 'creation_time',
                        'operator': 'gte',
                        'value': gte_creation_time_milliseconds
                    })

            if len(filters) > 0:
                request_data['filters'] = filters

            res = self._http_request(
                method='POST',
                url_suffix='/incidents/get_incidents/',
                json_data={'request_data': request_data},
                headers=self._headers,
                timeout=self.timeout
            )
            incidents = res.get('reply', {}).get('incidents', [])

            return incidents

        def handle_fetch_starred_incidents(self, limit: int, page_number: int, request_data: Dict[Any, Any]) -> List[Any]:
            """Called from get_incidents if the command is fetch-incidents. Implement in child classes."""
            return []

        def get_endpoints(self,
                          endpoint_id_list=None,
                          dist_name=None,
                          ip_list=None,
                          public_ip_list=None,
                          group_name=None,
                          platform=None,
                          alias_name=None,
                          isolate=None,
                          hostname=None,
                          page_number=0,
                          limit=30,
                          first_seen_gte=None,
                          first_seen_lte=None,
                          last_seen_gte=None,
                          last_seen_lte=None,
                          sort_by_first_seen=None,
                          sort_by_last_seen=None,
                          status=None,
                          username=None
                          ):

            search_from = page_number * limit
            search_to = search_from + limit

            request_data = {
                'search_from': search_from,
                'search_to': search_to,
            }

            filters = create_request_filters(
                status=status, username=username, endpoint_id_list=endpoint_id_list, dist_name=dist_name,
                ip_list=ip_list, group_name=group_name, platform=platform, alias_name=alias_name, isolate=isolate,
                hostname=hostname, first_seen_gte=first_seen_gte, first_seen_lte=first_seen_lte,
                last_seen_gte=last_seen_gte, last_seen_lte=last_seen_lte, public_ip_list=public_ip_list
            )

            if search_from:
                request_data['search_from'] = search_from

            if search_to:
                request_data['search_to'] = search_to

            if sort_by_first_seen:
                request_data['sort'] = {
                    'field': 'first_seen',
                    'keyword': sort_by_first_seen
                }
            elif sort_by_last_seen:
                request_data['sort'] = {
                    'field': 'last_seen',
                    'keyword': sort_by_last_seen
                }

            request_data['filters'] = filters

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/get_endpoint/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            demisto.debug(f"get_endpoints response = {reply}")

            endpoints = reply.get('reply').get('endpoints', [])
            return endpoints

        def set_endpoints_alias(self, filters: list[dict[str, str]], new_alias_name: str | None) -> dict:      # pragma: no cover
            """
            This func is used to set the alias name of an endpoint.

            args:
                filters: list of filters to get the endpoints
                new_alias_name: the new alias name to set

            returns: dict of the response(True if success else error message)
            """

            request_data = {'filters': filters, 'alias': new_alias_name}

            return self._http_request(
                method='POST',
                url_suffix='/endpoints/update_agent_name/',
                json_data={'request_data': request_data},
                timeout=self.timeout,
            )

        def isolate_endpoint(self, endpoint_id, incident_id=None):
            request_data = {
                'endpoint_id': endpoint_id,
            }
            if incident_id:
                request_data['incident_id'] = incident_id

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/isolate',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return reply.get('reply')

        def unisolate_endpoint(self, endpoint_id, incident_id=None):
            request_data = {
                'endpoint_id': endpoint_id,
            }
            if incident_id:
                request_data['incident_id'] = incident_id

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/unisolate',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return reply.get('reply')

        def insert_alerts(self, alerts):
            self._http_request(
                method='POST',
                url_suffix='/alerts/insert_parsed_alerts/',
                json_data={
                    'request_data': {
                        'alerts': alerts
                    }
                },
                timeout=self.timeout
            )

        def insert_cef_alerts(self, alerts):
            self._http_request(
                method='POST',
                url_suffix='/alerts/insert_cef_alerts/',
                json_data={
                    'request_data': {
                        'alerts': alerts
                    }
                },
                timeout=self.timeout
            )

        def get_distribution_url(self, distribution_id, package_type):
            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/get_dist_url/',
                json_data={
                    'request_data': {
                        'distribution_id': distribution_id,
                        'package_type': package_type
                    }
                },
                timeout=self.timeout
            )

            return reply.get('reply').get('distribution_url')

        def get_distribution_status(self, distribution_id):
            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/get_status/',
                json_data={
                    'request_data': {
                        'distribution_id': distribution_id
                    }
                },
                timeout=self.timeout
            )

            return reply.get('reply').get('status')

        def get_distribution_versions(self):
            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/get_versions/',
                json_data={},
                timeout=self.timeout
            )

            return reply.get('reply')

        def create_distribution(self, name, platform, package_type, agent_version, description):
            request_data = {}
            if package_type == 'standalone':
                request_data = {
                    'name': name,
                    'platform': platform,
                    'package_type': package_type,
                    'agent_version': agent_version,
                    'description': description,
                }
            elif package_type == 'upgrade':
                request_data = {
                    'name': name,
                    'package_type': package_type,
                    'description': description,
                }

                if platform == 'windows':
                    request_data['windows_version'] = agent_version
                elif platform == 'linux':
                    request_data['linux_version'] = agent_version
                elif platform == 'macos':
                    request_data['macos_version'] = agent_version

            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/create/',
                json_data={
                    'request_data': request_data
                },
                timeout=self.timeout
            )

            return reply.get('reply').get('distribution_id')

        def audit_management_logs(self, email, result, _type, sub_type, search_from, search_to, timestamp_gte,
                                  timestamp_lte, sort_by, sort_order):

            request_data: Dict[str, Any] = {}
            filters = []
            if email:
                filters.append({
                    'field': 'email',
                    'operator': 'in',
                    'value': email
                })
            if result:
                filters.append({
                    'field': 'result',
                    'operator': 'in',
                    'value': result
                })
            if _type:
                filters.append({
                    'field': 'type',
                    'operator': 'in',
                    'value': _type
                })
            if sub_type:
                filters.append({
                    'field': 'sub_type',
                    'operator': 'in',
                    'value': sub_type
                })
            if timestamp_gte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'gte',
                    'value': timestamp_gte
                })
            if timestamp_lte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'lte',
                    'value': timestamp_lte
                })

            if filters:
                request_data['filters'] = filters

            if search_from > 0:
                request_data['search_from'] = search_from

            if search_to:
                request_data['search_to'] = search_to

            if sort_by:
                request_data['sort'] = {
                    'field': sort_by,
                    'keyword': sort_order
                }

            reply = self._http_request(
                method='POST',
                url_suffix='/audits/management_logs/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply').get('data', [])

        def get_audit_agent_reports(self, endpoint_ids, endpoint_names, result, _type, sub_type, search_from, search_to,
                                    timestamp_gte, timestamp_lte, sort_by, sort_order):
            request_data: Dict[str, Any] = {}
            filters = []
            if endpoint_ids:
                filters.append({
                    'field': 'endpoint_id',
                    'operator': 'in',
                    'value': endpoint_ids
                })
            if endpoint_names:
                filters.append({
                    'field': 'endpoint_name',
                    'operator': 'in',
                    'value': endpoint_names
                })
            if result:
                filters.append({
                    'field': 'result',
                    'operator': 'in',
                    'value': result
                })
            if _type:
                filters.append({
                    'field': 'type',
                    'operator': 'in',
                    'value': _type
                })
            if sub_type:
                filters.append({
                    'field': 'sub_type',
                    'operator': 'in',
                    'value': sub_type
                })
            if timestamp_gte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'gte',
                    'value': timestamp_gte
                })
            if timestamp_lte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'lte',
                    'value': timestamp_lte
                })

            if filters:
                request_data['filters'] = filters

            if search_from > 0:
                request_data['search_from'] = search_from

            if search_to:
                request_data['search_to'] = search_to

            if sort_by:
                request_data['sort'] = {
                    'field': sort_by,
                    'keyword': sort_order
                }

            reply = self._http_request(
                method='POST',
                url_suffix='/audits/agents_reports/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply').get('data', [])

        def blocklist_files(self, hash_list, comment=None, incident_id=None, detailed_response=False):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id
            if detailed_response:
                request_data['detailed_response'] = detailed_response

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/blocklist/',
                json_data={'request_data': request_data},
                ok_codes=(200, 201, 500,),
                timeout=self.timeout
            )
            return reply.get('reply')

        def remove_blocklist_files(self, hash_list, comment=None, incident_id=None):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/blocklist/remove/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return reply.get('reply')

        def allowlist_files(self, hash_list, comment=None, incident_id=None, detailed_response=False):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id
            if detailed_response:
                request_data['detailed_response'] = detailed_response

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/allowlist/',
                json_data={'request_data': request_data},
                ok_codes=(201, 200),
                timeout=self.timeout
            )
            return reply.get('reply')

        def remove_allowlist_files(self, hash_list, comment=None, incident_id=None):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/allowlist/remove/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return reply.get('reply')

        def quarantine_files(self, endpoint_id_list, file_path, file_hash, incident_id):
            request_data: Dict[str, Any] = {}
            filters = []
            if endpoint_id_list:
                filters.append({
                    'field': 'endpoint_id_list',
                    'operator': 'in',
                    'value': endpoint_id_list
                })

            if filters:
                request_data['filters'] = filters

            request_data['file_path'] = file_path
            request_data['file_hash'] = file_hash
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/quarantine/',
                json_data={'request_data': request_data},
                ok_codes=(200, 201),
                timeout=self.timeout
            )

            return reply.get('reply')

        def restore_file(self, file_hash, endpoint_id=None, incident_id=None):
            request_data: Dict[str, Any] = {'file_hash': file_hash}
            if incident_id:
                request_data['incident_id'] = incident_id
            if endpoint_id:
                request_data['endpoint_id'] = endpoint_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/restore/',
                json_data={'request_data': request_data},
                ok_codes=(200, 201),
                timeout=self.timeout
            )
            return reply.get('reply')

        def endpoint_scan(self, url_suffix, endpoint_id_list=None, dist_name=None, gte_first_seen=None, gte_last_seen=None,
                          lte_first_seen=None,
                          lte_last_seen=None, ip_list=None, group_name=None, platform=None, alias=None, isolate=None,
                          hostname: list = None, incident_id=None):
            request_data: Dict[str, Any] = {}
            filters = []

            if endpoint_id_list:
                filters.append({
                    'field': 'endpoint_id_list',
                    'operator': 'in',
                    'value': endpoint_id_list
                })

            if dist_name:
                filters.append({
                    'field': 'dist_name',
                    'operator': 'in',
                    'value': dist_name
                })

            if ip_list:
                filters.append({
                    'field': 'ip_list',
                    'operator': 'in',
                    'value': ip_list
                })

            if group_name:
                filters.append({
                    'field': 'group_name',
                    'operator': 'in',
                    'value': group_name
                })

            if platform:
                filters.append({
                    'field': 'platform',
                    'operator': 'in',
                    'value': platform
                })

            if alias:
                filters.append({
                    'field': 'alias',
                    'operator': 'in',
                    'value': alias
                })

            if isolate:
                filters.append({
                    'field': 'isolate',
                    'operator': 'in',
                    'value': [isolate]
                })

            if hostname:
                filters.append({
                    'field': 'hostname',
                    'operator': 'in',
                    'value': hostname
                })

            if gte_first_seen:
                filters.append({
                    'field': 'first_seen',
                    'operator': 'gte',
                    'value': gte_first_seen
                })

            if lte_first_seen:
                filters.append({
                    'field': 'first_seen',
                    'operator': 'lte',
                    'value': lte_first_seen
                })

            if gte_last_seen:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'gte',
                    'value': gte_last_seen
                })

            if lte_last_seen:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'lte',
                    'value': lte_last_seen
                })

            if filters:
                request_data['filters'] = filters
            else:
                request_data['filters'] = 'all'
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix=url_suffix,
                json_data={'request_data': request_data},
                ok_codes=(200, 201),
                timeout=self.timeout
            )
            return reply.get('reply')

        def get_quarantine_status(self, file_path, file_hash, endpoint_id):
            request_data: Dict[str, Any] = {'files': [{
                'endpoint_id': endpoint_id,
                'file_path': file_path,
                'file_hash': file_hash
            }]}
            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/quarantine/status/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            reply_content = reply.get('reply')
            if isinstance(reply_content, list):
                return reply_content[0]
            else:
                raise TypeError(f'got unexpected response from api: {reply_content}\n')

        def delete_endpoints(self, endpoint_ids: list):
            request_data: Dict[str, Any] = {
                'filters': [
                    {
                        'field': 'endpoint_id_list',
                        'operator': 'in',
                        'value': endpoint_ids
                    }
                ]
            }

            self._http_request(
                method='POST',
                url_suffix='/endpoints/delete/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

        def get_policy(self, endpoint_id) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'endpoint_id': endpoint_id
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/get_policy/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def get_original_alerts(self, alert_id_list):
            res = self._http_request(
                method='POST',
                url_suffix='/alerts/get_original_alerts/',
                json_data={
                    'request_data': {
                        'alert_id_list': alert_id_list,
                    }
                },
            )
            return res.get('reply', {})

        def get_alerts_by_filter_data(self, request_data: dict):
            res = self._http_request(
                method='POST',
                url_suffix='/alerts/get_alerts_by_filter_data/',
                json_data={
                    'request_data': request_data
                },
            )
            return res.get('reply', {})

        def get_endpoint_device_control_violations(self, endpoint_ids: list, type_of_violation, timestamp_gte: int,
                                                   timestamp_lte: int,
                                                   ip_list: list, vendor: list, vendor_id: list, product: list,
                                                   product_id: list,
                                                   serial: list,
                                                   hostname: list, violation_ids: list, username: list) \
                -> Dict[str, Any]:
            arg_list = {'type': type_of_violation,
                        'endpoint_id_list': endpoint_ids,
                        'ip_list': ip_list,
                        'vendor': vendor,
                        'vendor_id': vendor_id,
                        'product': product,
                        'product_id': product_id,
                        'serial': serial,
                        'hostname': hostname,
                        'violation_id_list': violation_ids,
                        'username': username
                        }

            filters: list = [{
                'field': arg_key,
                'operator': 'in',
                'value': arg_val
            } for arg_key, arg_val in arg_list.items() if arg_val and arg_val[0]]

            if timestamp_lte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'lte',
                    'value': timestamp_lte
                })
            if timestamp_gte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'gte',
                    'value': timestamp_gte})

            request_data: Dict[str, Any] = {
                'filters': filters
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/device_control/get_violations/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def generate_files_dict_with_specific_os(self, windows: list, linux: list, macos: list) -> Dict[str, list]:
            if not windows and not linux and not macos:
                raise ValueError('You should enter at least one path.')

            files = {}
            if windows:
                files['windows'] = windows
            if linux:
                files['linux'] = linux
            if macos:
                files['macos'] = macos

            return files

        def retrieve_file(self, endpoint_id_list: list, windows: list, linux: list, macos: list, file_path_list: list,
                          incident_id: Optional[int]) -> Dict[str, Any]:
            # there are 2 options, either the paths are given with separation to a specific os or without
            # it using generic_file_path
            if file_path_list:
                files = self.generate_files_dict(
                    endpoint_id_list=endpoint_id_list,
                    file_path_list=file_path_list
                )
            else:
                files = self.generate_files_dict_with_specific_os(windows=windows, linux=linux, macos=macos)

            request_data: Dict[str, Any] = {
                'filters': [
                    {
                        'field': 'endpoint_id_list',
                        'operator': 'in',
                        'value': endpoint_id_list
                    }
                ],
                'files': files,
            }
            if incident_id:
                request_data['incident_id'] = incident_id

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/file_retrieval/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            demisto.debug(f"retrieve_file = {reply}")

            return reply.get('reply')

        def generate_files_dict(self, endpoint_id_list: list, file_path_list: list) -> Dict[str, Any]:
            files: dict = {"windows": [], "linux": [], "macos": []}

            if len(endpoint_id_list) != len(file_path_list):
                raise ValueError("The endpoint_ids list must be in the same length as the generic_file_path")

            for endpoint_id, file_path in zip(endpoint_id_list, file_path_list):
                endpoints = self.get_endpoints(endpoint_id_list=[endpoint_id])

                if len(endpoints) == 0 or not isinstance(endpoints, list):
                    raise ValueError(f'Error: Endpoint {endpoint_id} was not found')

                endpoint = endpoints[0]
                endpoint_os_type = endpoint.get('os_type')

                if 'windows' in endpoint_os_type.lower():
                    files['windows'].append(file_path)
                elif 'linux' in endpoint_os_type.lower():
                    files['linux'].append(file_path)
                elif 'mac' in endpoint_os_type.lower():
                    files['macos'].append(file_path)

            # remove keys with no value
            files = {k: v for k, v in files.items() if v}

            return files

        def retrieve_file_details(self, action_id: int) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'group_action_id': action_id
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/actions/file_retrieval_details/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            demisto.debug(f"retrieve_file_details = {reply}")

            return reply.get('reply').get('data')

        @logger
        def get_scripts(self, name: list, description: list, created_by: list, windows_supported,
                        linux_supported, macos_supported, is_high_risk) -> Dict[str, Any]:

            arg_list = {'name': name,
                        'description': description,
                        'created_by': created_by,
                        'windows_supported': windows_supported,
                        'linux_supported': linux_supported,
                        'macos_supported': macos_supported,
                        'is_high_risk': is_high_risk
                        }

            filters: list = [{
                'field': arg_key,
                'operator': 'in',
                'value': arg_val
            } for arg_key, arg_val in arg_list.items() if arg_val and arg_val[0]]

            request_data: Dict[str, Any] = {
                'filters': filters
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/scripts/get_scripts/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def get_script_metadata(self, script_uid) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'script_uid': script_uid
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_metadata/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def get_script_code(self, script_uid) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'script_uid': script_uid
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_code/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        @logger
        def run_script(self,
                       script_uid: str, endpoint_ids: list, parameters: Dict[str, Any], timeout: int, incident_id: Optional[int],
                       ) -> Dict[str, Any]:
            filters: list = [{
                'field': 'endpoint_id_list',
                'operator': 'in',
                'value': endpoint_ids
            }]
            request_data: Dict[str, Any] = {'script_uid': script_uid, 'timeout': timeout, 'filters': filters,
                                            'parameters_values': parameters}
            if incident_id:
                request_data['incident_id'] = incident_id

            return self._http_request(
                method='POST',
                url_suffix='/scripts/run_script/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

        @logger
        def run_snippet_code_script(self, snippet_code: str, endpoint_ids: list,
                                    incident_id: Optional[int] = None) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'filters': [{
                    'field': 'endpoint_id_list',
                    'operator': 'in',
                    'value': endpoint_ids
                }],
                'snippet_code': snippet_code,
            }

            if incident_id:
                request_data['incident_id'] = incident_id

            return self._http_request(
                method='POST',
                url_suffix='/scripts/run_snippet_code_script',
                json_data={
                    'request_data': request_data
                },
                timeout=self.timeout,
            )

        @logger
        def get_script_execution_status(self, action_id: str) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'action_id': action_id
            }

            return self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_execution_status/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

        @logger
        def get_script_execution_results(self, action_id: str) -> Dict[str, Any]:
            return self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_execution_results',
                json_data={
                    'request_data': {
                        'action_id': action_id
                    }
                },
                timeout=self.timeout,
            )

        @logger
        def get_script_execution_result_files(self, action_id: str, endpoint_id: str) -> Dict[str, Any]:
            response = self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_execution_results_files',
                json_data={
                    'request_data': {
                        'action_id': action_id,
                        'endpoint_id': endpoint_id,
                    }
                },
                timeout=self.timeout,
            )
            link = response.get('reply', {}).get('DATA')
            demisto.debug(f"From the previous API call, this link was returned {link=}")
            # If the link is None, the API call will result in a 'Connection Timeout Error', so we raise an exception
            if not link:
                raise DemistoException(f'Failed getting response files for {action_id=}, {endpoint_id=}')
            return self._http_request(
                method='GET',
                url_suffix=re.findall('download.*', link)[0],
                resp_type='response',
            )

        def action_status_get(self, action_id) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'group_action_id': action_id,
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/actions/get_action_status/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            demisto.debug(f"action_status_get = {reply}")

            return reply.get('reply').get('data')

        @logger
        def get_file(self, file_link):
            reply = self._http_request(
                method='GET',
                full_url=file_link,
                timeout=self.timeout,
                resp_type='content'
            )
            return reply

        def get_file_by_url_suffix(self, url_suffix):
            reply = self._http_request(
                method='GET',
                url_suffix=url_suffix,
                timeout=self.timeout,
                resp_type='content'
            )
            return reply

        @logger
        def get_endpoints_by_status(self, status, last_seen_gte=None, last_seen_lte=None):
            filters = []

            if not isinstance(status, list):
                status = [status]

            filters.append({
                'field': 'endpoint_status',
                'operator': 'IN',
                'value': status
            })

            if last_seen_gte:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'gte',
                    'value': last_seen_gte
                })

            if last_seen_lte:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'lte',
                    'value': last_seen_lte
                })

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/get_endpoint/',
                json_data={'request_data': {'filters': filters}},
                timeout=self.timeout
            )

            endpoints_count = reply.get('reply').get('total_count', 0)
            return endpoints_count, reply

        def add_exclusion(self, indicator, name, status="ENABLED", comment=None):
            request_data: Dict[str, Any] = {
                'indicator': indicator,
                'status': status,
                'name': name
            }

            res = self._http_request(
                method='POST',
                url_suffix='/alerts_exclusion/add/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return res.get("reply")

        def delete_exclusion(self, alert_exclusion_id: int):
            request_data: Dict[str, Any] = {
                'alert_exclusion_id': alert_exclusion_id,
            }

            res = self._http_request(
                method='POST',
                url_suffix='/alerts_exclusion/delete/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return res.get("reply")

        def get_exclusion(self, limit, tenant_id=None, filter=None):
            request_data: Dict[str, Any] = {}
            if tenant_id:
                request_data['tenant_id'] = tenant_id
            if filter:
                request_data['filter_data'] = filter
            res = self._http_request(
                method='POST',
                url_suffix='/alerts_exclusion/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            reply = res.get("reply")
            return reply[:limit]

        def add_tag_endpoint(self, endpoint_ids, tag, args):
            """
            Add tag to an endpoint
            """
            return self.call_tag_endpoint(endpoint_ids=endpoint_ids, tag=tag, args=args, url_suffix='/tags/agents/assign/')

        def remove_tag_endpoint(self, endpoint_ids, tag, args):
            """
            Remove tag from an endpoint.
            """
            return self.call_tag_endpoint(endpoint_ids=endpoint_ids, tag=tag, args=args, url_suffix='/tags/agents/remove/')

        def call_tag_endpoint(self, endpoint_ids, tag, args, url_suffix):
            """
            Add or remove a tag from an endpoint.
            """
            filters = args_to_request_filters(args)

            body_request = {
                'context': {
                    'lcaas_id': endpoint_ids,
                },
                'request_data': {
                    'filters': filters,
                    'tag': tag
                },
            }

            return self._http_request(
                method='POST',
                url_suffix=url_suffix,
                json_data=body_request,
                timeout=self.timeout
            )

        def list_users(self) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/get_users/',
                json_data={"request_data": {}},
            )

        def risk_score_user_or_host(self, user_or_host_id: str) -> dict[str, dict[str, Any]]:
            return self._http_request(
                method='POST',
                url_suffix='/get_risk_score/',
                json_data={"request_data": {"id": user_or_host_id}},
            )

        def list_risky_users(self) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/get_risky_users/',
            )

        def list_risky_hosts(self) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/get_risky_hosts/',
            )

        def list_user_groups(self, group_names: list[str]) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/get_user_group/',
                json_data={"request_data": {"group_names": group_names}},
            )

        def list_roles(self, role_names: list[str]) -> dict[str, list[list[dict[str, Any]]]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/get_roles/',
                json_data={"request_data": {"role_names": role_names}},
            )

        def set_user_role(self, user_emails: list[str], role_name: str) -> dict[str, dict[str, str]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/set_user_role/',
                json_data={"request_data": {
                    "user_emails": user_emails,
                    "role_name": role_name
                }},
            )

        def remove_user_role(self, user_emails: list[str]) -> dict[str, dict[str, str]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/set_user_role/',
                json_data={"request_data": {
                    "user_emails": user_emails,
                    "role_name": ""
                }},
            )


    class AlertFilterArg:
        def __init__(self, search_field: str, search_type: Optional[str], arg_type: str, option_mapper: dict = None):
            self.search_field = search_field
            self.search_type = search_type
            self.arg_type = arg_type
            self.option_mapper = option_mapper


    def catch_and_exit_gracefully(e):
        """

        Args:
            e: DemistoException caught while running a command.

        Returns:
            CommandResult if the error is internal XDR error, else, the exception.
        """
        if e.res.status_code == 500 and 'no endpoint was found for creating the requested action' in str(e).lower():
            return CommandResults(readable_output="The operation executed is not supported on the given machine.")
        else:
            raise e


    def init_filter_args_options():
        array = 'array'
        dropdown = 'dropdown'
        time_frame = 'time_frame'

        return {
            'alert_id': AlertFilterArg('internal_id', 'EQ', array),
            'severity': AlertFilterArg('severity', 'EQ', dropdown, {
                'low': 'SEV_020_LOW',
                'medium': 'SEV_030_MEDIUM',
                'high': 'SEV_040_HIGH'
            }),
            'starred': AlertFilterArg('starred', 'EQ', dropdown, {
                'true': True,
                'False': False,
            }),
            'Identity_type': AlertFilterArg('Identity_type', 'EQ', dropdown),
            'alert_action_status': AlertFilterArg('alert_action_status', 'EQ', dropdown, ALERT_STATUS_TYPES_REVERSE_DICT),
            'agent_id': AlertFilterArg('agent_id', 'EQ', array),
            'action_external_hostname': AlertFilterArg('action_external_hostname', 'CONTAINS', array),
            'rule_id': AlertFilterArg('matching_service_rule_id', 'EQ', array),
            'rule_name': AlertFilterArg('fw_rule', 'EQ', array),
            'alert_name': AlertFilterArg('alert_name', 'CONTAINS', array),
            'alert_source': AlertFilterArg('alert_source', 'CONTAINS', array),
            'time_frame': AlertFilterArg('source_insert_ts', None, time_frame),
            'user_name': AlertFilterArg('actor_effective_username', 'CONTAINS', array),
            'actor_process_image_name': AlertFilterArg('actor_process_image_name', 'CONTAINS', array),
            'causality_actor_process_image_command_line': AlertFilterArg('causality_actor_process_command_line', 'EQ',
                                                                         array),
            'actor_process_image_command_line': AlertFilterArg('actor_process_command_line', 'EQ', array),
            'action_process_image_command_line': AlertFilterArg('action_process_image_command_line', 'EQ', array),
            'actor_process_image_sha256': AlertFilterArg('actor_process_image_sha256', 'EQ', array),
            'causality_actor_process_image_sha256': AlertFilterArg('causality_actor_process_image_sha256', 'EQ', array),
            'action_process_image_sha256': AlertFilterArg('action_process_image_sha256', 'EQ', array),
            'action_file_image_sha256': AlertFilterArg('action_file_sha256', 'EQ', array),
            'action_registry_name': AlertFilterArg('action_registry_key_name', 'EQ', array),
            'action_registry_key_data': AlertFilterArg('action_registry_data', 'CONTAINS', array),
            'host_ip': AlertFilterArg('agent_ip_addresses', 'IPLIST_MATCH', array),
            'action_local_ip': AlertFilterArg('action_local_ip', 'IP_MATCH', array),
            'action_remote_ip': AlertFilterArg('action_remote_ip', 'IP_MATCH', array),
            'action_local_port': AlertFilterArg('action_local_port', 'EQ', array),
            'action_remote_port': AlertFilterArg('action_remote_port', 'EQ', array),
            'dst_action_external_hostname': AlertFilterArg('dst_action_external_hostname', 'CONTAINS', array),
            'mitre_technique_id_and_name': AlertFilterArg('mitre_technique_id_and_name', 'CONTAINS', array),
        }


    def run_polling_command(client: CoreClient,
                            args: dict,
                            cmd: str,
                            command_function: Callable,
                            command_decision_field: str,
                            results_function: Callable,
                            polling_field: str,
                            polling_value: List,
                            stop_polling: bool = False) -> CommandResults:
        """
        Arguments:
        args: args
        cmd: the scheduled command's name (as appears in the yml file) to run in the following polling.
        command_function: the pythonic function that executes the command.
        command_decision_field: the field that is retrieved from the command_function's response that indicates
        the command_function status.
        results_function: the pythonic result function which we want to poll on.
        polling_field: the field that is retrieved from the results_function's response and indicates the polling status.
        polling_value: list of values of the polling_field we want to check. The list can contain values to stop or
        continue polling on, not both.
        stop_polling: True - polling_value stops the polling. False - polling_value does not stop the polling.

        Return:
        command_results(CommandResults)
        """

        ScheduledCommand.raise_error_if_not_supported()
        interval_in_secs = int(args.get('interval_in_seconds', 60))
        timeout_in_seconds = int(args.get('timeout_in_seconds', 600))
        if command_decision_field not in args:
            # create new command run
            command_results = command_function(client, args)
            outputs = command_results.raw_response
            if outputs and not isinstance(outputs, list):
                outputs = [outputs]
            command_decision_values = [o.get(command_decision_field) for o in outputs] if outputs else []  # type: ignore
            if outputs and command_decision_values:
                polling_args = {
                    command_decision_field: command_decision_values,
                    'interval_in_seconds': interval_in_secs,
                    **args
                }
                scheduled_command = ScheduledCommand(
                    command=cmd,
                    next_run_in_seconds=interval_in_secs,
                    args=polling_args,
                    timeout_in_seconds=timeout_in_seconds)
                if isinstance(command_results, list):
                    command_results = command_results[0]
                command_results.scheduled_command = scheduled_command
                return command_results
            else:
                if command_results.readable_output:
                    demisto.error(f"{command_results.readable_output}")
                else:
                    demisto.error(f"Command {command_function} didn't succeeded, returned {outputs}")
                return command_results
        # get polling result
        command_results = results_function(client, args)
        outputs_result_func = command_results.raw_response
        if not outputs_result_func:
            return_error(f"Command {cmd} didn't succeeded, received empty response.")
        result = outputs_result_func.get(polling_field) if isinstance(outputs_result_func, dict) else \
            outputs_result_func[0].get(polling_field)
        cond = result not in polling_value if stop_polling else result in polling_value
        if cond:
            # schedule next poll
            polling_args = {
                'interval_in_seconds': interval_in_secs,
                **args
            }
            scheduled_command = ScheduledCommand(
                command=cmd,
                next_run_in_seconds=interval_in_secs,
                args=polling_args,
                timeout_in_seconds=timeout_in_seconds)

            # result with scheduled_command only - no update to the war room
            command_results = CommandResults(scheduled_command=scheduled_command, raw_response=outputs_result_func)
        return command_results


    def convert_time_to_epoch(time_to_convert: str) -> int:
        """
        Converts time in epoch UNIX timestamp format or date in '%Y-%m-%dT%H:%M:%S' format to timestamp format.
        :param time_to_convert:
        :return: converted_timestamp
        """
        try:
            timestamp = int(time_to_convert)
            return timestamp
        except Exception:
            try:
                return date_to_timestamp(time_to_convert)
            except Exception:
                raise DemistoException('the time_frame format is invalid. Valid formats: %Y-%m-%dT%H:%M:%S or '
                                       'epoch UNIX timestamp (example: 1651505482)')


    def create_filter_from_args(args: dict) -> dict:
        """
        Builds an XDR format filter dict for the xdr-get-alert command.
        :param args: The arguments provided by the user
        :return: The filter format built from args
        """
        valid_args = init_filter_args_options()
        and_operator_list = []
        start_time = args.pop('start_time', None)
        end_time = args.pop('end_time', None)

        if (start_time or end_time) and ('time_frame' not in args):
            raise DemistoException('Please choose "custom" under time_frame argument when using start_time and end_time '
                                   'arguments')

        for arg_name, arg_value in args.items():
            if arg_name not in valid_args:
                raise DemistoException(f'Argument {arg_name} is not valid.')
            arg_properties = valid_args.get(arg_name)

            # handle time frame
            if arg_name == 'time_frame':
                # custom time frame
                if arg_value == 'custom':
                    if not start_time or not end_time:
                        raise DemistoException(
                            'Please provide start_time and end_time arguments when using time_frame as custom.')
                    start_time = convert_time_to_epoch(start_time)
                    end_time = convert_time_to_epoch(end_time)
                    search_type = 'RANGE'
                    search_value: Union[dict, Optional[str]] = {
                        'from': start_time,
                        'to': end_time
                    }

                # relative time frame
                else:
                    search_value = None
                    search_type = 'RELATIVE_TIMESTAMP'
                    relative_date = dateparser.parse(arg_value)
                    if relative_date:
                        delta_in_milliseconds = int((datetime.now() - relative_date).total_seconds() * 1000)
                        search_value = str(delta_in_milliseconds)

                and_operator_list.append({
                    'SEARCH_FIELD': arg_properties.search_field,
                    'SEARCH_TYPE': search_type,
                    'SEARCH_VALUE': search_value
                })

            # handle array args, array elements should be seperated with 'or' op
            elif arg_properties.arg_type == 'array':
                or_operator_list = []
                arg_list = argToList(arg_value)
                for arg_item in arg_list:
                    or_operator_list.append({
                        'SEARCH_FIELD': arg_properties.search_field,
                        'SEARCH_TYPE': arg_properties.search_type,
                        'SEARCH_VALUE': arg_item
                    })
                and_operator_list.append({'OR': or_operator_list})
            else:
                and_operator_list.append({
                    'SEARCH_FIELD': arg_properties.search_field,
                    'SEARCH_TYPE': arg_properties.search_type,
                    'SEARCH_VALUE': arg_properties.option_mapper.get(arg_value) if arg_properties.option_mapper else arg_value
                })

        return {'AND': and_operator_list}


    def arg_to_int(arg, arg_name: str, required: bool = False):
        if arg is None:
            if required is True:
                raise ValueError(f'Missing "{arg_name}"')
            return None
        if isinstance(arg, str):
            if arg.isdigit():
                return int(arg)
            raise ValueError(f'Invalid number: "{arg_name}"="{arg}"')
        if isinstance(arg, int):
            return arg
        return ValueError(f'Invalid number: "{arg_name}"')


    def validate_args_scan_commands(args):
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        gte_first_seen = args.get('gte_first_seen')
        gte_last_seen = args.get('gte_last_seen')
        lte_first_seen = args.get('lte_first_seen')
        lte_last_seen = args.get('lte_last_seen')
        ip_list = argToList(args.get('ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias = argToList(args.get('alias'))
        hostname = argToList(args.get('hostname'))
        all_ = argToBoolean(args.get('all', 'false'))

        # to prevent the case where an empty filtered command will trigger by default a scan on all the endpoints.
        err_msg = 'To scan/abort scan all the endpoints run this command with the \'all\' argument as True ' \
                  'and without any other filters. This may cause performance issues.\n' \
                  'To scan/abort scan some of the endpoints, please use the filter arguments.'
        if all_:
            if endpoint_id_list or dist_name or gte_first_seen or gte_last_seen or lte_first_seen or lte_last_seen \
                    or ip_list or group_name or platform or alias or hostname:
                raise Exception(err_msg)
        elif not endpoint_id_list and not dist_name and not gte_first_seen and not gte_last_seen \
                and not lte_first_seen and not lte_last_seen and not ip_list and not group_name and not platform \
                and not alias and not hostname:
            raise Exception(err_msg)


    def endpoint_scan_command(client: CoreClient, args) -> CommandResults:
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        gte_first_seen = args.get('gte_first_seen')
        gte_last_seen = args.get('gte_last_seen')
        lte_first_seen = args.get('lte_first_seen')
        lte_last_seen = args.get('lte_last_seen')
        ip_list = argToList(args.get('ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias = argToList(args.get('alias'))
        isolate = args.get('isolate')
        hostname = argToList(args.get('hostname'))
        incident_id = arg_to_number(args.get('incident_id'))

        validate_args_scan_commands(args)

        reply = client.endpoint_scan(
            url_suffix='/endpoints/scan/',
            endpoint_id_list=argToList(endpoint_id_list),
            dist_name=dist_name,
            gte_first_seen=gte_first_seen,
            gte_last_seen=gte_last_seen,
            lte_first_seen=lte_first_seen,
            lte_last_seen=lte_last_seen,
            ip_list=ip_list,
            group_name=group_name,
            platform=platform,
            alias=alias,
            isolate=isolate,
            hostname=hostname,
            incident_id=incident_id
        )

        action_id = reply.get("action_id")

        context = {
            "actionId": action_id,
            "aborted": False
        }

        return CommandResults(
            readable_output=tableToMarkdown('Endpoint scan', {'Action Id': action_id}, ['Action Id']),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.endpointScan(val.actionId == obj.actionId)': context},
            raw_response=reply
        )


    def action_status_get_command(client: CoreClient, args) -> CommandResults:
        action_id_list = argToList(args.get('action_id', ''))
        action_id_list = [arg_to_int(arg=item, arg_name=str(item)) for item in action_id_list]

        result = []
        for action_id in action_id_list:
            data = client.action_status_get(action_id)

            for endpoint_id, status in data.items():
                result.append({
                    'action_id': action_id,
                    'endpoint_id': endpoint_id,
                    'status': status
                })

        return CommandResults(
            readable_output=tableToMarkdown(name='Get Action Status', t=result, removeNull=True),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.'
                           f'GetActionStatus(val.action_id == obj.action_id)',
            outputs=result,
            raw_response=result
        )


    def isolate_endpoint_command(client: CoreClient, args) -> CommandResults:
        endpoint_id = args.get('endpoint_id')
        disconnected_should_return_error = not argToBoolean(args.get('suppress_disconnected_endpoint_error', False))
        incident_id = arg_to_number(args.get('incident_id'))
        endpoint = client.get_endpoints(endpoint_id_list=[endpoint_id])
        if len(endpoint) == 0:
            raise ValueError(f'Error: Endpoint {endpoint_id} was not found')

        endpoint = endpoint[0]
        endpoint_status = endpoint.get('endpoint_status')
        is_isolated = endpoint.get('is_isolated')
        if is_isolated == 'AGENT_ISOLATED':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} already isolated.'
            )
        if is_isolated == 'AGENT_PENDING_ISOLATION':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} pending isolation.'
            )
        if endpoint_status == 'UNINSTALLED':
            raise ValueError(f'Error: Endpoint {endpoint_id}\'s Agent is uninstalled and therefore can not be isolated.')
        if endpoint_status == 'DISCONNECTED':
            if disconnected_should_return_error:
                raise ValueError(f'Error: Endpoint {endpoint_id} is disconnected and therefore can not be isolated.')
            else:
                return CommandResults(
                    readable_output=f'Warning: isolation action is pending for the following disconnected endpoint: {endpoint_id}.',
                    outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                             f'Isolation.endpoint_id(val.endpoint_id == obj.endpoint_id)': endpoint_id}
                )
        if is_isolated == 'AGENT_PENDING_ISOLATION_CANCELLATION':
            raise ValueError(
                f'Error: Endpoint {endpoint_id} is pending isolation cancellation and therefore can not be isolated.'
            )
        try:
            result = client.isolate_endpoint(endpoint_id=endpoint_id, incident_id=incident_id)

            return CommandResults(
                readable_output=f'The isolation request has been submitted successfully on Endpoint {endpoint_id}.\n',
                outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                         f'Isolation.endpoint_id(val.endpoint_id == obj.endpoint_id)': endpoint_id},
                raw_response=result
            )
        except Exception as e:
            return catch_and_exit_gracefully(e)


    def arg_to_timestamp(arg, arg_name: str, required: bool = False):
        if arg is None:
            if required is True:
                raise ValueError(f'Missing "{arg_name}"')
            return None

        if isinstance(arg, str) and arg.isdigit():
            # timestamp that str - we just convert it to int
            return int(arg)
        if isinstance(arg, str):
            # if the arg is string of date format 2019-10-23T00:00:00 or "3 days", etc
            date = dateparser.parse(arg, settings={'TIMEZONE': 'UTC'})
            if date is None:
                # if d is None it means dateparser failed to parse it
                raise ValueError(f'Invalid date: {arg_name}')

            return int(date.timestamp() * 1000)
        if isinstance(arg, (int, float)):
            return arg
        return None


    def create_account_context(endpoints):
        account_context = []
        for endpoint in endpoints:
            domain = endpoint.get('domain')
            if domain:
                users = endpoint.get('users', [])  # in case the value of 'users' is None
                if users and isinstance(users, list):
                    for user in users:
                        account_context.append({
                            'Username': user,
                            'Domain': domain,
                        })

        return account_context


    def get_endpoint_properties(single_endpoint):
        status = 'Online' if single_endpoint.get('endpoint_status', '').lower() == 'connected' else 'Offline'
        is_isolated = 'No' if 'unisolated' in single_endpoint.get('is_isolated', '').lower() else 'Yes'
        hostname = single_endpoint['host_name'] if single_endpoint.get('host_name') else single_endpoint.get(
            'endpoint_name')
        ip = single_endpoint.get('ip')
        return status, is_isolated, hostname, ip


    def convert_os_to_standard(endpoint_os):
        os_type = ''
        endpoint_os = endpoint_os.lower()
        if 'windows' in endpoint_os:
            os_type = "Windows"
        elif 'linux' in endpoint_os:
            os_type = "Linux"
        elif 'mac' in endpoint_os:
            os_type = "Macos"
        elif 'android' in endpoint_os:
            os_type = "Android"
        return os_type


    def generate_endpoint_by_contex_standard(endpoints, ip_as_string, integration_name="CoreApiModule"):
        standard_endpoints = []
        for single_endpoint in endpoints:
            status, is_isolated, hostname, ip = get_endpoint_properties(single_endpoint)
            # in the `-get-endpoints` command the ip is returned as list, in order not to break bc we will keep it
            # in the `endpoint` command we use the standard
            if ip_as_string and isinstance(ip, list):
                ip = ip[0]
            os_type = convert_os_to_standard(single_endpoint.get('os_type', ''))
            endpoint = Common.Endpoint(
                id=single_endpoint.get('endpoint_id'),
                hostname=hostname,
                ip_address=ip,
                os=os_type,
                status=status,
                is_isolated=is_isolated,
                mac_address=single_endpoint.get('mac_address'),
                domain=single_endpoint.get('domain'),
                vendor=integration_name)

            standard_endpoints.append(endpoint)
        return standard_endpoints


    def get_endpoints_command(client, args):
        integration_context_brand = args.pop('integration_context_brand', 'CoreApiModule')
        integration_name = args.pop("integration_name", "CoreApiModule")
        page_number = arg_to_int(
            arg=args.get('page', '0'),
            arg_name='Failed to parse "page". Must be a number.',
            required=True
        )

        limit = arg_to_int(
            arg=args.get('limit', '30'),
            arg_name='Failed to parse "limit". Must be a number.',
            required=True
        )

        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        ip_list = argToList(args.get('ip_list'))
        public_ip_list = argToList(args.get('public_ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias_name = argToList(args.get('alias_name'))
        isolate = args.get('isolate')
        hostname = argToList(args.get('hostname'))
        status = argToList(args.get('status'))

        first_seen_gte = arg_to_timestamp(
            arg=args.get('first_seen_gte'),
            arg_name='first_seen_gte'
        )

        first_seen_lte = arg_to_timestamp(
            arg=args.get('first_seen_lte'),
            arg_name='first_seen_lte'
        )

        last_seen_gte = arg_to_timestamp(
            arg=args.get('last_seen_gte'),
            arg_name='last_seen_gte'
        )

        last_seen_lte = arg_to_timestamp(
            arg=args.get('last_seen_lte'),
            arg_name='last_seen_lte'
        )

        sort_by_first_seen = args.get('sort_by_first_seen')
        sort_by_last_seen = args.get('sort_by_last_seen')

        username = argToList(args.get('username'))

        endpoints = client.get_endpoints(
            endpoint_id_list=endpoint_id_list,
            dist_name=dist_name,
            ip_list=ip_list,
            public_ip_list=public_ip_list,
            group_name=group_name,
            platform=platform,
            alias_name=alias_name,
            isolate=isolate,
            hostname=hostname,
            page_number=page_number,
            limit=limit,
            first_seen_gte=first_seen_gte,
            first_seen_lte=first_seen_lte,
            last_seen_gte=last_seen_gte,
            last_seen_lte=last_seen_lte,
            sort_by_first_seen=sort_by_first_seen,
            sort_by_last_seen=sort_by_last_seen,
            status=status,
            username=username
        )

        standard_endpoints = generate_endpoint_by_contex_standard(endpoints, False, integration_name)
        endpoint_context_list = []
        for endpoint in standard_endpoints:
            endpoint_context = endpoint.to_context().get(Common.Endpoint.CONTEXT_PATH)
            endpoint_context_list.append(endpoint_context)

        context = {
            f'{integration_context_brand}.Endpoint(val.endpoint_id == obj.endpoint_id)': endpoints,
            Common.Endpoint.CONTEXT_PATH: endpoint_context_list,
            f'{integration_context_brand}.Endpoint.count': len(standard_endpoints)
        }
        account_context = create_account_context(endpoints)
        if account_context:
            context[Common.Account.CONTEXT_PATH] = account_context

        return CommandResults(
            readable_output=tableToMarkdown('Endpoints', endpoints),
            outputs=context,
            raw_response=endpoints
        )


    def endpoint_alias_change_command(client: CoreClient, **args) -> CommandResults:
        # get arguments
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name_list = argToList(args.get('dist_name'))
        ip_list = argToList(args.get('ip_list'))
        group_name_list = argToList(args.get('group_name'))
        platform_list = argToList(args.get('platform'))
        alias_name_list = argToList(args.get('alias_name'))
        isolate = args.get('isolate')
        hostname_list = argToList(args.get('hostname'))
        status = args.get('status')
        scan_status = args.get('scan_status')
        username_list = argToList(args.get('username'))
        new_alias_name = args.get('new_alias_name')

        # This is a workaround that is needed because of a specific behaviour of the system
        # that converts an empty string to a string with double quotes.
        if new_alias_name == '""':
            new_alias_name = ""

        first_seen_gte = arg_to_timestamp(
            arg=args.get('first_seen_gte'),
            arg_name='first_seen_gte'
        )

        first_seen_lte = arg_to_timestamp(
            arg=args.get('first_seen_lte'),
            arg_name='first_seen_lte'
        )

        last_seen_gte = arg_to_timestamp(
            arg=args.get('last_seen_gte'),
            arg_name='last_seen_gte'
        )

        last_seen_lte = arg_to_timestamp(
            arg=args.get('last_seen_lte'),
            arg_name='last_seen_lte'
        )

        # create filters
        filters: list[dict[str, str]] = create_request_filters(
            status=status, username=username_list, endpoint_id_list=endpoint_id_list, dist_name=dist_name_list,
            ip_list=ip_list, group_name=group_name_list, platform=platform_list, alias_name=alias_name_list, isolate=isolate,
            hostname=hostname_list, first_seen_gte=first_seen_gte, first_seen_lte=first_seen_lte,
            last_seen_gte=last_seen_gte, last_seen_lte=last_seen_lte, scan_status=scan_status
        )
        if not filters:
            raise DemistoException('Please provide at least one filter.')
        # importent: the API will return True even if the endpoint does not exist, so its a good idea to check
        # the results by a get_endpoints command
        client.set_endpoints_alias(filters=filters, new_alias_name=new_alias_name)

        return CommandResults(
            readable_output="The endpoint alias was changed successfully.")


    def unisolate_endpoint_command(client, args):
        endpoint_id = args.get('endpoint_id')
        incident_id = arg_to_number(args.get('incident_id'))

        disconnected_should_return_error = not argToBoolean(args.get('suppress_disconnected_endpoint_error', False))
        endpoint = client.get_endpoints(endpoint_id_list=[endpoint_id])
        if len(endpoint) == 0:
            raise ValueError(f'Error: Endpoint {endpoint_id} was not found')

        endpoint = endpoint[0]
        endpoint_status = endpoint.get('endpoint_status')
        is_isolated = endpoint.get('is_isolated')
        if is_isolated == 'AGENT_UNISOLATED':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} already unisolated.'
            )
        if is_isolated == 'AGENT_PENDING_ISOLATION_CANCELLATION':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} pending isolation cancellation.'
            )
        if endpoint_status == 'UNINSTALLED':
            raise ValueError(f'Error: Endpoint {endpoint_id}\'s Agent is uninstalled and therefore can not be un-isolated.')
        if endpoint_status == 'DISCONNECTED':
            if disconnected_should_return_error:
                raise ValueError(f'Error: Endpoint {endpoint_id} is disconnected and therefore can not be un-isolated.')
            else:
                return CommandResults(
                    readable_output=f'Warning: un-isolation action is pending for the following disconnected '
                                    f'endpoint: {endpoint_id}.',
                    outputs={
                        f'{args.get("integration_context_brand", "CoreApiModule")}.'
                        f'UnIsolation.endpoint_id(val.endpoint_id == obj.endpoint_id)'
                        f'': endpoint_id}
                )
        if is_isolated == 'AGENT_PENDING_ISOLATION':
            raise ValueError(
                f'Error: Endpoint {endpoint_id} is pending isolation and therefore can not be un-isolated.'
            )
        result = client.unisolate_endpoint(endpoint_id=endpoint_id, incident_id=incident_id)

        return CommandResults(
            readable_output=f'The un-isolation request has been submitted successfully on Endpoint {endpoint_id}.\n',
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'UnIsolation.endpoint_id(val.endpoint_id == obj.endpoint_id)': endpoint_id},
            raw_response=result
        )


    def retrieve_files_command(client: CoreClient, args: Dict[str, str]) -> CommandResults:
        endpoint_id_list: list = argToList(args.get('endpoint_ids'))
        windows: list = argToList(args.get('windows_file_paths'))
        linux: list = argToList(args.get('linux_file_paths'))
        macos: list = argToList(args.get('mac_file_paths'))
        file_path_list: list = argToList(args.get('generic_file_path'))
        incident_id: Optional[int] = arg_to_number(args.get('incident_id'))

        reply = client.retrieve_file(
            endpoint_id_list=endpoint_id_list,
            windows=windows,
            linux=linux,
            macos=macos,
            file_path_list=file_path_list,
            incident_id=incident_id
        )
        result = {'action_id': reply.get('action_id')}

        return CommandResults(
            readable_output=tableToMarkdown(name='Retrieve files', t=result, headerTransform=string_to_table_header),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}'
                           f'.RetrievedFiles(val.action_id == obj.action_id)',
            outputs=result,
            raw_response=reply
        )


    def run_snippet_code_script_command(client: CoreClient, args: Dict) -> CommandResults:
        snippet_code = args.get('snippet_code')
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        response = client.run_snippet_code_script(snippet_code=snippet_code, endpoint_ids=endpoint_ids, incident_id=incident_id)
        reply = response.get('reply')
        return CommandResults(
            readable_output=tableToMarkdown('Run Snippet Code Script', reply),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=reply,
            raw_response=reply,
        )


    def run_script_execute_commands_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        parameters = {'commands_list': argToList(args.get('commands'))}
        response = client.run_script('a6f7683c8e217d85bd3c398f0d3fb6bf', endpoint_ids, parameters, timeout, incident_id)
        reply = response.get('reply')
        return CommandResults(
            readable_output=tableToMarkdown('Run Script Execute Commands', reply),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=reply,
            raw_response=reply,
        )


    def run_script_kill_process_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        processes_names = argToList(args.get('process_name'))
        replies = []

        for process_name in processes_names:
            parameters = {'process_name': process_name}
            response = client.run_script('fd0a544a99a9421222b4f57a11839481', endpoint_ids, parameters, timeout, incident_id)
            reply = response.get('reply')
            replies.append(reply)

        command_result = CommandResults(
            readable_output=tableToMarkdown("Run Script Kill Process Results", replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=replies,
        )

        return command_result


    def run_script_file_exists_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        file_paths = argToList(args.get('file_path'))
        replies = []
        for file_path in file_paths:
            parameters = {'path': file_path}
            response = client.run_script('414763381b5bfb7b05796c9fe690df46', endpoint_ids, parameters, timeout, incident_id)
            reply = response.get('reply')
            replies.append(reply)

        command_result = CommandResults(
            readable_output=tableToMarkdown(f'Run Script File Exists on {",".join(file_paths)}', replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=replies,
        )
        return command_result


    def run_script_delete_file_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        file_paths = argToList(args.get('file_path'))
        replies = []
        for file_path in file_paths:
            parameters = {'file_path': file_path}
            response = client.run_script('548023b6e4a01ec51a495ba6e5d2a15d', endpoint_ids, parameters, timeout, incident_id)
            reply = response.get('reply')
            replies.append(reply)

        command_result = CommandResults(
            readable_output=tableToMarkdown(f'Run Script Delete File on {",".join(file_paths)}', replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=replies,
        )
        return command_result


    def quarantine_files_command(client, args):
        endpoint_id_list = argToList(args.get("endpoint_id_list"))
        file_path = args.get("file_path")
        file_hash = args.get("file_hash")
        incident_id = arg_to_number(args.get('incident_id'))

        try:
            reply = client.quarantine_files(
                endpoint_id_list=endpoint_id_list,
                file_path=file_path,
                file_hash=file_hash,
                incident_id=incident_id
            )
            output = {
                'endpointIdList': endpoint_id_list,
                'filePath': file_path,
                'fileHash': file_hash,
                'actionId': reply.get("action_id")
            }

            return CommandResults(
                readable_output=tableToMarkdown('Quarantine files', output, headers=[*output],
                                                headerTransform=pascalToSpace),
                outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                         f'quarantineFiles.actionIds(val.actionId === obj.actionId)': output},
                raw_response=reply
            )
        except Exception as e:
            return catch_and_exit_gracefully(e)


    def restore_file_command(client, args):
        file_hash = args.get('file_hash')
        endpoint_id = args.get('endpoint_id')
        incident_id = arg_to_number(args.get('incident_id'))

        reply = client.restore_file(
            file_hash=file_hash,
            endpoint_id=endpoint_id,
            incident_id=incident_id
        )
        action_id = reply.get("action_id")

        return CommandResults(
            readable_output=tableToMarkdown('Restore files', {'Action Id': action_id}, ['Action Id']),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'restoredFiles.actionId(val.actionId == obj.actionId)': action_id},
            raw_response=reply
        )


    def blocklist_files_command(client, args):
        hash_list = argToList(args.get('hash_list'))
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))
        detailed_response = argToBoolean(args.get('detailed_response', False))

        res = client.blocklist_files(hash_list=hash_list,
                                     comment=comment,
                                     incident_id=incident_id,
                                     detailed_response=detailed_response)

        if detailed_response:
            return CommandResults(
                readable_output=tableToMarkdown('Blocklist Files', res),
                outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.blocklist',
                outputs=res,
                raw_response=res
            )

        markdown_data = [{'added_hashes': file_hash} for file_hash in hash_list]

        return CommandResults(
            readable_output=tableToMarkdown('Blocklist Files',
                                            markdown_data,
                                            headers=['added_hashes'],
                                            headerTransform=pascalToSpace),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'{args.get("prefix", "blocklist")}.added_hashes.fileHash(val.fileHash == obj.fileHash)': hash_list},
            raw_response=res
        )


    def remove_blocklist_files_command(client: CoreClient, args: Dict) -> CommandResults:
        hash_list = argToList(args.get('hash_list'))
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))

        res = client.remove_blocklist_files(hash_list=hash_list, comment=comment, incident_id=incident_id)
        markdown_data = [{'removed_hashes': file_hash} for file_hash in hash_list]

        return CommandResults(
            readable_output=tableToMarkdown('Blocklist Files Removed',
                                            markdown_data,
                                            headers=['removed_hashes'],
                                            headerTransform=pascalToSpace),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.blocklist',
            outputs=markdown_data,
            raw_response=res
        )


    def allowlist_files_command(client, args):
        hash_list = argToList(args.get('hash_list'))
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))
        detailed_response = argToBoolean(args.get('detailed_response', False))

        res = client.allowlist_files(hash_list=hash_list,
                                     comment=comment,
                                     incident_id=incident_id,
                                     detailed_response=detailed_response)
        if detailed_response:
            return CommandResults(
                readable_output=tableToMarkdown('Allowlist Files', res),
                outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.allowlist',
                outputs=res,
                raw_response=res
            )

        markdown_data = [{'added_hashes': file_hash} for file_hash in hash_list]

        return CommandResults(
            readable_output=tableToMarkdown('Allowlist Files',
                                            markdown_data,
                                            headers=['added_hashes'],
                                            headerTransform=pascalToSpace),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'{args.get("prefix", "allowlist")}.added_hashes.fileHash(val.fileHash == obj.fileHash)': hash_list},
            raw_response=res
        )


    def remove_allowlist_files_command(client, args):
        hash_list = argToList(args.get('hash_list'))
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))
        res = client.remove_allowlist_files(hash_list=hash_list, comment=comment, incident_id=incident_id)
        markdown_data = [{'removed_hashes': file_hash} for file_hash in hash_list]
        return CommandResults(
            readable_output=tableToMarkdown('Allowlist Files Removed',
                                            markdown_data,
                                            headers=['removed_hashes'],
                                            headerTransform=pascalToSpace),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.allowlist',
            outputs=markdown_data,
            raw_response=res
        )


    def create_endpoint_context(audit_logs):
        endpoints = []
        for log in audit_logs:
            endpoint_details = {
                'ID': log.get('ENDPOINTID'),
                'Hostname': log.get('ENDPOINTNAME'),
                'Domain': log.get('DOMAIN'),
            }
            remove_nulls_from_dictionary(endpoint_details)
            if endpoint_details:
                endpoints.append(endpoint_details)

        return endpoints


    def get_audit_agent_reports_command(client, args):
        endpoint_ids = argToList(args.get('endpoint_ids'))
        endpoint_names = argToList(args.get('endpoint_names'))
        result = argToList(args.get('result'))
        _type = argToList(args.get('type'))
        sub_type = argToList(args.get('sub_type'))

        timestamp_gte = arg_to_timestamp(
            arg=args.get('timestamp_gte'),
            arg_name='timestamp_gte'
        )

        timestamp_lte = arg_to_timestamp(
            arg=args.get('timestamp_lte'),
            arg_name='timestamp_lte'
        )

        page_number = arg_to_int(
            arg=args.get('page', 0),
            arg_name='Failed to parse "page". Must be a number.',
            required=True
        )
        limit = arg_to_int(
            arg=args.get('limit', 20),
            arg_name='Failed to parse "limit". Must be a number.',
            required=True
        )
        search_from = page_number * limit
        search_to = search_from + limit

        sort_by = args.get('sort_by')
        sort_order = args.get('sort_order', 'asc')

        audit_logs = client.get_audit_agent_reports(
            endpoint_ids=endpoint_ids,
            endpoint_names=endpoint_names,
            result=result,
            _type=_type,
            sub_type=sub_type,
            timestamp_gte=timestamp_gte,
            timestamp_lte=timestamp_lte,

            search_from=search_from,
            search_to=search_to,
            sort_by=sort_by,
            sort_order=sort_order
        )
        integration_context = {
            f'{args.get("integration_context_brand", "CoreApiModule")}.AuditAgentReports': audit_logs}
        endpoint_context = create_endpoint_context(audit_logs)
        if endpoint_context:
            integration_context[Common.Endpoint.CONTEXT_PATH] = endpoint_context
        return (
            tableToMarkdown('Audit Agent Reports', audit_logs),
            integration_context,
            audit_logs
        )


    def get_distribution_url_command(client, args):
        distribution_id = args.get('distribution_id')
        package_type = args.get('package_type')

        url = client.get_distribution_url(distribution_id, package_type)

        return (
            f'[Distribution URL]({url})',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Distribution(val.id == obj.id)': {
                    'id': distribution_id,
                    'url': url
                }
            },
            url
        )


    def get_distribution_status_command(client, args):
        distribution_ids = argToList(args.get('distribution_ids'))

        distribution_list = []
        for distribution_id in distribution_ids:
            status = client.get_distribution_status(distribution_id)

            distribution_list.append({
                'id': distribution_id,
                'status': status
            })

        return (
            tableToMarkdown('Distribution Status', distribution_list, ['id', 'status']),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Distribution(val.id == obj.id)': distribution_list
            },
            distribution_list
        )


    def get_process_context(alert, process_type):
        process_context = {
            'Name': alert.get(f'{process_type}_process_image_name'),
            'MD5': alert.get(f'{process_type}_process_image_md5'),
            'SHA256': alert.get(f'{process_type}_process_image_sha256'),
            'PID': alert.get(f'{process_type}_process_os_pid'),
            'CommandLine': alert.get(f'{process_type}_process_command_line'),
            'Path': alert.get(f'{process_type}_process_image_path'),
            'Start Time': alert.get(f'{process_type}_process_execution_time'),
            'Hostname': alert.get('host_name'),
        }

        remove_nulls_from_dictionary(process_context)

        # If the process contains only 'HostName' , don't create an indicator
        if len(process_context.keys()) == 1 and 'Hostname' in process_context:
            return {}
        return process_context


    def add_to_ip_context(alert, ip_context):
        action_local_ip = alert.get('action_local_ip')
        action_remote_ip = alert.get('action_remote_ip')
        if action_local_ip:
            ip_context.append({
                'Address': action_local_ip,
            })

        if action_remote_ip:
            ip_context.append({
                'Address': action_remote_ip,
            })


    def create_context_from_network_artifacts(network_artifacts, ip_context):
        domain_context = []

        if network_artifacts:
            for artifact in network_artifacts:
                domain = artifact.get('network_domain')
                if domain:
                    domain_context.append({
                        'Name': domain,
                    })

                network_ip_details = {
                    'Address': artifact.get('network_remote_ip'),
                    'GEO': {
                        'Country': artifact.get('network_country')},
                }

                remove_nulls_from_dictionary(network_ip_details)

                if network_ip_details:
                    ip_context.append(network_ip_details)

        return domain_context


    def get_indicators_context(incident):
        file_context: List[Any] = []
        process_context: List[Any] = []
        ip_context: List[Any] = []
        for alert in incident.get('alerts', []):
            # file context
            file_details = {
                'Name': alert.get('action_file_name'),
                'Path': alert.get('action_file_path'),
                'SHA265': alert.get('action_file_sha256'),  # Here for backward compatibility
                'SHA256': alert.get('action_file_sha256'),
                'MD5': alert.get('action_file_md5'),
            }
            remove_nulls_from_dictionary(file_details)

            if file_details:
                file_context.append(file_details)

            # process context
            process_types = ['actor', 'os_actor', 'causality_actor', 'action']
            for process_type in process_types:
                single_process_context = get_process_context(alert, process_type)
                if single_process_context:
                    process_context.append(single_process_context)

            # ip context
            add_to_ip_context(alert, ip_context)

        network_artifacts = incident.get('network_artifacts', [])

        domain_context = create_context_from_network_artifacts(network_artifacts, ip_context)

        file_artifacts = incident.get('file_artifacts', [])
        for file in file_artifacts:
            file_sha = file.get('file_sha256')
            file_details = {
                'Name': file.get('file_name'),
                'SHA256': file_sha,
            }
            remove_nulls_from_dictionary(file_details)
            is_malicious = file.get("is_malicious")

            if file_details:
                file_context.append(file_details)
                if file_sha:
                    relevant_processes = filter(lambda p: p.get("SHA256") == file_sha, process_context)
                    for process in relevant_processes:
                        process["is_malicious"] = is_malicious

        return file_context, process_context, domain_context, ip_context


    def endpoint_command(client, args):
        endpoint_id_list = argToList(args.get('id'))
        endpoint_ip_list = argToList(args.get('ip'))
        endpoint_hostname_list = argToList(args.get('hostname'))

        if not any((endpoint_id_list, endpoint_ip_list, endpoint_hostname_list)):
            raise DemistoException(f'{args.get("integration_name", "CoreApiModule")} -'
                                   f' In order to run this command, please provide a valid id, ip or hostname')

        endpoints = client.get_endpoints(
            endpoint_id_list=endpoint_id_list,
            ip_list=endpoint_ip_list,
            hostname=endpoint_hostname_list,
        )
        standard_endpoints = generate_endpoint_by_contex_standard(endpoints, True, args.get("integration_name", "CoreApiModule"))
        command_results = []
        if standard_endpoints:
            for endpoint in standard_endpoints:
                endpoint_context = endpoint.to_context().get(Common.Endpoint.CONTEXT_PATH)
                hr = tableToMarkdown('Cortex Endpoint', endpoint_context)

                command_results.append(CommandResults(
                    readable_output=hr,
                    raw_response=endpoints,
                    indicator=endpoint
                ))

        else:
            command_results.append(CommandResults(
                readable_output="No endpoints were found",
                raw_response=endpoints,
            ))
        return command_results


    def get_audit_management_logs_command(client, args):
        email = argToList(args.get('email'))
        result = argToList(args.get('result'))
        _type = argToList(args.get('type'))
        sub_type = argToList(args.get('sub_type'))

        timestamp_gte = arg_to_timestamp(
            arg=args.get('timestamp_gte'),
            arg_name='timestamp_gte'
        )

        timestamp_lte = arg_to_timestamp(
            arg=args.get('timestamp_lte'),
            arg_name='timestamp_lte'
        )

        page_number = arg_to_int(
            arg=args.get('page', 0),
            arg_name='Failed to parse "page". Must be a number.',
            required=True
        )
        limit = arg_to_int(
            arg=args.get('limit', 20),
            arg_name='Failed to parse "limit". Must be a number.',
            required=True
        )
        search_from = page_number * limit
        search_to = search_from + limit

        sort_by = args.get('sort_by')
        sort_order = args.get('sort_order', 'asc')

        audit_logs = client.audit_management_logs(
            email=email,
            result=result,
            _type=_type,
            sub_type=sub_type,
            timestamp_gte=timestamp_gte,
            timestamp_lte=timestamp_lte,
            search_from=search_from,
            search_to=search_to,
            sort_by=sort_by,
            sort_order=sort_order
        )

        return (
            tableToMarkdown('Audit Management Logs', audit_logs, [
                'AUDIT_ID',
                'AUDIT_RESULT',
                'AUDIT_DESCRIPTION',
                'AUDIT_OWNER_NAME',
                'AUDIT_OWNER_EMAIL',
                'AUDIT_ASSET_JSON',
                'AUDIT_ASSET_NAMES',
                'AUDIT_HOSTNAME',
                'AUDIT_REASON',
                'AUDIT_ENTITY',
                'AUDIT_ENTITY_SUBTYPE',
                'AUDIT_SESSION_ID',
                'AUDIT_CASE_ID',
                'AUDIT_INSERT_TIME'
            ]),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.'
                f'AuditManagementLogs(val.AUDIT_ID == obj.AUDIT_ID)': audit_logs
            },
            audit_logs
        )


    def get_quarantine_status_command(client, args):
        file_path = args.get('file_path')
        file_hash = args.get('file_hash')
        endpoint_id = args.get('endpoint_id')

        reply = client.get_quarantine_status(
            file_path=file_path,
            file_hash=file_hash,
            endpoint_id=endpoint_id
        )
        output = {
            'status': reply['status'],
            'endpointId': reply['endpoint_id'],
            'filePath': reply['file_path'],
            'fileHash': reply['file_hash']
        }

        return CommandResults(
            readable_output=tableToMarkdown('Quarantine files status', output, headers=[*output], headerTransform=pascalToSpace),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'quarantineFiles.status(val.fileHash === obj.fileHash &&'
                     f'val.endpointId === obj.endpointId && val.filePath === obj.filePath)': output},
            raw_response=reply
        )


    def endpoint_scan_abort_command(client, args):
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        gte_first_seen = args.get('gte_first_seen')
        gte_last_seen = args.get('gte_last_seen')
        lte_first_seen = args.get('lte_first_seen')
        lte_last_seen = args.get('lte_last_seen')
        ip_list = argToList(args.get('ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias = argToList(args.get('alias'))
        isolate = args.get('isolate')
        hostname = argToList(args.get('hostname'))
        incident_id = arg_to_number(args.get('incident_id'))

        validate_args_scan_commands(args)

        reply = client.endpoint_scan(
            url_suffix='endpoints/abort_scan/',
            endpoint_id_list=argToList(endpoint_id_list),
            dist_name=dist_name,
            gte_first_seen=gte_first_seen,
            gte_last_seen=gte_last_seen,
            lte_first_seen=lte_first_seen,
            lte_last_seen=lte_last_seen,
            ip_list=ip_list,
            group_name=group_name,
            platform=platform,
            alias=alias,
            isolate=isolate,
            hostname=hostname,
            incident_id=incident_id
        )

        action_id = reply.get("action_id")

        context = {
            "actionId": action_id,
            "aborted": True
        }

        return CommandResults(
            readable_output=tableToMarkdown('Endpoint abort scan', {'Action Id': action_id}, ['Action Id']),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'endpointScan(val.actionId == obj.actionId)': context},
            raw_response=reply
        )


    def sort_by_key(list_to_sort, main_key, fallback_key):
        """Sorts a given list elements by main_key for all elements with the key,
        uses sorting by fallback_key on all elements that dont have the main_key"""
        list_elements_with_main_key = [element for element in list_to_sort if element.get(main_key)]
        sorted_list = sorted(list_elements_with_main_key, key=itemgetter(main_key))
        if len(list_to_sort) == len(sorted_list):
            return sorted_list

        list_elements_with_fallback_without_main = [element for element in list_to_sort
                                                    if element.get(fallback_key) and not element.get(main_key)]
        sorted_list.extend(sorted(list_elements_with_fallback_without_main, key=itemgetter(fallback_key)))

        if len(sorted_list) == len(list_to_sort):
            return sorted_list

        list_elements_without_fallback_and_main = [element for element in list_to_sort
                                                   if not element.get(fallback_key) and not element.get(main_key)]

        sorted_list.extend(list_elements_without_fallback_and_main)
        return sorted_list


    def drop_field_underscore(section):
        section_copy = section.copy()
        for field in section_copy:
            if '_' in field:
                section[field.replace('_', '')] = section.get(field)


    def reformat_sublist_fields(sublist):
        for section in sublist:
            drop_field_underscore(section)


    def handle_outgoing_incident_owner_sync(update_args):
        if 'owner' in update_args and demisto.params().get('sync_owners'):
            if update_args.get('owner'):
                user_info = demisto.findUser(username=update_args.get('owner'))
                if user_info:
                    update_args['assigned_user_mail'] = user_info.get('email')
            else:
                # handle synced unassignment
                update_args['assigned_user_mail'] = None


    def handle_user_unassignment(update_args):
        if ('assigned_user_mail' in update_args and update_args.get('assigned_user_mail') in ['None', 'null', '', None]) \
                or ('assigned_user_pretty_name' in update_args
                    and update_args.get('assigned_user_pretty_name') in ['None', 'null', '', None]):
            update_args['unassign_user'] = 'true'
            update_args['assigned_user_mail'] = None
            update_args['assigned_user_pretty_name'] = None


    def handle_outgoing_issue_closure(remote_args):
        incident_id = remote_args.remote_incident_id
        demisto.debug(f"handle_outgoing_issue_closure {incident_id=}")
        update_args = remote_args.delta
        current_remote_status = remote_args.data.get('status') if remote_args.data else None
        close_reason = update_args.get('close_reason') or update_args.get('closeReason')
        demisto.debug(f'{current_remote_status=} {remote_args.data=} {remote_args.inc_status=} {close_reason=}')
        # force closing remote incident only if:
        #   The XSOAR incident is closed
        #   and the remote incident isn't already closed
        if remote_args.inc_status == 2 and \
           current_remote_status not in XDR_RESOLVED_STATUS_TO_XSOAR and close_reason:

            if close_notes := update_args.get('closeNotes'):
                demisto.debug(f"handle_outgoing_issue_closure {incident_id=} {close_notes=}")
                update_args['resolve_comment'] = close_notes
            update_args['status'] = XSOAR_RESOLVED_STATUS_TO_XDR.get(close_reason, 'Other')
            demisto.debug(f"handle_outgoing_issue_closure Closing Remote incident {incident_id=} with status {update_args['status']}")


    def get_update_args(remote_args):
        """Change the updated field names to fit the update command"""

        handle_outgoing_issue_closure(remote_args)
        handle_outgoing_incident_owner_sync(remote_args.delta)
        handle_user_unassignment(remote_args.delta)
        return remote_args.delta


    def get_distribution_versions_command(client, args):
        versions = client.get_distribution_versions()

        readable_output = []
        for operation_system in versions:
            os_versions = versions[operation_system]

            readable_output.append(
                tableToMarkdown(operation_system, os_versions or [], ['versions'])
            )

        return (
            '\n\n'.join(readable_output),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.DistributionVersions': versions
            },
            versions
        )


    def create_distribution_command(client, args):
        name = args.get('name')
        platform = args.get('platform')
        package_type = args.get('package_type')
        description = args.get('description')
        agent_version = args.get('agent_version')
        if not platform == 'android' and not agent_version:
            # agent_version must be provided for all the platforms except android
            raise ValueError(f'Missing argument "agent_version" for platform "{platform}"')

        distribution_id = client.create_distribution(
            name=name,
            platform=platform,
            package_type=package_type,
            agent_version=agent_version,
            description=description
        )

        distribution = {
            'id': distribution_id,
            'name': name,
            'platform': platform,
            'package_type': package_type,
            'agent_version': agent_version,
            'description': description
        }

        return (
            f'Distribution {distribution_id} created successfully',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Distribution(val.id == obj.id)': distribution
            },
            distribution
        )


    def delete_endpoints_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, Any, Any]:
        endpoint_id_list: list = argToList(args.get('endpoint_ids'))

        client.delete_endpoints(endpoint_id_list)

        return f'Successfully deleted the following endpoints: {args.get("endpoint_ids")}', None, None


    def get_policy_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        endpoint_id = args.get('endpoint_id')

        reply = client.get_policy(endpoint_id)
        context = {'endpoint_id': endpoint_id,
                   'policy_name': reply.get('policy_name')}

        return (
            f'The policy name of endpoint: {endpoint_id} is: {reply.get("policy_name")}.',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Policy(val.endpoint_id == obj.endpoint_id)': context
            },
            reply
        )


    def get_endpoint_device_control_violations_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        endpoint_ids: list = argToList(args.get('endpoint_ids'))
        type_of_violation = args.get('type')
        timestamp_gte: int = arg_to_timestamp(
            arg=args.get('timestamp_gte'),
            arg_name='timestamp_gte'
        )
        timestamp_lte: int = arg_to_timestamp(
            arg=args.get('timestamp_lte'),
            arg_name='timestamp_lte'
        )
        ip_list: list = argToList(args.get('ip_list'))
        vendor: list = argToList(args.get('vendor'))
        vendor_id: list = argToList(args.get('vendor_id'))
        product: list = argToList(args.get('product'))
        product_id: list = argToList(args.get('product_id'))
        serial: list = argToList(args.get('serial'))
        hostname: list = argToList(args.get('hostname'))
        violation_id_list: list = argToList(args.get('violation_id_list', ''))
        username: list = argToList(args.get('username'))

        violation_ids = [arg_to_int(arg=item, arg_name=str(item)) for item in violation_id_list]

        reply = client.get_endpoint_device_control_violations(
            endpoint_ids=endpoint_ids,
            type_of_violation=[type_of_violation],
            timestamp_gte=timestamp_gte,
            timestamp_lte=timestamp_lte,
            ip_list=ip_list,
            vendor=vendor,
            vendor_id=vendor_id,
            product=product,
            product_id=product_id,
            serial=serial,
            hostname=hostname,
            violation_ids=violation_ids,
            username=username
        )

        headers = ['date', 'hostname', 'platform', 'username', 'ip', 'type', 'violation_id', 'vendor', 'product',
                   'serial']
        violations: list = copy.deepcopy(reply.get('violations'))  # type: ignore
        for violation in violations:
            timestamp: str = violation.get('timestamp')
            violation['date'] = timestamp_to_datestring(timestamp, TIME_FORMAT)

        return (
            tableToMarkdown(name='Endpoint Device Control Violation', t=violations, headers=headers,
                            headerTransform=string_to_table_header, removeNull=True),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.'
                f'EndpointViolations(val.violation_id==obj.violation_id)': violations
            },
            reply
        )


    def retrieve_file_details_command(client: CoreClient, args, add_to_context):
        action_id_list = argToList(args.get('action_id', ''))
        action_id_list = [arg_to_int(arg=item, arg_name=str(item)) for item in action_id_list]

        result = []
        raw_result = []
        file_results = []
        endpoints_count = 0
        retrived_files_count = 0

        for action_id in action_id_list:
            data = client.retrieve_file_details(action_id)
            raw_result.append(data)

            for endpoint, link in data.items():
                endpoints_count += 1
                obj = {
                    'action_id': action_id,
                    'endpoint_id': endpoint
                }
                if link:
                    retrived_files_count += 1
                    obj['file_link'] = link
                    file_link = "download" + link.split("download")[1]
                    file = client.get_file_by_url_suffix(url_suffix=file_link)
                    file_results.append(fileResult(filename=f'{endpoint}_{retrived_files_count}.zip', data=file))
                result.append(obj)

        hr = f'### Action id : {args.get("action_id", "")} \n Retrieved {retrived_files_count} files from ' \
             f'{endpoints_count} endpoints. \n To get the exact action status run the core-action-status-get command'
        context = {f'{args.get("integration_context_brand", "CoreApiModule")}'
                   f'.RetrievedFiles(val.action_id == obj.action_id)': result}
        return_entry = {'Type': entryTypes['note'],
                        'ContentsFormat': formats['json'],
                        'Contents': raw_result,
                        'HumanReadable': hr,
                        'ReadableContentsFormat': formats['markdown'],
                        'EntryContext': context if add_to_context else {}
                        }
        return return_entry, file_results


    def get_scripts_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        script_name: list = argToList(args.get('script_name'))
        description: list = argToList(args.get('description'))
        created_by: list = argToList(args.get('created_by'))
        windows_supported = args.get('windows_supported')
        linux_supported = args.get('linux_supported')
        macos_supported = args.get('macos_supported')
        is_high_risk = args.get('is_high_risk')
        offset = arg_to_int(arg=args.get('offset', 0), arg_name='offset')
        limit = arg_to_int(arg=args.get('limit', 50), arg_name='limit')

        result = client.get_scripts(
            name=script_name,
            description=description,
            created_by=created_by,
            windows_supported=[windows_supported],
            linux_supported=[linux_supported],
            macos_supported=[macos_supported],
            is_high_risk=[is_high_risk]
        )
        scripts = copy.deepcopy(result.get('scripts')[offset:(offset + limit)])  # type: ignore
        for script in scripts:
            timestamp = script.get('modification_date')
            script['modification_date_timestamp'] = timestamp
            script['modification_date'] = timestamp_to_datestring(timestamp, TIME_FORMAT)
        headers: list = ['name', 'description', 'script_uid', 'modification_date', 'created_by',
                         'windows_supported', 'linux_supported', 'macos_supported', 'is_high_risk']

        return (
            tableToMarkdown(name='Scripts', t=scripts, headers=headers, removeNull=True,
                            headerTransform=string_to_table_header),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Scripts(val.script_uid == obj.script_uid)': scripts
            },
            result
        )


    def get_script_metadata_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        script_uid = args.get('script_uid')

        reply = client.get_script_metadata(script_uid)
        script_metadata = copy.deepcopy(reply)

        timestamp = script_metadata.get('modification_date')
        script_metadata['modification_date_timestamp'] = timestamp
        script_metadata['modification_date'] = timestamp_to_datestring(timestamp, TIME_FORMAT)

        return (
            tableToMarkdown(name='Script Metadata', t=script_metadata, removeNull=True,
                            headerTransform=string_to_table_header),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptMetadata(val.script_uid == obj.script_uid)': reply
            },
            reply
        )


    def get_script_code_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        script_uid = args.get('script_uid')

        reply = client.get_script_code(script_uid)
        context = {
            'script_uid': script_uid,
            'code': reply
        }

        return (
            f'### Script code: \n ``` {str(reply)} ```',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptCode(val.script_uid == obj.script_uid)': context
            },
            reply
        )


    @polling_function(
        name=demisto.command(),
        interval=arg_to_number(demisto.args().get('polling_interval_in_seconds', 10)),
        # Check for both 'polling_timeout_in_seconds' and 'polling_timeout' to avoid breaking BC:
        timeout=arg_to_number(demisto.args().get('polling_timeout_in_seconds', demisto.args().get('polling_timeout', 600))),
        requires_polling_arg=False  # means it will always be default to poll, poll=true
    )
    def script_run_polling_command(args: dict, client: CoreClient) -> PollResult:

        if action_id := args.get('action_id'):
            response = client.get_script_execution_status(action_id)
            general_status = response.get('reply', {}).get('general_status') or ''

            return PollResult(
                response=get_script_execution_results_command(
                    client, {'action_id': action_id, 'integration_context_brand': 'PaloAltoNetworksXDR'}
                ),
                continue_to_poll=general_status.upper() in ('PENDING', 'IN_PROGRESS')
            )

        else:
            endpoint_ids = argToList(args.get('endpoint_ids'))
            response = get_run_script_execution_response(client, args)
            reply = response.get('reply')
            action_id = reply.get('action_id')

            args['action_id'] = action_id

            return PollResult(
                response=None,  # since polling defaults to true, no need to deliver response here
                continue_to_poll=True,  # if an error is raised from the api, an exception will be raised
                partial_result=CommandResults(
                    readable_output=f'Waiting for the script to finish running '
                                    f'on the following endpoints: {endpoint_ids}...'
                ),
                args_for_next_run=args
            )


    def get_run_script_execution_response(client: CoreClient, args: Dict):
        script_uid = args.get('script_uid')
        endpoint_ids = argToList(args.get('endpoint_ids'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        incident_id = arg_to_number(args.get('incident_id'))
        if parameters := args.get('parameters'):
            try:
                parameters = json.loads(parameters)
            except json.decoder.JSONDecodeError as e:
                raise ValueError(f'The parameters argument is not in a valid JSON structure:\n{e}')
        else:
            parameters = {}
        return client.run_script(script_uid, endpoint_ids, parameters, timeout, incident_id=incident_id)


    def run_script_command(client: CoreClient, args: Dict) -> CommandResults:
        response = get_run_script_execution_response(client, args)
        reply = response.get('reply')
        return CommandResults(
            readable_output=tableToMarkdown('Run Script', reply),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=reply,
            raw_response=response,
        )


    def get_script_execution_status_command(client: CoreClient, args: Dict) -> CommandResults:
        action_ids = argToList(args.get('action_id', ''))
        replies = []
        raw_responses = []
        for action_id in action_ids:
            response = client.get_script_execution_status(action_id)
            reply = response.get('reply')
            reply['action_id'] = int(action_id)
            replies.append(reply)
            raw_responses.append(response)

        command_result = CommandResults(
            readable_output=tableToMarkdown(f'Script Execution Status - {",".join(str(i) for i in action_ids)}', replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptStatus',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=raw_responses,
        )
        return command_result


    def parse_get_script_execution_results(results: List[Dict]) -> List[Dict]:
        parsed_results = []
        api_keys = ['endpoint_name',
                    'endpoint_ip_address',
                    'endpoint_status',
                    'domain',
                    'endpoint_id',
                    'execution_status',
                    'return_value',
                    'standard_output',
                    'retrieved_files',
                    'failed_files',
                    'retention_date']
        for result in results:
            result_keys = result.keys()
            difference_keys = list(set(result_keys) - set(api_keys))
            if difference_keys:
                for key in difference_keys:
                    parsed_res = result.copy()
                    parsed_res['command'] = key
                    parsed_res['command_output'] = result[key]
                    parsed_results.append(parsed_res)
            else:
                parsed_results.append(result.copy())
        return parsed_results


    def get_script_execution_results_command(client: CoreClient, args: Dict) -> List[CommandResults]:
        action_ids = argToList(args.get('action_id', ''))
        command_results = []
        for action_id in action_ids:
            response = client.get_script_execution_results(action_id)
            results = response.get('reply', {}).get('results')
            context = {
                'action_id': int(action_id),
                'results': parse_get_script_execution_results(results),
            }
            command_results.append(CommandResults(
                readable_output=tableToMarkdown(f'Script Execution Results - {action_id}', results),
                outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptResult',
                outputs_key_field='action_id',
                outputs=context,
                raw_response=response,
            ))
        return command_results


    def get_script_execution_result_files_command(client: CoreClient, args: Dict) -> Dict:
        action_id = args.get('action_id', '')
        endpoint_id = args.get('endpoint_id')
        file_response = client.get_script_execution_result_files(action_id, endpoint_id)
        try:
            filename = file_response.headers.get('Content-Disposition').split('attachment; filename=')[1]
        except Exception as e:
            demisto.debug(f'Failed extracting filename from response headers - [{str(e)}]')
            filename = action_id + '.zip'
        return fileResult(filename, file_response.content)


    def add_exclusion_command(client: CoreClient, args: Dict) -> CommandResults:
        name = args.get('name')
        indicator = args.get('filterObject')
        if not indicator:
            raise DemistoException("Didn't get filterObject arg. This arg is required.")
        status = args.get('status', "ENABLED")
        comment = args.get('comment')

        res = client.add_exclusion(name=name,
                                   status=status,
                                   indicator=json.loads(indicator),
                                   comment=comment)

        return CommandResults(
            readable_output=tableToMarkdown('Add Exclusion', res),
            outputs={
                f'{args.get("integration_context_brand", "CoreApiModule")}.exclusion.rule_id(val.rule_id == obj.rule_id)': res.get(
                    "rule_id")},
            raw_response=res
        )


    def delete_exclusion_command(client: CoreClient, args: Dict) -> CommandResults:
        alert_exclusion_id = arg_to_number(args.get('alert_exclusion_id'))
        if not alert_exclusion_id:
            raise DemistoException("Didn't get alert_exclusion_id arg. This arg is required.")
        res = client.delete_exclusion(alert_exclusion_id=alert_exclusion_id)
        return CommandResults(
            readable_output=f"Successfully deleted the following exclusion: {alert_exclusion_id}",
            outputs={
                f'{args.get("integration_context_brand", "CoreApiModule")}.'
                f'deletedExclusion.rule_id(val.rule_id == obj.rule_id)': res.get(
                    "rule_id")},
            raw_response=res
        )


    def get_exclusion_command(client: CoreClient, args: Dict) -> CommandResults:
        res = client.get_exclusion(tenant_id=args.get('tenant_ID'),
                                   filter=args.get('filterObject'),
                                   limit=arg_to_number(args.get('limit', 20)))

        return CommandResults(
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.exclusion',
            outputs=res,
            readable_output=tableToMarkdown('Exclusion', res),
            raw_response=res
        )


    def decode_dict_values(dict_to_decode: dict):
        """Decode JSON str values of a given dict.

        Args:
          dict_to_decode (dict): The dict to decode.

        """
        for key, value in dict_to_decode.items():
            # if value is a dictionary, we want to recursively decode it's values
            if isinstance(value, dict):
                decode_dict_values(value)
            # if value is a string, we want to try to decode it, if it cannot be decoded, we will move on.
            elif isinstance(value, str):
                try:
                    dict_to_decode[key] = json.loads(value)
                except ValueError:
                    continue


    def filter_general_fields(alert: dict, filter_fields: bool = True) -> dict:
        """filter only relevant general fields from a given alert.

        Args:
          alert (dict): The alert to filter
          filter_fields (bool): Whether to return a subset of the fields.

        Returns:
          dict: The filtered alert
        """

        if filter_fields:
            result = {k: v for k, v in alert.items() if k in ALERT_GENERAL_FIELDS}
        else:
            result = alert

        if not (event := alert.get('raw_abioc', {}).get('event', {})):
            return_warning('No XDR cloud analytics event.')
            return result

        if filter_fields:
            updated_event = {k: v for k, v in event.items() if k in ALERT_EVENT_GENERAL_FIELDS}
        else:
            updated_event = event

        result['event'] = updated_event
        return result


    def filter_vendor_fields(alert: dict):
        """Remove non relevant fields from the alert event (filter by vendor: Amazon/google/Microsoft)

        Args:
          alert (dict): The alert to filter

        Returns:
          dict: The filtered alert
        """
        vendor_mapper = {
            'Amazon': ALERT_EVENT_AWS_FIELDS,
            'Google': ALERT_EVENT_GCP_FIELDS,
            'MSFT': ALERT_EVENT_AZURE_FIELDS,
        }
        event = alert.get('event', {})
        vendor = event.get('vendor')
        if vendor and vendor in vendor_mapper:
            raw_log = event.get('raw_log', {})
            if raw_log and isinstance(raw_log, dict):
                for key in list(raw_log):
                    if key not in vendor_mapper[vendor]:
                        raw_log.pop(key)


    def get_original_alerts_command(client: CoreClient, args: Dict) -> CommandResults:
        alert_id_list = argToList(args.get('alert_ids', []))
        raw_response = client.get_original_alerts(alert_id_list)
        reply = copy.deepcopy(raw_response)
        alerts = reply.get('alerts', [])
        processed_alerts = []
        filtered_alerts = []

        filter_fields_argument = argToBoolean(args.get('filter_alert_fields', True))  # default, for BC, is True.

        for alert in alerts:
            # decode raw_response
            try:
                alert['original_alert_json'] = safe_load_json(alert.get('original_alert_json', ''))
                # some of the returned JSON fields are double encoded, so it needs to be double-decoded.
                # example: {"x": "someValue", "y": "{\"z\":\"anotherValue\"}"}
                decode_dict_values(alert)
            except Exception as e:
                demisto.debug("encountered the following while decoding dictionary values, skipping")
                demisto.debug(e)
                continue

            # Remove original_alert_json field and add its content to the alert body.
            alert.update(alert.pop('original_alert_json', {}))

            # Process the alert (with without filetring fields)
            processed_alerts.append(filter_general_fields(alert, filter_fields=False))

            # Create a filtered version (used either for output when filter_fields is False, or for readable output)
            filtered_alert = filter_general_fields(alert, filter_fields=True)
            filter_vendor_fields(filtered_alert)  # changes in-place

            filtered_alerts.append(filtered_alert)

        return CommandResults(
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.OriginalAlert',
            outputs_key_field='internal_id',
            outputs=filtered_alerts if filter_fields_argument else processed_alerts,
            readable_output=tableToMarkdown("Alerts", t=filtered_alerts),  # Filtered are always used for readable output
            raw_response=raw_response,
        )


    ALERT_STATUS_TYPES = {
        'DETECTED': 'detected',
        'DETECTED_0': 'detected (allowed the session)',
        'DOWNLOAD': 'detected (download)',
        'DETECTED_19': 'detected (forward)',
        'POST_DETECTED': 'detected (post detected)',
        'PROMPT_ALLOW': 'detected (prompt allow)',
        'DETECTED_4': 'detected (raised an alert)',
        'REPORTED': 'detected (reported)',
        'REPORTED_TRIGGER_4': 'detected (on write)',
        'SCANNED': 'detected (scanned)',
        'DETECTED_23': 'detected (sinkhole)',
        'DETECTED_18': 'detected (syncookie sent)',
        'DETECTED_21': 'detected (wildfire upload failure)',
        'DETECTED_20': 'detected (wildfire upload success)',
        'DETECTED_22': 'detected (wildfire upload skip)',
        'DETECTED_MTH': 'detected (xdr managed threat hunting)',
        'BLOCKED_25': 'prevented (block)',
        'BLOCKED': 'prevented (blocked)',
        'BLOCKED_14': 'prevented (block-override)',
        'BLOCKED_5': 'prevented (blocked the url)',
        'BLOCKED_6': 'prevented (blocked the ip)',
        'BLOCKED_13': 'prevented (continue)',
        'BLOCKED_1': 'prevented (denied the session)',
        'BLOCKED_8': 'prevented (dropped all packets)',
        'BLOCKED_2': 'prevented (dropped the session)',
        'BLOCKED_3': 'prevented (dropped the session and sent a tcp reset)',
        'BLOCKED_7': 'prevented (dropped the packet)',
        'BLOCKED_16': 'prevented (override)',
        'BLOCKED_15': 'prevented (override-lockout)',
        'BLOCKED_26': 'prevented (post detected)',
        'PROMPT_BLOCK': 'prevented (prompt block)',
        'BLOCKED_17': 'prevented (random-drop)',
        'BLOCKED_24': 'prevented (silently dropped the session with an icmp unreachable message to the host or application)',
        'BLOCKED_9': 'prevented (terminated the session and sent a tcp reset to both sides of the connection)',
        'BLOCKED_10': 'prevented (terminated the session and sent a tcp reset to the client)',
        'BLOCKED_11': 'prevented (terminated the session and sent a tcp reset to the server)',
        'BLOCKED_TRIGGER_4': 'prevented (on write)',
    }

    ALERT_STATUS_TYPES_REVERSE_DICT = {v: k for k, v in ALERT_STATUS_TYPES.items()}


    def get_alerts_by_filter_command(client: CoreClient, args: Dict) -> CommandResults:
        # get arguments
        request_data: dict = {'filter_data': {}}
        filter_data = request_data['filter_data']
        sort_field = args.pop('sort_field', 'source_insert_ts')
        sort_order = args.pop('sort_order', 'DESC')
        prefix = args.pop("integration_context_brand", "CoreApiModule")
        args.pop("integration_name", None)
        custom_filter = {}
        filter_data['sort'] = [{
            'FIELD': sort_field,
            'ORDER': sort_order
        }]
        offset = args.pop('offset', 0)
        limit = args.pop('limit', 50)
        filter_data['paging'] = {
            'from': int(offset),
            'to': int(limit)
        }
        if not args:
            raise DemistoException('Please provide at least one filter argument.')

        # handle custom filter
        custom_filter_str = args.pop('custom_filter', None)

        if custom_filter_str:
            for arg in args:
                if arg not in ['time_frame', 'start_time', 'end_time']:
                    raise DemistoException(
                        'Please provide either "custom_filter" argument or other filter arguments but not both.')
            try:
                custom_filter = json.loads(custom_filter_str)
            except Exception as e:
                raise DemistoException('custom_filter format is not valid.') from e

        filter_res = create_filter_from_args(args)
        if custom_filter:  # if exists, add custom filter to the built filter
            if 'AND' in custom_filter:
                filter_obj = custom_filter['AND']
                filter_res['AND'].extend(filter_obj)
            else:
                filter_res['AND'].append(custom_filter)

        filter_data['filter'] = filter_res
        demisto.debug(f'sending the following request data: {request_data}')
        raw_response = client.get_alerts_by_filter_data(request_data)

        context = []
        for alert in raw_response.get('alerts', []):
            alert = alert.get('alert_fields')
            if 'alert_action_status' in alert:
                # convert the status, if failed take the original status
                action_status = alert.get('alert_action_status')
                alert['alert_action_status_readable'] = ALERT_STATUS_TYPES.get(action_status, action_status)

            context.append(alert)

        human_readable = [{
            'Alert ID': alert.get('internal_id'),
            'Detection Timestamp': timestamp_to_datestring(alert.get('source_insert_ts')),
            'Name': alert.get('alert_name'),
            'Severity': alert.get('severity'),
            'Category': alert.get('alert_category'),
            'Action': alert.get('alert_action_status_readable'),
            'Description': alert.get('alert_description'),
            'Host IP': alert.get('agent_ip_addresses'),
            'Host Name': alert.get('agent_hostname'),
        } for alert in context]

        return CommandResults(
            outputs_prefix=f'{prefix}.Alert',
            outputs_key_field='internal_id',
            outputs=context,
            readable_output=tableToMarkdown('Alerts', human_readable),
            raw_response=raw_response,
        )


    def get_dynamic_analysis_command(client: CoreClient, args: Dict) -> CommandResults:
        alert_id_list = argToList(args.get('alert_ids', []))
        raw_response = client.get_original_alerts(alert_id_list)
        reply = copy.deepcopy(raw_response)
        alerts = reply.get('alerts', [])
        filtered_alerts = []
        for alert in alerts:
            # decode raw_response
            try:
                alert['original_alert_json'] = safe_load_json(alert.get('original_alert_json', ''))
                # some of the returned JSON fields are double encoded, so it needs to be double-decoded.
                # example: {"x": "someValue", "y": "{\"z\":\"anotherValue\"}"}
                decode_dict_values(alert)
            except Exception as e:
                demisto.debug("encountered the following while decoding dictionary values, skipping")
                demisto.debug(e)
            # remove original_alert_json field and add its content to alert.
            alert.update(alert.pop('original_alert_json', {}))
            if demisto.get(alert, 'messageData.dynamicAnalysis'):
                filtered_alerts.append(demisto.get(alert, 'messageData.dynamicAnalysis'))
        if not filtered_alerts:
            return CommandResults(
                readable_output="There is no dynamicAnalysis for these alert ids.",
                raw_response=raw_response
            )
        return CommandResults(
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.DynamicAnalysis',
            outputs=filtered_alerts,
            raw_response=raw_response,
        )


    def create_request_filters(
        status: Optional[str] = None,
        username: Optional[List] = None,
        endpoint_id_list: Optional[List] = None,
        dist_name: Optional[List] = None,
        ip_list: Optional[List] = None,
        public_ip_list: Optional[List] = None,
        group_name: Optional[List] = None,
        platform: Optional[List] = None,
        alias_name: Optional[List] = None,
        isolate: Optional[str] = None,
        hostname: Optional[List] = None,
        first_seen_gte=None,
        first_seen_lte=None,
        last_seen_gte=None,
        last_seen_lte=None,
        scan_status=None,
    ):
        filters = []

        if status:
            filters.append({
                'field': 'endpoint_status',
                'operator': 'IN',
                'value': status if isinstance(status, list) else [status]
            })

        if username:
            filters.append({
                'field': 'username',
                'operator': 'IN',
                'value': username
            })

        if endpoint_id_list:
            filters.append({
                'field': 'endpoint_id_list',
                'operator': 'in',
                'value': endpoint_id_list
            })

        if dist_name:
            filters.append({
                'field': 'dist_name',
                'operator': 'in',
                'value': dist_name
            })

        if ip_list:
            filters.append({
                'field': 'ip_list',
                'operator': 'in',
                'value': ip_list
            })

        if public_ip_list:
            filters.append({
                'field': 'public_ip_list',
                'operator': 'in',
                'value': public_ip_list
            })

        if group_name:
            filters.append({
                'field': 'group_name',
                'operator': 'in',
                'value': group_name
            })

        if platform:
            filters.append({
                'field': 'platform',
                'operator': 'in',
                'value': platform
            })

        if alias_name:
            filters.append({
                'field': 'alias',
                'operator': 'in',
                'value': alias_name
            })

        if isolate:
            filters.append({
                'field': 'isolate',
                'operator': 'in',
                'value': [isolate]
            })

        if hostname:
            filters.append({
                'field': 'hostname',
                'operator': 'in',
                'value': hostname
            })

        if first_seen_gte:
            filters.append({
                'field': 'first_seen',
                'operator': 'gte',
                'value': first_seen_gte
            })

        if first_seen_lte:
            filters.append({
                'field': 'first_seen',
                'operator': 'lte',
                'value': first_seen_lte
            })

        if last_seen_gte:
            filters.append({
                'field': 'last_seen',
                'operator': 'gte',
                'value': last_seen_gte
            })

        if last_seen_lte:
            filters.append({
                'field': 'last_seen',
                'operator': 'lte',
                'value': last_seen_lte
            })

        if scan_status:
            filters.append({
                'field': 'scan_status',
                'operator': 'IN',
                'value': [scan_status]
            })

        return filters


    def args_to_request_filters(args):

        if set(args.keys()) & {  # check if any filter argument was provided
            'endpoint_id_list', 'dist_name', 'ip_list', 'group_name', 'platform', 'alias_name',
            'isolate', 'hostname', 'status', 'first_seen_gte', 'first_seen_lte', 'last_seen_gte', 'last_seen_lte'
        }:
            endpoint_id_list = argToList(args.get('endpoint_id_list'))
            dist_name = argToList(args.get('dist_name'))
            ip_list = argToList(args.get('ip_list'))
            group_name = argToList(args.get('group_name'))
            platform = argToList(args.get('platform'))
            alias_name = argToList(args.get('alias_name'))
            isolate = args.get('isolate')
            hostname = argToList(args.get('hostname'))
            status = args.get('status')

            first_seen_gte = arg_to_timestamp(
                arg=args.get('first_seen_gte'),
                arg_name='first_seen_gte'
            )

            first_seen_lte = arg_to_timestamp(
                arg=args.get('first_seen_lte'),
                arg_name='first_seen_lte'
            )

            last_seen_gte = arg_to_timestamp(
                arg=args.get('last_seen_gte'),
                arg_name='last_seen_gte'
            )

            last_seen_lte = arg_to_timestamp(
                arg=args.get('last_seen_lte'),
                arg_name='last_seen_lte'
            )

            return create_request_filters(
                endpoint_id_list=endpoint_id_list, dist_name=dist_name, ip_list=ip_list,
                group_name=group_name, platform=platform, alias_name=alias_name, isolate=isolate, hostname=hostname,
                first_seen_lte=first_seen_lte, first_seen_gte=first_seen_gte,
                last_seen_lte=last_seen_lte, last_seen_gte=last_seen_gte, status=status
            )
        # a request must be sent with at least one filter parameter, so by default we will send the endpoint_id_list filter
        return create_request_filters(endpoint_id_list=argToList(args.get('endpoint_ids')))


    def add_tag_to_endpoints_command(client: CoreClient, args: Dict):
        endpoint_ids = argToList(args.get('endpoint_ids', []))
        tag = args.get('tag')
        raw_response = {}
        for b in batch(endpoint_ids, 1000):
            raw_response.update(client.add_tag_endpoint(endpoint_ids=b, tag=tag, args=args))

        return CommandResults(
            readable_output=f'Successfully added tag {tag} to endpoint(s) {endpoint_ids}', raw_response=raw_response
        )


    def remove_tag_from_endpoints_command(client: CoreClient, args: Dict):
        endpoint_ids = argToList(args.get('endpoint_ids', []))
        tag = args.get('tag')
        raw_response = {}
        for b in batch(endpoint_ids, 1000):
            raw_response.update(client.remove_tag_endpoint(endpoint_ids=b, tag=tag, args=args))

        return CommandResults(
            readable_output=f'Successfully removed tag {tag} from endpoint(s) {endpoint_ids}', raw_response=raw_response
        )


    def parse_risky_users_or_hosts(user_or_host_data: dict[str, Any],
                                   id_header: str,
                                   score_header: str,
                                   description_header: str
                                   ) -> dict[str, Any]:

        reasons = user_or_host_data.get('reasons', [])
        return {
            id_header: user_or_host_data.get('id'),
            score_header: user_or_host_data.get('score'),
            description_header: reasons[0].get('description') if reasons else None,
        }


    def parse_user_groups(group: dict[str, Any]) -> list[dict[str, Any]]:
        return [
            {
                'User email': user,
                'Group Name': group.get('group_name'),
                'Group Description': group.get('description'),
            }
            for user in group.get("user_email", [])
        ]


    def parse_role_names(role_data: dict[str, Any]) -> dict[str, Any]:
        return {
            "Role Name": role_data.get("pretty_name"),
            "Description": role_data.get("description"),
            "Permissions": role_data.get("permissions", []),
            "Users": role_data.get("users", []),
            "Groups": role_data.get("groups", []),
        }


    def enrich_error_message_id_group_role(e: DemistoException, type_: str | None, custom_message: str | None) -> str | None:
        """
        Attempts to parse additional info from an exception and return it as string. Returns `None` if it can't do that.

        Args:
            e (Exception): The error that occurred.
            type (str | None): The type of resource associated with the error(Role id or Group), if applicable.
            custom_message (str | None): A custom error message to be included in the raised ValueError, if desired.

        Raises:
            ValueError: If the error message indicates that the resource was not found, a more detailed error message
                is constructed using the `find_the_cause_error` function and raised with the original error as the cause.
        """
        if (
            e.res is not None
            and e.res.status_code == 500
            and 'was not found' in str(e)
        ):
            error_message: str = ''
            pattern = r"(id|Group|Role) \\?'([/A-Za-z 0-9_]+)\\?'"
            if match := re.search(pattern, str(e)):
                error_message = f'Error: {match[1]} {match[2]} was not found. '

            return (f'{error_message}{custom_message if custom_message and type_ in ("Group", "Role") else ""}'
                    f'Full error message: {e}')
        return None


    def list_users_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
        Returns a list of all users using the Core API client.

        Args:
            client: A CoreClient instance used for connecting to the Core API.
            args: A dictionary containing additional arguments. Possible keys include:
                - integration_context_brand (str): The name of the integration context brand.

        Returns:
            A CommandResults object containing the readable_output and outputs fields.

        Raises:
            ValueError: If the API connection failed.
        """

        def parse_user(user: dict[str, Any]) -> dict[str, Any]:
            return {
                'User email': user.get('user_email'),
                'First Name': user.get('user_first_name'),
                'Last Name': user.get('user_last_name'),
                'Role': user.get('role_name'),
                'Type': user.get('user_type'),
                'Groups': user.get('groups'),
            }

        listed_users: list[dict[str, Any]] = client.list_users().get('reply', [])
        table_for_markdown = [parse_user(user) for user in listed_users]
        readable_output = tableToMarkdown(name='Users', t=table_for_markdown)

        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.User',
            outputs_key_field='user_email',
            outputs=listed_users,
        )


    def list_user_groups_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
         Retrieves a list of user groups from the Core API module based on the specified group names.

        Args:
            client: A CoreClient object used to communicate with the Core API module.
            args: A dictionary of arguments passed to the function. The following keys may be present:
                - group_names (required): A list of group names to retrieve details for.

        Returns:
            A CommandResults object containing the table of user groups.

        Raises:
            ValueError: If the API connection fails or the specified group name(s) is not found.
        """

        group_names = argToList(args['group_names'])
        try:
            outputs = client.list_user_groups(group_names).get("reply", [])
        except DemistoException as e:
            custom_message = None
            if len(group_names) > 1:
                custom_message = "Note: If you sent more than one group name, they may not exist either. "

            if error_message := enrich_error_message_id_group_role(e=e, type_="Group", custom_message=custom_message):
                raise DemistoException(error_message)
            raise

        table_for_markdown: list[dict[str, str | None]] = []
        for group in outputs:
            table_for_markdown.extend(parse_user_groups(group))

        headers = ["Group Name", "Group Description", "User email"]
        readable_output = tableToMarkdown(name='Groups', t=table_for_markdown, headers=headers)
        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.UserGroup',
            outputs_key_field='group_name',
            outputs=outputs,
        )


    def list_roles_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
        Retrieves a list of roles with the provided role names from the Core API.

        Args:
            client: A CoreClient object used to communicate with the Core API module.
            args: A dictionary of arguments. The 'role_names' key should be present and contain a
                  comma-separated string of role names to retrieve.

        Returns:
             A CommandResults object containing the table of roles.

        Raises:
            DemistoException: If an error occurs while retrieving the data from the Core API.
            ValueError: If the input argument is not valid.

        """
        role_names = argToList(args["role_names"])
        try:
            outputs = client.list_roles(role_names).get("reply", [])
        except DemistoException as e:
            custom_message = None
            if len(role_names) > 1:
                custom_message = "Note: If you sent more than one Role name, they may not exist either. "

            if error_message := enrich_error_message_id_group_role(e=e, type_="Role", custom_message=custom_message):
                raise DemistoException(error_message)
            raise

        headers = ["Role Name", "Description", "Permissions", "Users", "Groups"]
        table_for_markdown = [parse_role_names(role[0]) for role in outputs if len(role) == 1]
        readable_output = tableToMarkdown(
            name='Roles',
            t=table_for_markdown,
            headers=headers
        )
        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.Role',
            outputs_key_field='pretty_name',
            outputs=outputs,
        )


    def change_user_role_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
         Changes or removes the role of user(s) in the system.

        Args:
            client (CoreClient): An instance of the CoreClient class used to interact with the system.
            args (dict[str, str]): A dictionary containing the command arguments.
                - 'user_emails' (str): A comma-separated string of user emails.
                - 'role_name' (str, optional): The name of the role to assign to the user(s).
                  If not provided, the role for the user(s) will be removed.

        Returns:
            CommandResults: An object containing the result of the command execution.
        """
        user_emails = argToList(args['user_emails'])

        if role_name := args.get('role_name'):
            res = client.set_user_role(user_emails, role_name)["reply"]
            action_message = "updated"
        else:
            res = client.remove_user_role(user_emails)["reply"]
            action_message = "removed"

        if not (count := int(res["update_count"])):
            raise DemistoException(f"No user role has been {action_message}.")

        plural_suffix = 's' if count > 1 else ''

        return CommandResults(
            readable_output=f"Role was {action_message} successfully for {count} user{plural_suffix}."
        )


    def list_risky_users_or_host_command(client: CoreClient, command: str, args: dict[str, str]) -> CommandResults:
        """
        Retrieves a list of risky users or details about a specific user's risk score.

        Args:
            client: A CoreClient object used to communicate with the API.
            args: A dictionary containing the following headers (optional):
                - user_id [str]: ID of the user to retrieve risk score details for.
                - limit [str]: Specifying the maximum number of risky users to return.

        Returns:
            A CommandResults object, in case the user was not found, an appropriate message will be returend.

        Raises:
            ValueError: If the API connection fails.

        """
        def _warn_if_module_is_disabled(e: DemistoException) -> None:
            if (
                    e is not None
                    and e.res is not None
                    and e.res.status_code == 500
                    and 'No identity threat' in str(e)
                    and "An error occurred while processing XDR public API" in e.message
            ):
                return_warning(f'Please confirm the XDR Identity Threat Module is enabled.\nFull error message: {e}', exit=True)

        match command:
            case "user":
                id_key = "user_id"
                table_title = "Risky Users"
                outputs_prefix = "RiskyUser"
                get_func = client.list_risky_users
                table_headers = ["User ID", "Score", "Description"]
            case 'host':
                id_key = "host_id"
                table_title = "Risky Hosts"
                outputs_prefix = "RiskyHost"
                get_func = client.list_risky_hosts
                table_headers = ["Host ID", "Score", "Description"]

        outputs: list[dict] | dict
        if id_ := args.get(id_key):
            try:
                outputs = client.risk_score_user_or_host(id_).get('reply', {})
            except DemistoException as e:
                _warn_if_module_is_disabled(e)
                if error_message := enrich_error_message_id_group_role(e=e, type_="id", custom_message=""):
                    not_found_message = 'was not found'
                    if not_found_message in error_message:
                        return CommandResults(readable_output=f'The {command} {id_} {not_found_message}')
                    else:
                        raise DemistoException(error_message)
                else:
                    raise

            table_for_markdown = [parse_risky_users_or_hosts(outputs, *table_headers)]  # type: ignore[arg-type]

        else:
            list_limit = int(args.get('limit', 50))

            try:
                outputs = get_func().get('reply', [])[:list_limit]
            except DemistoException as e:
                _warn_if_module_is_disabled(e)
                raise
            table_for_markdown = [parse_risky_users_or_hosts(user, *table_headers) for user in outputs]

        readable_output = tableToMarkdown(name=table_title, t=table_for_markdown, headers=table_headers)

        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.{outputs_prefix}',
            outputs_key_field='id',
            outputs=outputs,
        )


    def get_incidents_command(client, args):
        """
        Retrieve a list of incidents from XDR, filtered by some filters.
        """

        # sometimes incident id can be passed as integer from the playbook
        incident_id_list = args.get('incident_id_list')
        if isinstance(incident_id_list, int):
            incident_id_list = str(incident_id_list)

        incident_id_list = argToList(incident_id_list)
        # make sure all the ids passed are strings and not integers
        for index, id_ in enumerate(incident_id_list):
            if isinstance(id_, int | float):
                incident_id_list[index] = str(id_)

        lte_modification_time = args.get('lte_modification_time')
        gte_modification_time = args.get('gte_modification_time')
        since_modification_time = args.get('since_modification_time')

        if since_modification_time and gte_modification_time:
            raise ValueError('Can\'t set both since_modification_time and lte_modification_time')
        if since_modification_time:
            gte_modification_time, _ = parse_date_range(since_modification_time, TIME_FORMAT)

        lte_creation_time = args.get('lte_creation_time')
        gte_creation_time = args.get('gte_creation_time')
        since_creation_time = args.get('since_creation_time')

        if since_creation_time and gte_creation_time:
            raise ValueError('Can\'t set both since_creation_time and lte_creation_time')
        if since_creation_time:
            gte_creation_time, _ = parse_date_range(since_creation_time, TIME_FORMAT)

        statuses = argToList(args.get('status', ''))

        starred = args.get('starred')
        starred_incidents_fetch_window = args.get('starred_incidents_fetch_window', '3 days')
        starred_incidents_fetch_window, _ = parse_date_range(starred_incidents_fetch_window, to_timestamp=True)

        sort_by_modification_time = args.get('sort_by_modification_time')
        sort_by_creation_time = args.get('sort_by_creation_time')

        page = int(args.get('page', 0))
        limit = int(args.get('limit', 100))

        # If no filters were given, return a meaningful error message
        if not incident_id_list and (not lte_modification_time and not gte_modification_time and not since_modification_time
                                     and not lte_creation_time and not gte_creation_time and not since_creation_time
                                     and not statuses and not starred):
            raise ValueError("Specify a query for the incidents.\nFor example:"
                             " since_creation_time=\"1 year\" sort_by_creation_time=\"desc\" limit=10")

        if statuses:
            raw_incidents = []

            for status in statuses:
                raw_incidents += client.get_incidents(
                    incident_id_list=incident_id_list,
                    lte_modification_time=lte_modification_time,
                    gte_modification_time=gte_modification_time,
                    lte_creation_time=lte_creation_time,
                    gte_creation_time=gte_creation_time,
                    sort_by_creation_time=sort_by_creation_time,
                    sort_by_modification_time=sort_by_modification_time,
                    page_number=page,
                    limit=limit,
                    status=status,
                    starred=starred,
                    starred_incidents_fetch_window=starred_incidents_fetch_window,
                )

            if len(raw_incidents) > limit:
                raw_incidents = raw_incidents[:limit]
        else:
            raw_incidents = client.get_incidents(
                incident_id_list=incident_id_list,
                lte_modification_time=lte_modification_time,
                gte_modification_time=gte_modification_time,
                lte_creation_time=lte_creation_time,
                gte_creation_time=gte_creation_time,
                sort_by_creation_time=sort_by_creation_time,
                sort_by_modification_time=sort_by_modification_time,
                page_number=page,
                limit=limit,
                starred=starred,
                starred_incidents_fetch_window=starred_incidents_fetch_window,
            )

        return (
            tableToMarkdown('Incidents', raw_incidents),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Incident(val.incident_id==obj.incident_id)': raw_incidents
            },
            raw_incidents
        )

    register_module_line('CoreIRApiModule', 'end', __line__(), wrapper=1)
    ### END GENERATED CODE ###

    # Disable insecure warnings
    urllib3.disable_warnings()

    TIME_FORMAT = "%Y-%m-%dT%H:%M:%S"

    INTEGRATION_CONTEXT_BRAND = 'Core'
    INTEGRATION_NAME = 'Cortex Core - IR'

    XSOAR_RESOLVED_STATUS_TO_Core = {
        'Other': 'resolved_other',
        'Duplicate': 'resolved_duplicate',
        'False Positive': 'resolved_false_positive',
        'Resolved': 'resolved_true_positive',
    }

    PREVALENCE_COMMANDS = {
        'core-get-hash-analytics-prevalence': 'hash',
        'core-get-IP-analytics-prevalence': 'ip',
        'core-get-domain-analytics-prevalence': 'domain',
        'core-get-process-analytics-prevalence': 'process',
        'core-get-registry-analytics-prevalence': 'registry',
        'core-get-cmd-analytics-prevalence': 'cmd',
    }


    class Client(CoreClient):

        def test_module(self):
            """
                Performs basic get request to get item samples
            """
            try:
                self.get_endpoints(limit=1)
            except Exception as err:
                if 'API request Unauthorized' in str(err):
                    # this error is received from the Core server when the client clock is not in sync to the server
                    raise DemistoException(f'{str(err)} please validate that your both '
                                           f'XSOAR and Core server clocks are in sync')
                else:
                    raise

        def report_incorrect_wildfire(self, file_hash: str, new_verdict: int, reason: str, email: str) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                "hash": file_hash,
                "new_verdict": new_verdict,
                "reason": reason,
                "email": email,
            }

            reply = demisto._apiCall(name="wfReportIncorrectVerdict",
                                     params=None,
                                     data=json.dumps(request_data))

            return reply

        def get_prevalence(self, request_data: dict):
            reply = self._http_request(method='POST', json_data={'request_data': request_data}, headers=self._headers,
                                       url_suffix='/analytics_apis/')
            return reply


    def report_incorrect_wildfire_command(client: Client, args) -> CommandResults:
        file_hash = args.get('file_hash')
        reason = args.get('reason')
        email = args.get('email')
        new_verdict = arg_to_int(
            arg=args.get('new_verdict'),
            arg_name='Failed to parse "new_verdict". Must be a number.',
            required=True
        )

        response = client.report_incorrect_wildfire(file_hash, new_verdict, reason, email)
        return CommandResults(
            readable_output=f'Reported incorrect WildFire on {file_hash}',
            outputs_prefix=f'{INTEGRATION_CONTEXT_BRAND}.WildFire',
            outputs={"file_hash": file_hash, "new_verdict": new_verdict},
            raw_response=response,
        )


    def handle_prevalence_command(client: Client, command: str, args: dict):
        key_names_in_response = {
            'ip': 'ip_address',
            'domain': 'domain_name',
            'process': 'process_name',
            'cmd': 'process_command_line',
            'hash': 'sha256',
            'registry': 'key_name',
        }
        args.pop('integration_context_brand', None)
        args.pop('integration_name', None)
        if command == 'core-get-registry-analytics-prevalence':
            # arg list should in the following structure:
            #   args: [
            #       {"key_name": "some_key1", "value_name": "some_value1"},
            #       {"key_name": "some_key2", "value_name": "some_value2"}
            #       ]

            args_list = []
            keys = argToList(args.get('key_name'))
            values = argToList(args.get('value_name'))
            if len(keys) != len(values):
                raise DemistoException('Number of elements in key_name argument should be equal to the number '
                                       'of elements in value_name argument.')
            for key, value in zip(keys, values):
                args_list.append({'key_name': key, 'value_name': value})
        else:
            args_list = []
            for key, value in args.items():
                values = argToList(value)
                for val in values:
                    args_list.append({key: val})

        request_body = {
            'api_id': command,
            'args': args_list
        }
        res = client.get_prevalence(request_body).get('results', [])
        for item in res:  # remove 'args' scope
            name = item.pop('args', {})
            item.update(name)
        command_type = PREVALENCE_COMMANDS[command]
        return CommandResults(
            readable_output=tableToMarkdown(string_to_table_header(f'{command_type} Prevalence'),
                                            [{
                                                key_names_in_response[command_type]: item.get(
                                                    key_names_in_response[command_type]),
                                                'Prevalence': item.get('value')
                                            } for item in res],
                                            headerTransform=string_to_table_header),
            outputs_prefix=f'{INTEGRATION_CONTEXT_BRAND}.AnalyticsPrevalence.{command_type.title()}',
            outputs=res,
            raw_response=res,
        )


    def main():  # pragma: no cover
        """
        Executes an integration command
        """
        command = demisto.command()
        LOG(f'Command being called is {command}')
        args = demisto.args()
        args["integration_context_brand"] = INTEGRATION_CONTEXT_BRAND
        args["integration_name"] = INTEGRATION_NAME
        api_key = demisto.params().get('apikey')
        api_key_id = demisto.params().get('apikey_id')
        url = demisto.params().get('url')
        url_suffix = '/xsiam' if command in PREVALENCE_COMMANDS else "/public_api/v1"

        if not api_key or not api_key_id or not url:
            headers = {
                "HOST": demisto.getLicenseCustomField("Core.ApiHostName"),
                demisto.getLicenseCustomField("Core.ApiHeader"): demisto.getLicenseCustomField("Core.ApiKey"),
                "Content-Type": "application/json"
            }
            url = "http://" + demisto.getLicenseCustomField("Core.ApiHost") + "/api/webapp/"
            add_sensitive_log_strs(demisto.getLicenseCustomField("Core.ApiKey"))
        else:
            headers = {
                "Content-Type": "application/json",
                "x-xdr-auth-id": str(api_key_id),
                "Authorization": api_key
            }
            add_sensitive_log_strs(api_key)

        base_url = urljoin(url, url_suffix)
        proxy = demisto.params().get('proxy')
        verify_cert = not demisto.params().get('insecure', False)

        try:
            timeout = int(demisto.params().get('timeout', 120))
        except ValueError as e:
            demisto.debug(f'Failed casting timeout parameter to int, falling back to 120 - {e}')
            timeout = 120

        client = Client(
            base_url=base_url,
            proxy=proxy,
            verify=verify_cert,
            headers=headers,
            timeout=timeout
        )

        try:
            if command == 'test-module':
                client.test_module()
                demisto.results('ok')

            elif command == 'core-get-endpoints':
                return_results(get_endpoints_command(client, args))

            elif command == 'core-endpoint-alias-change':
                return_results(endpoint_alias_change_command(client, **args))

            elif command == 'core-isolate-endpoint':
                polling_args = {
                    **args,
                    "endpoint_id_list": args.get('endpoint_id')
                }
                return_results(run_polling_command(client=client,
                                                   args=polling_args,
                                                   cmd="core-isolate-endpoint",
                                                   command_function=isolate_endpoint_command,
                                                   command_decision_field="action_id",
                                                   results_function=get_endpoints_command,
                                                   polling_field="is_isolated",
                                                   polling_value=["AGENT_ISOLATED"],
                                                   stop_polling=True))

            elif command == 'core-unisolate-endpoint':
                polling_args = {
                    **args,
                    "endpoint_id_list": args.get('endpoint_id')
                }
                return_results(run_polling_command(client=client,
                                                   args=polling_args,
                                                   cmd="core-unisolate-endpoint",
                                                   command_function=unisolate_endpoint_command,
                                                   command_decision_field="action_id",
                                                   results_function=get_endpoints_command,
                                                   polling_field="is_isolated",
                                                   polling_value=["AGENT_UNISOLATED",
                                                                  "CANCELLED",
                                                                  "ֿPENDING_ABORT",
                                                                  "ABORTED",
                                                                  "EXPIRED",
                                                                  "COMPLETED_PARTIAL",
                                                                  "COMPLETED_SUCCESSFULLY",
                                                                  "FAILED",
                                                                  "TIMEOUT"],
                                                   stop_polling=True))

            elif command == 'core-get-distribution-url':
                return_outputs(*get_distribution_url_command(client, args))

            elif command == 'core-get-create-distribution-status':
                return_outputs(*get_distribution_status_command(client, args))

            elif command == 'core-get-distribution-versions':
                return_outputs(*get_distribution_versions_command(client, args))

            elif command == 'core-create-distribution':
                return_outputs(*create_distribution_command(client, args))

            elif command == 'core-get-audit-management-logs':
                return_outputs(*get_audit_management_logs_command(client, args))

            elif command == 'core-get-audit-agent-reports':
                return_outputs(*get_audit_agent_reports_command(client, args))

            elif command == 'core-blocklist-files':
                return_results(blocklist_files_command(client, args))

            elif command == 'core-allowlist-files':
                return_results(allowlist_files_command(client, args))

            elif command == 'core-quarantine-files':
                polling_args = {
                    **args,
                    "endpoint_id": argToList(args.get("endpoint_id_list"))[0]
                }
                return_results(run_polling_command(client=client,
                                                   args=polling_args,
                                                   cmd="core-quarantine-files",
                                                   command_function=quarantine_files_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-get-quarantine-status':
                return_results(get_quarantine_status_command(client, args))

            elif command == 'core-restore-file':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-restore-file",
                                                   command_function=restore_file_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-endpoint-scan':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-endpoint-scan",
                                                   command_function=endpoint_scan_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-endpoint-scan-abort':
                return_results(endpoint_scan_abort_command(client, args))

            elif command == 'core-delete-endpoints':
                return_outputs(*delete_endpoints_command(client, args))

            elif command == 'core-get-policy':
                return_outputs(*get_policy_command(client, args))

            elif command == 'core-get-endpoint-device-control-violations':
                return_outputs(*get_endpoint_device_control_violations_command(client, args))

            elif command == 'core-retrieve-files':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-retrieve-files",
                                                   command_function=retrieve_files_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-retrieve-file-details':
                return_entry, file_results = retrieve_file_details_command(client, args, False)
                demisto.results(return_entry)
                if file_results:
                    demisto.results(file_results)

            elif command == 'core-get-scripts':
                return_outputs(*get_scripts_command(client, args))

            elif command == 'core-get-script-metadata':
                return_outputs(*get_script_metadata_command(client, args))

            elif command == 'core-get-script-code':
                return_outputs(*get_script_code_command(client, args))

            elif command == 'core-action-status-get':
                return_results(action_status_get_command(client, args))

            elif command == 'core-run-script':
                return_results(run_script_command(client, args))

            elif command == 'core-run-snippet-code-script':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-run-snippet-code-script",
                                                   command_function=run_snippet_code_script_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-get-script-execution-status':
                return_results(get_script_execution_status_command(client, args))

            elif command == 'core-get-script-execution-results':
                return_results(get_script_execution_results_command(client, args))

            elif command == 'core-get-script-execution-result-files':
                return_results(get_script_execution_result_files_command(client, args))

            elif command == 'core-run-script-execute-commands':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-run-script-execute-commands",
                                                   command_function=run_script_execute_commands_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-run-script-delete-file':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-run-script-delete-file",
                                                   command_function=run_script_delete_file_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-run-script-file-exists':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-run-script-file-exists",
                                                   command_function=run_script_file_exists_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-run-script-kill-process':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="core-run-script-kill-process",
                                                   command_function=run_script_kill_process_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'endpoint':
                return_results(endpoint_command(client, args))

            elif command == 'core-report-incorrect-wildfire':
                return_results(report_incorrect_wildfire_command(client, args))

            elif command == 'core-remove-blocklist-files':
                return_results(remove_blocklist_files_command(client, args))

            elif command == 'core-remove-allowlist-files':
                return_results(remove_allowlist_files_command(client, args))

            elif command == 'core-add-exclusion':
                return_results(add_exclusion_command(client, args))

            elif command == 'core-delete-exclusion':
                return_results(delete_exclusion_command(client, args))

            elif command == 'core-get-exclusion':
                return_results(get_exclusion_command(client, args))

            elif command == 'core-get-cloud-original-alerts':
                return_results(get_original_alerts_command(client, args))

            elif command == 'core-get-dynamic-analysis':
                return_results(get_dynamic_analysis_command(client, args))

            elif command == 'core-add-endpoint-tag':
                return_results(add_tag_to_endpoints_command(client, args))

            elif command == 'core-remove-endpoint-tag':
                return_results(remove_tag_from_endpoints_command(client, args))

            elif command == 'core-list-users':
                return_results(list_users_command(client, args))

            elif command == 'core-list-risky-users':
                return_results(list_risky_users_or_host_command(client, "user", args))

            elif command == 'core-list-risky-hosts':
                return_results(list_risky_users_or_host_command(client, "host", args))

            elif command == 'core-list-user-groups':
                return_results(list_user_groups_command(client, args))

            elif command == 'core-get-incidents':
                return_outputs(*get_incidents_command(client, args))

            elif command in PREVALENCE_COMMANDS:
                return_results(handle_prevalence_command(client, command, args))

        except Exception as err:
            demisto.error(traceback.format_exc())
            return_error(str(err))


    if __name__ in ('__main__', '__builtin__', 'builtins'):
        main()

    register_module_line('Cortex Core - IR', 'end', __line__())
  subtype: python3
  type: python
system: true
